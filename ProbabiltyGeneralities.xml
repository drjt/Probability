<?xml version="1.0" encoding="UTF-8"?>

<!-- This file is part of the documentation of MathBook XML   -->
<!--                                                          -->
<!--    MathBook XML Author's Guide                           -->
<!--                                                          -->
<!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
<!-- See the file COPYING for copying conditions.             -->

<chapter xml:id="ProbabilityGeneralities" xmlns:xi="http://www.w3.org/2001/XInclude">
<title>Probability and Probability Functions</title>

<introduction>
	<p>This chapter is a definitions of probability, consequences, and probability functions.</p>
</introduction>


<section xml:id="RelativeFrequency"><title>Relative Frequency</title>
	<p>Mathematics generally focuses on providing precise answers with absolute certainty. For example, solving an equation generates specific (and non-varying) solutions. Statistics on the other hand deals with providing precise answers to questions when there is uncertainty. It might seem impossible to provide such precise answers but the focus of this text is to show how that can be done so long as the questions are properly posed and the answers properly interpreted.</p>
	<p>People often make claims about being the biggest, best, most often recommended, etc. One sometimes even believes these claims. In this class, we will attempt to determine if such claims are reasonable by first introducing probability from a semi rigorous mathematical viewpoint using concepts developed in Calculus. We will use this framework to carefully discuss making such statistical inferences as above and in general to obtain accurate knowledge even when the known data is not complete. </p>

	<p>When attempting to precisely measure this uncertainty a few experiments are in order. When doing statistical experiments, a few terms and corresponding notation might be useful:</p>
	<ul>
		<li>S = Universal Set or Sample Space Experiment or Outcome Space. 
		This is the collection of all possible outcomes.</li>
		<li>Random Experiment. A random experiment is a repeatable activity which has more than one
		possible outcome all of which can be specified in advance but can not be known in advance with certainty.</li>
		<li>Trial. Performing a Random Experiment one time and measuring the result.</li> 
		<li>A = Event. A collection of outcomes.  Generally denoted by an upper case letter such as A, B, C, etc.</li>
		<li>Success/Failure. When recording the result of a trial, a success for event A occurs when the outcome
		lies in A. If not, then the trial was a failure. There is no qualitative meaning to this term.</li>
		<li>Mutually Exclusive Events. Two events which share no common outcomes. Also known as disjoint events.</li>
		<li>|A| = Frequency. In a sequence of n events, the frequency is the number of trials which resulted in 
		a success for event A.</li>
		<li>|A| / n = Relative Frequency. A proportion of successes to total number of trials.</li>
		<li>Histogram. A bar chart representation of data where area corresponds to the value being described.</li>
	</ul>

	<p>To investigate these terms and to motivate our discussion of probability, consider flipping coins using the interactive cell below. Notice in this case, the sample space S = {Heads, Tails} and the random experiment consists of flipping a fair coin one time. Each trial results in either a Head or a Tail. Since we are measuring both Heads and Tails then we will not worry about which is a success or failure. Further, on each flip the outcomes of Heads or Tails are mutually exclusive events. We count the frequencies and compute the relative frequencies for a varying number of trials selected by you as you move the slider bar. Results are displayed using a histogram.</p>

	<p>
	Question 1: What do you notice as the number of flips increases?
	</p>
	<p>
	Question 2: Why do you rarely (if even) get exactly the same number of Heads and Tails? Would you not "expect"
	that to happen?
	</p>
	
	
<sage>
<input>
coin = ["Heads", "Tails"]
@interact
def _(num_rolls = slider([5..5000],label="Number of Flips")):
	rolls = [choice(coin) for roll in range(num_rolls)]
	show(rolls)   
	freq = [0,0]
	for outcome in rolls:
		if (outcome=='Tails'):
			freq[0] = freq[0]+1
		else:
			freq[1] = freq[1]+1
	print("\nThe frequency of tails = "+ str(freq[0]))+" and heads = "+ str(freq[1])+"."
	rel = [freq[0]/num_rolls,freq[1]/num_rolls]
	print("\nThe relative frequencies for Tails and Heads:"+str(rel))
	show(bar_chart(freq,axes=False,ymin=0))     #  A histogram of the results
</input>
</sage>


	<p>Notice that as the number of flips increases, the relative frequency of Heads (and Tails)
	stabilized around 0.5. This makes sense intuitively since there are two options for each 
	individual flip and 1/2 of those options are Heads while the other 1/2 is Tails.</p>
	<p>
	Let's try again
	by doing a random experiment consisting of rolling a single die one time. Note that the sample space 
	in this case will be the outcomes S = {1, 2, 3, 4, 5, 6}.
	</p>


<!--
	<exercise>
		<introduction>
		Let's see if you understand the relationship between frequency and relative frequency.
		</introduction>
		<webwork source="local/relative_frequency1.pg" />
		<conclusion>
		So, these are simple calculations.
		</conclusion>
	</exercise>
-->

	<p>
	Question 1: What do you notice as the number of rolls increases?
	</p>
	<p>
	Question 2: What do you expect for the relative frequencies and why are they not all exactly the same?
	</p>


<sage>
<input>
@interact
def _(num_rolls = slider([20..5000],label='Number of rolls'),Number_of_Sides = [4,6,8,12,20]):
	die = list((1..Number_of_Sides))
	rolls = [choice(die) for roll in range(num_rolls)]
	show(rolls)   

	freq = [rolls.count(outcome) for outcome in set(die)]  # count the numbers for each outcome
	print 'The frequencies of each outcome is '+str(freq)

	print 'The relative frequencies of each outcome:'
	rel_freq = [freq[outcome-1]/num_rolls for outcome in set(die)]  # make frequencies relative
	print rel_freq
	fs = []
	for f in rel_freq:
		fs.append(f.n(digits=4))
	print fs
	show(bar_chart(freq,axes=False,ymin=0)) 
</input>
</sage>


	<p>Notice in this instance that there are a larger number of options (for example 6 on a regular
	die) but once again the relative frequencies of each  outcome was close to 1/n (i.e. 1/6 for the regular die)
	as the number of rolls increased.</p>
	<p>In general, this suggests a rule: if there are n outcomes and each one has the same
	chance of occurring on a given trial then on average on a large number of trials the relative
	frequency of that outcome is 1/n.
	In general, if a number of outcomes are "equally likely" then this is a good model for measuring
	the proportion of outcomes that would be expected to have any given outcome. However, it is not
	always true that outcomes are equally likely. Consider rolling two die and measuring their sum:</p>


<sage>
<title>Rolling Two Dice and Measuring their Sum</title>
<input>
@interact
def _(num_rolls = slider([20..5000],label='Number of rolls'),num_sides = slider(4,20,1,6,label='Number of sides')):
    die = list((1..num_sides))
    dice = list((2..num_sides*2))
    rolls = [(choice(die),choice(die)) for roll in range(num_rolls)]
    sums = [sum(rolls[roll]) for roll in range(num_rolls)]
    show(rolls)   

    freq = [sums.count(outcome) for outcome in set(dice)]  # count the numbers for each outcome
    print 'The frequencies of each outcome is '+str(freq)
    
    print 'The relative frequencies of each outcome:'
    rel_freq = [freq[outcome-2]/num_rolls for outcome in set(dice)]  # make frequencies relative
    print rel_freq        
    show(bar_chart(freq,axes=False,ymin=0))     #  A histogram of the results
    print "Relative Frequence of ",dice[0]," is about ",rel_freq[0].n(digits=4)
    print "Relative Frequence of ",dice[num_sides-1]," is about ",rel_freq[num_sides-1].n(digits=4)

</input>
</sage>


	<p>Notice, not only are the answers not the same but they are not even close. To understand why this 
	is different from the examples before, consider the possible outcomes from each pair of die. Since we
	are measuring the sum of the dice then (for a pair of standard 6-sided dice) the possible sums are from 
	2 to 12. However, there is only one way to get a 2--namely from a (1,1) pair--while there are 6 ways to get
	a 7--namely from the pairs (1,6), (2,5), (3,4), (4,3), (5,2), and (6,1). So it might make some sense
	that the likelihood of getting a 7 is 6 times larger than that of getting a 2. Check to see if that
	is the case with your experiment above.</p>
</section>

<section><title>Definition of Probability</title>
<subsection xml:id="ProbabilityDefns"><title>Motivating the Definition</title>
	<p>Using the ideas from our examples above, let's consider how we might formally define a way
	to measure the expectation from similar experiments.  Before doing so, we need a little notation:</p>

		<definition>
		<statement>The Cardinality of the set A is the number of elements in A. This will be denoted |A| (similar
		to the idea of frequency of an outcome noted earlier.) If a set has
		a infinite number of elements, then we will say it's cardinality is also infinite and 
		write |A| = <m>\infty</m></statement>
		</definition>
	
		<definition><title>Pairwise Disjoint Sets</title>
		<statement>
		<m> \{ A_1, A_2, ... , A_n \}</m> are pairwise disjoint provided <m>A_k \cap A_j = \emptyset</m> so long as <m>k \ne j</m>.
		</statement>
		</definition>
		
	
	<p>
	To model the behavior above, consider how we might create a definition for our expectation
	of a given outcome by following the ideas uncovered above. To do so, first consider a desired collection
	of outcomes A. If each outcome in A is equally likely then we might follow the concept behind relative 
	frequency and consider a measure of expectation be |A|/|S|. Indeed, on a standard 
	6-sided die, the expectation of the outcome A={2} from the collection S = {1,2,3,4,5,6} should be
	|A|/|S| = 1/6.</p>
	<p>From the example where we take the sum of two die, the outcome A={4,5} from the
	collection S = {2,3,4,...,12} would be</p>
	<md>
		<mrow>|A| = | {(1,3),(2,2),(3,1),(1,4),(2,3),(3,2),(4,1)}| = 7</mrow>
		<mrow>|S| = | {(1,1),...,(1,6),(2,1),...,(2,6),...,(6,1),...,(6,6)}| = 36</mrow>
	</md>
	<p>and so the expected relative frequency would be |A|/|S| = 7/36. Compare this theoretical value
	with the sum of the two outcomes from your experiment above.</p>
				
	<p>We are ready to now formally give a name to the theoretical measure of expectation for
	outcomes from an experiment. Taking our cue from the ideas related to equally likely outcomes, we 
	make our definition have the following basic properties:</p>
	<ol>
		<li>Relative frequency cannot be negative, since cardinality cannot be negative</li>
		<li>Relative frequencies for disjoint events should sum to one</li>
		<li>Relative frequencies for collections of disjoint outcomes should equal the sum of the
	individual relative frequencies</li>
	</ol>
</subsection>
<subsection><title>Probability</title>
	<p>Based upon these we give the following:</p>
	<definition xml:id="DefnProb">
		<statement>The probability P(A) of a given outcome A is a set function which satisfies:
		<ol>
			<li>(Nonnegativity) P(A) <m>\ge 0</m></li>
			<li>(Totality) P(S) = 1</li>
			<li>(Subadditivity) If A <m>\cap</m> B = <m>\emptyset</m>, then P(A <m>\cup</m> B) = P(A) + P(B).  
			In general, if {<m>A_k</m>} are pairwise disjoint then <m>P( \cup_k A_k) = \sum_k P(A_k)</m>.</li>
		</ol>
		</statement>
	</definition>
</subsection>
	
<subsection xml:id="BasicProbabilityTheorems"><title>Basic Probability Theorems</title>
	<p>Based upon this definition we can immediately establish a number of results.</p>
	<theorem xml:id="ProbabilityComplemnts"><title>Probability of Complements</title>
		<statement> For any event A, <m>P(A) + P(A^c) = 1</m>
		</statement>
		<proof>
			<p>Let A be any event and note that <m>A \cap A^c = \emptyset</m>.  But <m>A \cup A^c = S</m>.
			So, by subadditivity <m>1 = P(S) = P(A \cup A^c) = P(A) + P(A^c)</m> as desired.</p>
		</proof>
	</theorem>
	<theorem xml:id="ProbabilityEmptySet">
		<statement><m>P(\emptyset) = 0</m>
		</statement>
		<proof>
			<p>Note that <m>\emptyset^c = S</m>. So, by the theorem above, 
			<m>1 = P(S) + P(\emptyset) \Rightarrow 1 = 1 + P(\emptyset)</m>.
			Cancelling the 1 on both sides gives <m>P(\emptyset) = 0</m>. </p>
		</proof>
	</theorem>
	<theorem xml:id="ProbabilityContainment">
		<statement>For events A and B with <m> A \subset B, P(A) \le P(B)</m>.
		</statement>
		<proof>
			<p>Assume sets A and B satisfy <m> A \subset B</m>. Then, notice that
			<m>A \cap (B-A) = \emptyset</m> and  <m>B = A \cup (B-A)</m>. Therefore, by 
			subadditivity and nonnegativity</p>
			<md>
				<mrow>0 \le P(B-A)</mrow>
				<mrow>P(A) \le P(A) + P(B-A) </mrow>
				<mrow>P(A) \le P(B)</mrow>
			</md>
		</proof>
	</theorem>
	<theorem xml:id="ProbabilityLessThanOne">
		<statement>For any event A, <m>P(A) \le 1</m> 
		</statement>
		<proof>
			<p>Notice <m>A \subset S</m>. By the theorem above <m> P(A) \le P(S) = 1</m></p>
		</proof>
	</theorem>
	<theorem xml:id="ProbabilityTwoUnions">
		<statement>For any sets A and B, <m>P(A \cup B) = P(A) + P(B) - P(A \cap B)</m>
		</statement>
		<proof>
			<p>Notice that we can write <m>A \cup B</m> as the disjoint union</p>
			<md>
				<mrow>A \cup B = (A-B) \cup (A \cap B) \cup (B-A).</mrow>
			</md> 
			<p>We can also write disjointly</p>
			<md>
				<mrow>A = (A-B) \cup (A \cap B)</mrow>
				<mrow>B = (A \cap B) \cup (B-A)</mrow>
			</md>
			<p>Hence, </p>
			<md>
				<mrow>P(A) &amp; + P(B) - P(A \cap B) </mrow>
				<mrow>&amp; = [P(A-B) + P(A \cap B)] + [P(A \cap B) + P(B-A)] - P(A \cap B)</mrow>
				<mrow>&amp; = P(A-B) + P(A \cap B) + P(B-A)</mrow>
				<mrow>&amp; = P(A \cup B)</mrow>
			</md>
		</proof>
	</theorem>
	<p>This result can be extended to more that two sets using a property known as inclusion-exclusion. The
	following two theorems illustrate this property and are presented without proof.
	</p>
	<corollary xml:id="ProbabilityThreeUnions">
		<statement>
			For any sets A, B and C, 
			<md>
				<mrow>P(A \cup B \cup C) &amp; = P(A) + P(B) + P(C)</mrow> 
			   	<mrow>&amp; - P(A \cap B) - P(A \cap C) - P(B \cap C) </mrow>
			   	<mrow>&amp; + P(A \cap B \cap C)</mrow>
			</md>
		</statement>
	</corollary>
	<corollary xml:id="ProbabilityFourUnions">
		<statement>
			For any sets A, B, C and D, 
			<md>
				<mrow>P(A \cup B \cup C \cup D) &amp; = P(A) + P(B) + P(C) + P(D)</mrow>
			  	<mrow>&amp; - P(A \cap B) - P(A \cap C) - P(A \cap D)  - P(B \cap C) - P(B \cap D) - P(C \cap D)</mrow>
			  	<mrow>&amp; + P(A \cap B \cap C) + P(A \cap B \cap D) + P(A \cap C \cap D) + P(B \cap C \cap D)</mrow>
			  	<mrow>&amp; - P(A \cap B \cap C \cap D)</mrow>
			</md>
		</statement>
	</corollary>
	
</subsection>

<subsection><title>Equally Likely Outcomes</title>
<p>
Many times, you will be dealing with making selections from a sample space where each item in the space has an equal chance of being selected. This may happen (for example) when items in the sample space are of equal size or when selecting a card from a completely shuffled deck or when coins are flipped or when a normal fair die is rolled. 
</p>
<p>It is important to notice that not all outcomes are equally likely--even in times when there are only two of them. Indeed, it is generally not an equally likely situation when picking the winner of a football game which pits, say, the New Orleans Saints professional football team with the New Orleans Home School Saints. Even though there are only two options the probability of the professional team winning is much greater than the chances that the high school will prevail. 
</p>
<p>
When items are equally likely (sometimes also called "randomly selected") then each individual event has the same chance of being selected as any other. In this instance, determining the probability of a collection of outcomes is relatively simple.
</p>
<theorem><title>Probability of Equally Likely Events</title>
<statement>If outcomes in S are equally likely, then for <m>A \subset S, P(A) = \frac{|A|}{|S|}</m> </statement>
<proof>
<p>
Enumerate S = {<m>x_1, x_2, ..., x_{|S|}</m>} and note <m>P( \{ x_k \} ) = c</m> for some constant c since each item is equally likely. However, using each outcome as a disjoint event and the definition of probability, 
<md>
	<mrow>1 = P(S) &amp; = P( \{ x_1 \} \cup \{x_2 \} \cup ... \cup \{x_{|S|} \} )</mrow>
	<mrow> &amp; = P(\{ x_1 \}) + P(\{ x_2 \} ) + ... + P(\{ x_{|S|} \} )</mrow>
	<mrow> &amp; = c + c + ... + c = {|S|} \times c</mrow>
</md>
and so <m>c = \frac{1}{{|S|}}</m>. Therefore, <m>P( \{ x_k \} ) = \frac{1}{|S|}</m> .
</p>
<p>
Hence, with A = {<m>a_1, a_2, ..., a_{|A|}</m>}, breaking up the disjoint probabilities as above gives
<md>
	<mrow>P(A) &amp; = P( \{ a_1 \} \cup \{ a_2 \} \cup ... \cup \{ a_{|A|} \} )</mrow>
	<mrow> &amp; = P(\{ a_1 \}) + P(\{ a_2 \} ) + ... + P(\{ a_{|A|} \} )</mrow>
	<mrow> &amp; = \frac{1}{{|S|}} + \frac{1}{{|S|}} + ... + \frac{1}{{|S|}}</mrow>
	<mrow> &amp; = \frac{|A|}{{|S|}}</mrow>
</md>
as desired.
</p>
</proof>
</theorem>
</subsection>

<subsection><title>Exercises</title>
<homework>
<p>
HOMEWORK: Determine the probabilities associated with the various 5-card hands.
</p>

<p>
HOMEWORK: Determine the 36 possible outcomes related to the rolling a pair of fair dice. Justify why each of these outcomes is equally likely. Determine the probabilities associated with each possible sum.
</p>

<p>
HOMEWORK: Suppose you have one die which only has three possible sides labeled 1, 2, or 3. Suppose a second die has twelve equally likely sides with labels 1,2,3,4,4,5,5,6,6,7,8,9.  Justify that the probabilities associate with each possible sum is the same as the probabilities when using two normal 6-sided dice.
</p>


<p>
HOMEWORK: Analyze the game of
<url href="http://mathworld.wolfram.com/Craps.html">"craps"</url>.
</p>
</homework>
</subsection>

</section>

<section>
<title>Conditional Probability</title>

	
	<p><title>Changing Sample Space - Balls:</title>  Consider a box with three balls: one Red, one White, and one Blue.  Using an equally likely assumption, the probability of randomly pulling out a Red ball should be 1/3.  That is P(Red) = 1/3.  However, suppose that for a first trial you pull out the White ball and set it aside. Attempting to pull out another ball leaves you with only two options and so the probability of randomly pulling out a Red ball is 1/2. Notice that the probability changed for the second trial dependent on the outcome of the first trial.</p>


	<p><title>Changing Sample Space - Cards: </title>
	Consider a deck of 52 standard playing cards and a success occurs when a Heart is selected from the deck. When extracting one card randomly, the probability	of that card being a Heart is then P(Heart) = 13/52. Now, assume that one card has already been extracted and setaside.  Now, prepare to extract another. If the first card drawn was a Heart, then there are only 12 Hearts left for the second draw. However, if the first card drawn was not a Heart, then there are 13 Hearts available for the second draw. To compute this probability correctly, one need to formulate the question so that subadditivity can  be utilized.</p>
	<p>
	To do this, consider 
	P(Heart on 2nd draw) 
	= P( [Heart on 1st draw <m>\cap</m> Heart on 2nd draw] <m>\cup</m> [Not Heart on 1st draw <m>\cap</m> Heart on 2nd draw] )
	= P(Heart on 1st draw <m>\cap</m> Heart on 2nd draw ) + P(Not Heart on 1st draw <m>\cap</m> Heart on 2nd draw )
	= | Heart on 1st draw <m>\cap</m> Heart on 2nd draw | / | Number of ways to get two cards |
	+ | Not Heart on 1st draw <m>\cap</m> Heart on 2nd draw / | Number of ways to get two cards |
	= (13 12) / (52 51) + (39 13) / (52 51) = 12 / (4 51) + (3 13) / ( 4 51) =  

	</p>
	
	<definition>
		<title>Conditional Probability</title>
			<statement>P(B | A) = P(A <m>\cap</m> B) / P(A), provided P(A)<m>\gt 0</m>.</statement>
		</definition>
		<theorem>
		<statement>Conditional Probability satisfies all of the requirements of regular probability.</statement>
		<proof>
		<p>
		By definition, for any event probability must be nonnegative. Therefore
		<m>P(A \cap B) \ge 0</m>.  Therefore, P(B | A) <m>\ge 0</m>.
		</p>
		<p>
		Further, P (S | A) = P(A <m>\cap</m> S)/P(A) = P(A)/P(A) = 1.
		</p>
		</proof>
		</theorem>
		
		<theorem><title>Multiplication Rule</title>
		<statement>
			<me>P(A \cap B) = P(A) P(B | A) = P(B) P(A | B)</me>
		</statement>
		<proof>
		<p>
		Unravel the definition of conditional probably by taking the denominator to the other side. Also note that you can write <m>A \cap B = B \cap A</m>.
		</p>
		</proof>
		</theorem>
	</section>
	
	
	
	<section><title>Bayes Theorem</title>	
	
		<theorem>
		<title>Bayes Theorem</title>
		<statement>Let <m>S = \{ S_1, S_2, ... , S_m \}</m> where the <m>S_k</m> are pairwise disjoint and <m>S_1 \cup S_2 \cup ... \cup S_m = S</m> (i.e. a partition of the space S).  Then for any <m>A \subset S</m>
		<md>
			<mrow>P(S_j | A) = \frac{P(S_j)P(A | S_j)}{\sum_{k=1}^m P(S_k)P(A | S_k)}.</mrow>
		</md>
		The conditional probability <m>P(S_j | A)</m> is called the posterior probability of <m>S_k</m>.
		</statement>
		<proof>
		<p>
		Notice, by the definition of conditional probability and the multiplication rule
		<me>P(S_j | A) = \frac{P(S_j \cap A)}{P(A)} = \frac{P(S_j)P( A | S_j)}{P(A)}.</me>
		But using the disjointness of the partition 
		<md>
		<mrow>P(A) &amp; = P( (A \cap S_1) \cup (A \cup S_2) \cup ... \cup (A \cup S_m) )</mrow>
		<mrow>    &amp; = P(A \cap S_1) + P(A \cup S_2) + ... + P(A \cup S_m)</mrow>
		<mrow>    &amp; = P(S_1 \cap A) + P(S_2 \cup A) + ... + P(S_m \cup A)</mrow>
		<mrow>    &amp; = P(S_1) P(A | S_1) + P(S_2)P(A | S_2) + ... + P(S_m)P(A | S_m)</mrow>
		<mrow>    &amp; = \sum_{k=1}^m P(S_k)P(A | S_k)</mrow>
		</md>
		Put these two expansions together to obtain the desired result.
		</p>
		</proof>
		</theorem>
	
	
<p>
To illustrate this result, from the web site <url href="http://stattrek.com/probability/bayes-theorem.aspx"></url> consider the following problem:
</p>
<p>
Marie is getting married tomorrow, at an outdoor ceremony in the desert. In recent years, it has rained only 5 days each year. Unfortunately, the weatherman has predicted rain for tomorrow. When it actually rains, the weatherman correctly forecasts rain 90% of the time. When it doesn't rain, he incorrectly forecasts rain 10% of the time. What is the probability that it will rain on the day of Marie's wedding?
</p>
<p>
Notice, all days can be classified into one of two disjoint options:
<ul>
	<li>Rainy, in which case we can deduce from the given info that P(Rain) = 5/365</li>
	<li>No Rainy, and since this is the complement of above, P(No Rain) = 360/365</li>
</ul>
In the notation of Bayes Theorem, let A represent a forecast of Rain and note you have <m>P(\text{Rain}) = P(S_1) = \frac{5}{365}</m> and <m>P(\text{No Rain}) = \frac{360}{365}</m>. Further, you are given the conditional probabilities
<ul>
	<li><m>P(\text{Rain | Forecast Rain}) = P( A | S_1) = 0.9</m></li>
	<li><m>P(\text{Rain | Forecast Rain}) = P( A | S_2) = 0.1</m></li>
</ul>
Notice that the question provided requests that you find the probability of Rain given that the weatherman has forecasted rain. What is given on the other hand is the reverse of that conditional probability. Using Bayes Theorem allows you to turn this around...
<md>
	<mrow>P(\text{Rain}) &amp;  = P(S_1) P( A | S_1) + P(S_2) P(A | S_2)</mrow>	
	<mrow> &amp; = \frac{5}{365} \cdot 0.9 + \frac{360}{365} \cdot 0.1</mrow>
	<mrow> &amp; = NUMBER </mrow>
</md>
Hence, putting these together gives
<md>
	<mrow>P(\text{Rain | Forecast Rain}) &amp; = \frac{\frac{5}{365} \cdot 0.9}{\frac{5}{365} \cdot 0.9 + \frac{360}{365} \cdot 0.1}</mrow>
	<mrow> &amp; = \frac{5 \cdot 0.9}{5 \cdot 0.9 + 360 \cdot 0.1}</mrow>
	<mrow> &amp; = \frac{45}{45+360} \approx 0.111</mrow>
</md>
So, normally there is only a 5 percent chance of rain on a given day but given that the weatherman has forecast rain, the chance of rain has risen to a little more than 11 percent.
</p>	
	
<sage>
<input>

#  This function is used to convert an input string into separate entries
def g(s): return str(s).replace(',',' ').replace('(',' ').replace(')',' ').split()

@interact
def _(Partition_Probabilities=input_box('0.35,0.25,0.40',label="$P(B_1),P(B_2),...$"),
        Conditional_Probabilities=input_box('0.02,0.01,0.03',label='$P(A|B_1),P(A|B_2),...$'),
        print_numbers=checkbox(True,label='Numerical Results on Graphs?'),
        auto_update=False):
            
    Partition_Probabilities = g(Partition_Probabilities)
    Conditional_Probabilities = g(Conditional_Probabilities)
    n = len(Partition_Probabilities)
    n0 = len(Conditional_Probabilities)
    
    # below needs to be n not equal to n0 but mathbook xml will not let me get the other
    if (n > n0):
        pretty_print("You must have the same number of partition probabilities and conditional probabilities.")
        
    else:                               # input data streams now are the same size!
        colors = rainbow(n)
        accum = float(0)                # to test whether partition probs sum to one
        ends = [0]                      # where the graphed partition sectors change in pie chart 
        mid = []                        # middle of each pie chart sector used for placement of text
        p_Bk_given_A = []               # P( B_k | A )
        pA = 0                          # P(A)
        PP=[]                           # array to hold the numerical Partition Probabilities 
        CP=[]                           # array to hold the numerical Conditional Probabilities     
        for k in range(n):
            PP.append(float(Partition_Probabilities[k]))
            CP.append(float(Conditional_Probabilities[k]))    
            p_Bk_given_A.append(PP[k]*CP[k] )
            pA += p_Bk_given_A[k]
            accum = accum + PP[k]
            ends.append(accum)
            mid.append((ends[k]+accum)/2)
#
#  Marching along from 0 to 1, saving angles for each partition sector boundary.
#  Later, we will multiple these by 2*pi to get actual sector boundary angles.
#
        if abs(accum-float(1))>0.0000001:     #  Due to roundoff issues, this should be close enough.                     
            pretty_print("Sum of probabilities should equal 1.")
        
        else:                           # probability data is sensible
 
#        
#  Draw the Venn diagram by drawing sectors from the angles determined above
#  First, create a circle of radius 1 to illustrate the the sample space S
#  Then draw each sector with varying colors and print out their names on the edge
#
            G = circle((0,0), 1, rgbcolor='black',fill=False, alpha=0.4,aspect_ratio=True,axes=False,thickness=5)
            for k in range(n):
                G += disk((0,0), 1, (ends[k]*2*pi, ends[k+1]*2*pi), color=colors[mod(k,10)],alpha = 0.2)
                G += text('$B_'+str(k+1)+'$',(1.1*cos(mid[k]*2*pi), 1.1*sin(mid[k]*2*pi)), rgbcolor='black')
                
            G += circle((0,0), 0.6, facecolor='yellow', fill = True, alpha = 0.1, thickness=5,edgecolor='black') 
    
#  Print the probabilities corresponding to each particular region as a list and on the graphs
            if print_numbers:               

                html("$P(A) = %s$"%(str(pA),))
                for k in range(n):
                    html("$P(B_{%s} | A)$"%(str(k+1))+"$ = %s$"%str(p_Bk_given_A[k]/pA))
                                        
                    G += text(str(p_Bk_given_A[k]),(0.4*cos(mid[k]*2*pi), 0.4*sin(mid[k]*2*pi)), rgbcolor='black')
                    G += text(str(PP[k] - p_Bk_given_A[k]),(0.8*cos(mid[k]*2*pi), 0.8*sin(mid[k]*2*pi)), rgbcolor='black')
        
#  This is essentially a repeat of some of the above code but focused only on creating the smaller inner circle dealing
#  with the set A so that the sectors now correspond in area to the Bayes Theorem probabilities


            accum = float(0)                        
            ends = [0]                     # where the graphed partition sectors change in pie chart 
            mid = []                       # middle of each pie chart sector used for placement of text
            for k in range(n): 
                accum += float(p_Bk_given_A[k]/pA) 
                ends.append(accum)
                mid.append((ends[k]+accum)/2)
            H = circle((0,0), 1, rgbcolor='black',fill=False, alpha=0,aspect_ratio=True,axes=False,thickness=0)
            H += circle((0,0), 0.6, facecolor='yellow',fill=True, alpha=0.1,aspect_ratio=True,axes=False,thickness=5,edgecolor='black')
            
            for k in range(n):
                H += disk((0,0), 0.6, (ends[k]*2*pi, ends[k+1]*2*pi), color=colors[mod(k,10)],alpha = 0.2)
                H += text('$B_'+str(k+1)+'|A$',(0.7*cos(mid[k]*2*pi), 0.7*sin(mid[k]*2*pi)), rgbcolor='black')
                    
        #  Now, print out the bayesian probabilities using the smaller set A only
    
            if print_numbers:
                for k in range(n):
                    H += text(str( N(p_Bk_given_A[k]/pA,digits=4) ),(0.4*cos(mid[k]*2*pi), 0.4*sin(mid[k]*2*pi)), rgbcolor='black')
                    
            G.show(title='Venn diagram of partition with A in middle')
            print
            H.show(title='Venn diagram presuming A has occured')
</input>
</sage>

<homework>

</homework>

</section>

<section>
<title>Independence</title>
	<definition>
	<title>Independent Events</title>
	<statement>Events A and B are independent provided <m>P(A \cap B) = P(A) P(B)</m>
	</statement>
	</definition>
</section>

<section><title>Random Variables</title>
	<p>For a given set of events, we might have difficulty doing mathematics since the outcomes
	are not numerical. In order to accomodate our desire to convert to numerical measures we want
	to assign numerical values to all outcomes. The process of doing this creates what is known as a random
	variable.
	</p>

	<definition>
	<title>Random Variable</title>
		<statement>Given a random experiment with sample space S, a function X mapping each 
		element of S to a unique real number is called a random variable. 
		For each element s from the sample space S, denote this function by
		X(s) = x
		and call the range of X the space of X: R={ x : X(s)=x, for some s in S} 
		</statement>
	</definition>

	<p>We will make various restrictions on the range of the random variable to fit different 
	generalized problems. Then, we will be able to work on a problem (which may be 
	inherently non-numerical) by using the random variable in subsequent calculations.
	</p>
	<example>
	<title>Success vs Failure</title>
	<p>When dealing with only two outcomes, one might use S = { success, failure}.
	Choose X(success)=1, X(failure)=0. Then, R={0,1}.</p>
	</example>
	<example>
	<title>Standard Dice Pairs</title>
	<p>When gambling with a pair of dice, one might use
	S=ordered pairs of all possible rolls = {(a,b): a=die 1 outcome, b=die 2 outcome}.
	Choose X( (a,b) ) = a+b. Then, R={2, 3, 4, 5, ..., 12}.</p>
	</example>
	<example>
	<title>Other Dice Options</title>
	<p>When rolling dice in a board game (like RISK), one might use
	S={(a,b): a=die 1 outcome, b=die 2 outcome}
	Choose X( (a,b) ) = max{a,b}. Then, R={1, 2, 3, 4, 5, 6}
	</p>
	</example>

	<definition>
		<statement>
		R contains a countable number of points if either R is finite or there 
		is a one to one correspondence between R and the positive integers. 
		Such a set will be called discrete. We will see that often the set R is not countable. 
		If R consists of an interval of points (or a union of intervals), 
		then we call X a continuous random variable. 
		</statement>
	</definition>


<image source="images/randomvariable.png" />

</section>


<section xml:id="ProbabilityFunctions"><title>Probability Functions</title>
	<p>In the formulas below, we will presume that we have a random variable X which maps the sample space S onto some range of real numbers R.  From this set, we then can define a probability function f(x) which acts on the numerical values in R and returns another real number.  We attempt to do so to obtain (for discrete values) P(sample space value s)<m> = f(X(s))</m>.  That is, the probability of a given outcome s is equal to the composition which takes s to a numerical value x which is then plugged into f to get the same final values.</p>

	<definition><title>Probability Mass Function</title>
		<statement>Given a discrete random variable X on a space R, a probability mass function on X is given by a function <m>f:R \rightarrow \mathbb{R}</m> such that:
		<md>
			<mrow>&amp; \forall x \in R , f(x) \gt 0</mrow>
			<mrow>&amp; \sum_{x \in R} f(x) = 1</mrow>
			<mrow>&amp; A \subset R \Rightarrow P(X \in A) = \sum_{x \in A}f(x)</mrow>
		</md>
		</statement>
	</definition>
	
	<definition><title>Probability Density Function</title>
		<statement>Given a continuous random variable X on a space R, a probability density function on X is given by a function <m>f:R \rightarrow \mathbb{R}</m> such that:
			<md>
				<mrow>&amp; \forall x \in R , f(x) \gt 0</mrow>
				<mrow>&amp; \int_{R} f(x) = 1</mrow>
				<mrow>&amp; A \subset R \Rightarrow P(X \in A) = \int_{A} f(x) dx</mrow>
			</md>
		</statement>
	</definition>
	
	<example>
	<title>Discrete Probability Function</title>
	<p>
	Consider <m>f(x) = x/10</m> over R = {1,2,3,4}.  Then, f(x) is obviously positive for each of the values in R and certainly <m>\sum_{x \in R} f(x) = f(1) + f(2) + f(3) + f(4) = 1/10 + 2/10 + 3/10 + 4/10 = 1</m>. Therefore, f(x) is a probability mass function over the space R.
	</p>
	</example>
	
<sage><title>Sampling Discrete Probability Function</title>
	<input>
# Combining all of the above into one interactive cell
@interact
def _(D = input_box([1,2,3,5,6,8,9,11,12,14],label="Enter domain R (in brackets):"), 
       Probs = input_box([1/20,1/20,1/20,3/20,1/20,4/20,4/20,1/20,1/20,3/20],label="Enter corresponding f(x) (in brackets):"),
       n_samples=slider(100,10000,100,100,label="Number of times to sample from this distribution:")):
    n = len(D)
    R = range(n)
    one_huh = sum(Probs)
    pretty_print('\n\nJust to be certain, we should check to make certain the probabilities sum to 1\n')
    pretty_print(html('<center>$\sum_{x\epsilon R} f(x) = %s$</center>'%str(one_huh)))
    
    G = Graphics()
    if len(D)==len(Probs):
        f = zip(D,Probs)
        meanf = 0
        variancef = 0
        for k in R:
            meanf += D[k]*Probs[k]
            variancef += D[k]^2*Probs[k]
            G += line([(D[k],0),(D[k],Probs[k])],color='green')
        variancef = variancef - meanf^2
        sd = sqrt(variancef)
        G += points(f,color='blue',size=50)
        G += point((meanf,0),color='yellow',size=60,zorder=3)
        G += line([(meanf-sd,0),(meanf+sd,0)],color='red',thickness=5)
    
        g = DiscreteProbabilitySpace(D,Probs)
        pretty_print('     mean = %s'%str(meanf))
        pretty_print(' variance = %s'%str(variancef))
    
        #  perhaps to add mean and variance for pmf here
    else:
        print 'Domain D and Probabilities Probs must be lists of the same size'
    
    #  Now, let's sample from the distribution given above and see how a random sampling matches up

    counts = [0] * len(Probs)
    X = GeneralDiscreteDistribution(Probs)
    sample = []

    for _ in range(n_samples):
        elem = X.get_random_element()
        sample.append(D[elem])
        counts[elem] += 1
    Empirical = [1.0*x/n_samples for x in counts] # random
    
    samplemean = mean(sample)
    samplevariance = variance(sample)
    sampdev = sqrt(samplevariance)
    
    E = points(zip(D,Empirical),color='orange',size=40)
    E += point((samplemean,0.005),color='brown',size=60,zorder=3)
    E += line([(samplemean-sampdev,0.005),(samplemean+sampdev,0.005)],color='orange',thickness=5)    
    (G+E).show(ymin=0,figsize=(8,5))	
	</input>
</sage>

	<example>
	<title>Continuous Probability Function</title>
	<p>
	Consider <m>f(x) = x^2/c</m> for some positive real number c and presume R = [-1,2]. Then f(x) is nonnegative (and only equals zero at one point). To make f(x) a probability density function, we must have
	<me>\int_{x \in R} f(x) = 1.</me>
	In this instance you get
	<me>1 = \int_{-1}^2 x^2/c = x^3/(3c) |_{-1}^2 = \frac{8}{3c} - \frac{-1}{3c} = \frac{3}{c}</me>
	Therefore, f(x) is a probability density function over R provided   = 3.
	</p>
	</example>
	
	<definition><title>Distribution Function</title>
		<statement>Given a random variable X on a space R, a probability distribution function on X is given by a function 
				   <m>F:\mathbb{R} \rightarrow \mathbb{R}</m> such that <m>\displaystyle F(x)=P(X \le x)</m>
		</statement>
	</definition>
	
	<example>
	<title>Discrete Distribution Function</title>
	<p>Using <m>f(x) = x/10</m> over R = {1,2,3,4} again, note that F(x) will only change at these four domain values. We get
	
	<table halign="left">
      	<tabular halign="right">
      
<row><cell bottom="medium">X</cell><cell bottom="medium">F(x)</cell></row>      
<row><cell><m>x \lt 1</m></cell><cell>0</cell></row>
<row><cell><m>1 \le x \lt 2</m></cell><cell>1/10</cell></row>
<row><cell><m>2 \le x \lt 3</m></cell><cell>3/10</cell></row>
<row><cell><m>3 \le x \lt 4</m></cell><cell>6/10</cell></row>
<row><cell><m>4 \le x </m></cell><cell>1</cell></row>
		</tabular>
	</table>
	</p>
	</example>
	
	<example>
	<title>Continuous Distribution Function</title>
	<p>
	Consider <m>f(x) = x^2/3</m> over R = [-1,2].  Then, for <m>-1 \le x \le 2</m>,
	<me>F(x) = \int_{-1}^x u^2/3 du = x^3/9 + 1/9.</me>
	Notice, F(-1) = 0 since nothing has yet been accumulated over values smaller than -1 and F(2)=1 since by that time everything has been accumulated. In summary:
	
	<table halign="left">
      	<tabular halign="right">
      
<row><cell bottom="medium">X</cell><cell bottom="medium">F(x)</cell></row>      
<row><cell><m>x \lt -1</m></cell><cell>0</cell></row>
<row><cell><m>-1 \le x \lt 2</m></cell><cell><m>x^3/9 + 1/9</m></cell></row>
<row><cell><m>2 \le x</m></cell><cell>1</cell></row>
	
		</tabular>
	</table>
	
	
	</p>
	</example>
</section>	
<section><title>Properties of the Distribution Function</title>
		
		<theorem xml:id="theorem-Fmin">
			<statement><m>F(x)=0, \forall x \le \inf(R)</m></statement>
			<proof>TBA</proof>
		</theorem>
		
		<theorem xml:id="theorem-Fmax">
			<statement><m>F(x)=1, \forall x \ge \sup(R)</m></statement>
			<proof>TBA</proof>
		</theorem>
		
		<theorem>
			<statement xml:id="theorem-F-non-decreasing">F is non-decreasing</statement>
			<proof>
				<p>Case 1: R discrete</p>
				<md>
					<mrow>\forall x_1,x_2 \in \mathbb{Z} \ni x_1 \lt x_2</mrow>
					<mrow>F(x_2) &amp; = \sum_{x \le x_2} f(x) </mrow>
					<mrow>&amp; = \sum_{x \le x_1} f(x) + \sum_{x_1 \lt x \le x_2} f(x)</mrow>
					<mrow>&amp; \ge \sum_{x \le x_1} f(x) = F(x_1)</mrow>
				</md>
				<p>Case 2: R continuous</p>
				<md>
					<mrow>\forall x_1,x_2 \in \mathbb{R} \ni x_1 \lt x_2</mrow>
					<mrow>F(x_2) &amp; = \int_{-\infty}^{x_2} f(x) dx </mrow>
					<mrow> &amp; = \int_{-\infty}^{x_1} f(x) dx + \int_{x_1}^{x_2} f(x) dx</mrow>
					<mrow> &amp; \ge \int_{-\infty}^{x_1} f(x) dx</mrow>
					<mrow> &amp; = F(x_1)</mrow>
				</md>
			</proof>
		</theorem>
		
		<theorem xml:id="theorem-Fvsf-discrete">
			<title>Using Discrete Distribution Function to compute probabilities</title>
			<statement>for <m>x \in R, f(x) = F(x) - F(x-1)</m></statement>
		</theorem>
		
		<theorem xml:id="theorem-Fvsf-continuyous">
			<title>Using Continuous Distribution function to compute probabilities</title>
			<statement>for <m>a \lt b, (a,b) \in R, P(a \lt X \lt b) = F(b) - F(a)</m></statement>
		</theorem>
		
		<corollary xml:id="corollary-ProbPointZero-continuous">
			<statement>For continuous distributions, P(X = a) = 0</statement>
		</corollary>
		
</section>
	
<section>
		<title>Standard Units</title>
			<p>Any distribution variable can be converted to “standard units” using the linear translation 
			<m>\displaystyle z = \frac{x-\mu}{\sigma}</m>. In doing so, then values of z will always represent the number of
			standard deviations x is from the mean and will provide “dimensionless” comparisons.</p>
</section>    


<section><title>Expected Value</title>
	<p>Blaise Pascal was a 	17th century mathematician and philosopher who was accomplished in many areas but may likely be best known to you for his creation of what is now known as Pascal's Triangle. As part of his philosophical pursuits, he proposed what is known as "Pascal's wager". It suggests two  mutually exclusive outcomes: that God exists or that he does not. His argument is that a rational person should live as though God exists and seek to believe in God. If God does not actually exist, such a person will have only a finite loss (some pleasures, luxury, etc.), whereas they stand to receive infinite gains as represented by eternity in Heaven and avoid an infinite losses of eternity in Hell. This type of reasoning is part of what is known as "decision theory".
	</p>
	<p>You may not confront such dire payouts when making your daily decisions but we need a formal method for making these determinations precise. The procedure for doing so is what we call expected value.
	</p>
	<definition><title>Expected Value</title>
	<p>Given a random variable X over space R, corresponding probability function f(x) and "value function" u(x), the expected value of u(x) is given by
	<me>E = E[u(X)] = \sum_{x \in R} u(x) f(x)</me>
	provided X is discrete, or
	<me>E = E[u(X)] = \int_R u(x)f(x) dx</me>
	provided X is continuous.
	</p>
	</definition>
	
	<example><title>Discrete Expected Value</title>
	<p>Consider <m>f(x) = x/10</m> over R = {1,2,3,4} where the payout is 10 euros if x=1, 5 euros if x=2, 2 euros if x=3 and -7 euros if x = 4.  Then your value function would be u(1)=10, u(2) = 5, u(3)=2, and u(4) = -7. Computing the expect payout gives
	<me>E = 10 \times 1/10 + 5 \times 2/10 + 2 \times 3/10 - 7 \times 4/10 = -2/10</me>
	Therefore, the expected payout is actually negative due to a relatively large negative payout associated with the largest likelihood outcome and the larger positive payout only associated with the least likely outcome.
	</p>
	</example>
	
	<example><title>Continuous Expected Value</title>
	<p>
	Consider <m>f(x) = x^2/3</m> over R = [-1,2] with value function given by <m>u(x) = e^x - 1</m>. Then, the expected value for u(x) is given by
	<me>E = \int_{-1}^2 (e^x-1) \cdot x^2/3 = -1/9 \cdot (e + 15) \cdot e^{-1} + 2/3 \cdot e^2 - 8/9 \approx 3.3129</me>
	</p>
	</example>
	
	<p>So, going back to Pascal's wager, let X = 0 represent disbelief when God doesn't exist and X = 1 represent disbelief when God does exist, X = 2 represent belief when God does exist, and X = 3 represent belief when God does not exist. Let p be the likelihood that God exists. Then you can compute the expected value of disbelief and the expect value of belief by first creating a value function. Below, for argument sake we are somewhat randomly assign a value of one million to disbelief if God doesn't exist. The conclusions are the same if you choose any other finite number...
	<md>
		<mrow>u(0) = 1,000,000, f(0) = 1-p</mrow>
		<mrow>u(1) = -\infty, f(1) = p</mrow>
		<mrow>u(2) = \infty, f(2) = p</mrow>
		<mrow>u(3) = 0, f(3) = 1-p</mrow>
	</md>
	Then, 
	<md>
		<mrow>E[disbelief] &amp; = u(0)f(0) + u(1)f(1)</mrow>
		<mrow>&amp; = 1000000 \times (1-p) - \infty \times p</mrow>
		<mrow>&amp; = -\infty</mrow>
	</md>
	if p>0. On the other hand, 
	<md>
		<mrow>E[belief] &amp; = u(2)f(2) + u(3)f(3)</mrow>
		<mrow>&amp; = \infty \times p + 0 \times (1-p)</mrow>
		<mrow>&amp; = \infty</mrow>
	</md>
	if p>0. So Pascal's conclusion is that if there is even the slightest chance that God exists then belief is the smart and scientific choice.
	</p>

</section>



</chapter>