<?xml version="1.0" encoding="UTF-8"?>

<!-- This file is part of the documentation of MathBook XML   -->
<!--                                                          -->
<!--    MathBook XML Author's Guide                           -->
<!--                                                          -->
<!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
<!-- See the file COPYING for copying conditions.             -->

<chapter xml:id="UniformHypergeometric" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Uniform and Hypergeometric Distributions</title>
	<introduction>
	<p>
	When motivating our definition of probability you may have noticed that we modeled our definition on the relative frequency of equally-likely outcomes. In this chapter you will develop the theoretical formulas which can be used to model equally-likely outcomes.
	</p>
	</introduction>
<section>	
	<title>Discrete Uniform Distribution</title>
	<p>
	Assume that you have a variable with space R = {1, 2, 3, ..., n} so that the likelihood of each value is equally likely. Then, the probability function satisfies <m>f(x) = c</m> for any <m>x \in R</m>.  As before, since <m>\sum_{x \in R} f(x) = 1</m>, then <me>f(x) = \frac{1}{n}</me> is the probability function.
	</p>
	
	
<sage>
<input>
# Uniform distribution over 1 .. n
pretty_print("Discrete Uniform Distribution over the set 1, 2, ..., n")
var('x')
@interact
def _(n=slider(2,10,1,2)):
    np1 = n+1
    R = range(1,np1)
    f(x) = 1/n
    pretty_print(html('Density Function: $f(x) =%s$'%str(latex(f(x)))+' over the space $R = %s$'%str(R)))
    points((k,f(x=k)) for k in R).show()
    for k in R:
        pretty_print(html('$f(%s'%k+') = %s'%f(x=k)+' \\approx %s$'%f(x=k).n(digits=5)))

</input>
</sage>

	<theorem><title>Properties of the Discrete Uniform Probability Function</title>
	<statement>
	<ol>
		<li><m>f(x) = \frac{1}{n}</m> over R = {1, 2, 3, ..., n} satisfies the properties of a discrete probability function</li>
		<li><m>\mu = \frac{1+n}{2}</m></li>
		<li><m>\sigma^2 = \frac{n^2-1}{12}</m></li>
		<li><m>\gamma_1 = 0</m></li>
		<li><m>\gamma_2 = \frac{6}{5}\frac{1+n^2}{1-n^2}</m></li>
		<li>Distribution function F(x) = frac{x}{n} for <m>x \in R</m>.</li>
	</ol>
	</statement>
	<proof>
	<ol>
		<li>Trivially, by construction you get <me>\sum_{k=1}^n \frac{1}{n} = 1</me>
		Also, 1/n is positive for all x values.
		</li>
		<li>
		<p>To determine the mean,
		<md>
			<mrow>\mu &amp; = \sum_{k=1}^n x \cdot \frac{1}{n}</mrow>
			<mrow> &amp; = \frac{1}{n}\sum_{k=1}^n x </mrow>
			<mrow> &amp; = \frac{1}{n} \frac{n(n+1)}{2}</mrow>
			<mrow> &amp; = \frac{1+n}{2}</mrow>
		</md>
		</p>
		</li>
		<li>
		<p>To determine the variance,
		<md>
			<mrow>\sigma^2 &amp; = \sum_{k=1}^n x^2 \cdot \frac{1}{n} - \mu^2</mrow>
			<mrow> &amp; = \frac{1}{n}\sum_{k=1}^n x^2 - \left ( \frac{1+n}{2}\right )^2 </mrow>
			<mrow> &amp; = \frac{1}{n} \frac{n(n+1)(2n+1)}{6} - \frac{1+2n+n^2}{4}</mrow>
			<mrow> &amp; = \frac{(2n^2+3n+1)}{6} - \frac{1+2n+n^2}{4}</mrow>
			<mrow> &amp; = \frac{(4n^2+6n+2)}{12} - \frac{3+6n+3n^2}{12}</mrow>
			<mrow> &amp; = \frac{(n^2-1)}{12}</mrow>
		</md>
		</p>
		</li>
		
		<li>
		<p>For skewness,
		<md>
			<mrow>\gamma_1 = &amp; \sum_{k=1}^n x^3 \cdot \frac{1}{n} - 3 \mu \sum_{k=1}^n x^2 \cdot \frac{1}{n}  + 2\mu^3</mrow>
			<mrow> &amp; = \frac{n^2(n+1)^2}{4n} - 3\frac{(n(n+1))}{2} \frac{1+n}{2} + 2 \left ( \frac{1+n}{2}\right )^3 </mrow>
			<mrow> &amp; = </mrow>
		</md>
		</p>
		</li>
		<li>
		<p>For Kurtosis, use the fourth moment and simplify...the algebra is performed using Sage in the active cell below this proof.
		</p>
		</li>
		<li>

		</li>
	</ol>
	</proof>
	</theorem>
	<p>
	Sage can also do the algebra for you to determine each of these measures. Notice, as n increases the Kurtosis approaches <m>\frac{6}{5}</m> which indicates that there is (obviously) no tend toward central tendency over time.
	</p>
<sage>
	<input>
var('x,n')
f = 1/n
mu = sum(x*f,x,1,n).factor()
pretty_print('Mean = ',mu)
mu = (1+n)/2
v = sum((x-mu)^2*f, x, 1, n)
pretty_print('Variance = ',v.factor())
stand = sqrt(v)
pretty_print('Skewness =  ',(sum((x-mu)^3*f, x, 1, n)/stand^3))
kurt = sum((x-mu)^4*f, x, 1, n)/stand^4
pretty_print('Kurtosis = ',(kurt-3).factor(),' + 3')
	</input>
</sage>

<example><title>Rolling one die</title>
<p>When you consider rolling a regular, fair, single 6-sided die, each side is equally likely. The sample space consists of the 6 sides, each with a unique number of physical dots. Let the random variable X correspond each side with the number corresponding to the number of dots. Then, R = {1, 2, 3, 4, 5, 6}.  Since each side is equally likely then f(x) = 1/6.
</p>
<p>
Further, the probability of getting an outcome in A={2,3} would be f(2)+f(3) = 1/6 + 1/6 = 2/6.
</p>
</example>


</section>

<section>	
	<title>Continuous Uniform Distribution</title>
	<p>
	Modeling the idea of "equally-likely" in a continuous world requires a slightly different perspective since there are obviously infinitely many outcomes to consider. Instead, you should consider requiring that intervals in the domain which are of equal width should have the same probability regardless of where they are in that domain. This behaviour suggests <m>P(u \lt X \lt v) = P(u + w \lt X \lt v + w)</m>.  In integral notation you obtain the following:
	<md>
		<mrow>\int_u^v f(x) dx = \int_{u+w}^{v+w} f(x) dx</mrow>
		<mrow>F(v)-F(u) = F(v+w)-F(u+w)</mrow>
		<mrow>F(u+w)-F(u) = F(v+w)-F(v)</mrow>
	</md>
	which is true regardless of w so long as you stay in the domain of interest. This only happens if F is linear and therefore f must be constant. Say, f(x)=c. In many situations, the space of X will be a single interval with R = [a,b]. Unless otherwise noted, this will be our assumption as well.
	</p>
	
	<theorem><title>Properties of the Continuous Uniform Probability Function</title>
	<statement>
	<ol>
		<li><m>f(x) = \frac{1}{b-a}</m> satisfies the properties of a probability function over R = [a,b].</li>
		<li><m>\mu = \frac{a+b}{2}</m></li>
		<li><m>\sigma^2 = \frac{b^2-a^2}{12}</m></li>
		<li><m>\gamma_1 = 0</m></li>
		<li><m>\gamma_2 = \frac{9 \, {\left(a^{5} - 5 \, a^{4} b + 10 \, a^{3} b^{2} - 10 \, a^{2} b^{3} + 5 \, a b^{4} - b^{5}\right)} {\left(a - b\right)}}{5 \, {\left(a^{3} - 3 \, a^{2} b + 3 \, a b^{2} - b^{3}\right)}^{2}}</m>
		</li>
	</ol>
	</statement>
	</theorem>
	
<sage>
<input>
# Continous uniform distribution statistics derivation
reset()
var('x,a,b')


f = 1/(b-a)

mu = integrate(x*f,x,a,b).factor()
pretty_print('Mean = ',mu)

v = integrate((x-mu)^2*f, x, a, b)

pretty_print('Variance = ',v.factor())
stand = sqrt(v)
sk = (integrate((x-mu)^3*f, x, a, b)/stand^3)
pretty_print('Skewness =  ',sk)
kurt = (integrate((x-mu)^4*f, x, a, b)/stand^4)
pretty_print('Kurtosis = ',kurt)

pretty_print('Several Examples')
a1=0
for b1 in range(2,7):
    pretty_print('Using [',a1,',',b1,']:')
    pretty_print('    mean = ',mu(a=a1,b=b1))
    pretty_print('variance = ',v(a=a1,b=b1))
    pretty_print('skewness = ',sk(a=a1,b=b1))
    pretty_print('kurtosis = ',kurt(a=a1,b=b1))
</input>
</sage>

<example><title>Occurence of exactly one event randomly in a given interval</title>
<p>
Suppose you know that only one person showed up at the counter of a local business in a given 30 minute interval of time. Then, R=[0,30] given f(x) = 1/30.
</p>
<p>
Further, the probability that the person arrived within the first 6 minutes would be <m>\int_0^6 \frac{1}{30} dx = 0.2</m>.
</p>
</example>

<theorem><title>Distribution Function for Continuous Uniform</title>
<statement> For <m>x \in [a,b], F(x) = \frac{x-a}{b-a}</m></statement>
<proof>
<p>
For x in this range, 
<me>F(x) = \int_a^x \frac{1}{b-a} du = \frac{u}{b-a} \big |_a^x = \frac{x-a}{b-a}.</me>
</p>
</proof>
</theorem>

</section>


<section>	
	<title>Hypergeometric Distribution</title>
	
	<p>
	For the discrete uniform distribution, the presumption is that you will be making a selection one time from the collection of items. However, if you want to take a larger sample without replacement from a distribution in which originally all are equally likely then you will end up with something which will not be uniform.</p>
	<p>
	Indeed, consider a collection of n items from which you want to take a sample of size r without replacement. If <m>n_1</m> of the items are "desired" and the remainder are not, let the random variable X measure the number of items from the first group in your sample. The resulting collection of probabilities is called a Hypergeometric Distribution.
	</p>
	<p>
	Since you are sampling without replacement and trying only measure the number of items from your desired group in the sample, then the space of X will include R = {0, 1, ..., r} assuming <m>n_1 \ge r</m> and <m>n-n_1 \ge r</m>. In the case when r is too large for either of these, the formulas below will follow noting that binomial coefficients are zero if the top is smaller than the bottom or if the bottom is negative.
	</p>
	<p>
	So f(x) = P(X = x) = P(x from the sample are from the target group and the remainder are not). Breaking these up gives
	<me>f(x) = \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}}</me>
	</p>
	
	<theorem><title>Properties of the Hypergeometric Distribution</title>
	<statement>
	<ol>
		<li><m>f(x) = \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}}</m> satisfies the properties of a probability function.</li>
		<li><m>\mu = r \frac{n_1}{n}</m></li>
		<li><m>\sigma^2 = r \frac{n_1}{n} \frac{n_2}{n} \frac{n-r}{n-1}</m></li>
		<li><m>\gamma_1 = \frac{(n - 2 n_1)\sqrt{n-1}(n - 2r)}{r n_1 (n - n_1) \sqrt{n-r}(n-2)}</m></li>
		<li><m>\gamma_2 = \frac{n(n+1)-6n(n-r)}{n_1(n-n_1)} + \frac{3r(n-r)(n+6)}{n^2} - 6</m></li>
	</ol>

	</statement>
	<proof>
	<ol>
		<li>
			<p>		
			<md>
				<mrow>\sum_{x=0}^n \binom{n}{x} y^x &amp; = (1+y)^n, \text{ by the Binomial Theorem}</mrow>
				<mrow>&amp; = (1+y)^{n_1} \cdot (1+y)^{n_2} </mrow>
				<mrow>&amp; = \sum_{x=0}^{n_1} \binom{n_1}{x} y^x \cdot \sum_{x=0}^{n_2} \binom{n_2}{x} y^x </mrow>
				<mrow>&amp; = \sum_{x=0}^n \sum_{t=0}^r \binom{n_1}{r} \binom{n_2}{r-t} y^x</mrow>
			</md>		
			Equating like coefficients for the various powers of y gives
			<me>\binom{n}{r} = \sum_{t=0}^r \binom{n_1}{r} \binom{n_2}{r-t}.</me>
			Dividing gives
			<me>1 = \sum_{x=0}^r f(x).</me>
			</p>
		</li>
		<li>
		<p>For the mean
			<md>
				<mrow>\sum_{x=0}^n x \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}} &amp; = 
\frac{1}{\binom{n}{r}} \sum_{x=1}^n  \frac{n_1(n_1-1)!}{(x-1)!(n_1-x)!}  \binom{n-n_1}{r-x}				
				</mrow>
				<mrow> &amp; = \frac{n_1}{\binom{n}{r}} \sum_{x=1}^n  \frac{(n_1-1)!}{(x-1)!((n_1-1)-(x-1))!}  \binom{n-n_1}{r-x} </mrow>
				<mrow> &amp; = \frac{n_1}{\frac{n(n-1)!}{r!(n-r)!}} \sum_{x=1}^n  \binom{n_1-1}{x-1}  \binom{n-n_1}{r-x} </mrow>
			</md>
			Consider the following change of variables for the summation: 
			<md>
				<mrow>y = x-1</mrow>
				<mrow>n_3 = n_1-1</mrow>
				<mrow>s = r-1</mrow>
				<mrow>m = n-1</mrow>
			</md>
			Then, this becomes
			<md>
				<mrow> \mu = \sum_{x=0}^n x \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}} &amp; = r \frac{n_1}{n} \sum_{y=0}^m  \frac{\binom{n_3}{y} \binom{m-n_3}{s-y}}{\binom{m}{s}}
				</mrow>
				<mrow>&amp; = r \frac{n_1}{n} \cdot 1</mrow>
			</md>
			noting that the summation is in the same form as was show yields 1 above.

		</p>
		</li>
		<li>
		<p>The proof of the variance formula is similar and uses E(X(X-1)+ μ - μ2. The proof of skewness and kurtosis are messy and we won’t bother with them for this distribution!
		</p>
		</li>
	</ol>
	</proof>
	</theorem>


	<p>
	Note, if r=1 then you are back at a regular discrete uniform model. Indeed, <me>P(\text{desired item}) = 1 \cdot \frac{n_1}{n} = \mu .</me>
	which is indeed what you might expect when selecting once.
	</p>

<p>Consider the Hypergeometric distribution for various values of <m>n_1, n_2,</m> and r using the interactive cell below. Notice what happens when you start with relatively small values of <m>n_1, n_2,</m> and r (say, start with <m>n_1 = 5, n_2 = 8,</m> and r = 4 and then doubling then all again and again. Consider the likely skewness and kurtosis of the graph as the values get larger.
</p>	
<sage>
	<input>
# Hypergeometric distribution over 0 .. N
# Size of classes N1 and N2 must be given as well as subset size r
var('x')
@interact
def _(N1=slider(1,40,1,10,label='$N_1$'),
    N2=slider(1,40,1,10,label='$N_2$'),
    r=slider(1,40,1,10,label='$r$')):
    N = N1 + N1
    R = range(r+1)
    if (r &gt; N1)|(r &gt; N2):
        pretty_print('When r is bigger than N1 or N2, special consideration must be made')
    else:
        f(x) = binomial(N1,x)*binomial(N2,r-x)/binomial(N,r)
        pretty_print(html('Density Function: $f(x) =%s$'%str(latex(f(x)))))
        pretty_print(html('over the space $R = %s$'%str(R)))
        points((k,f(x=k)) for k in R).show()
        for k in R:
           print (html('$f(%s'%k+') = %s'%latex(f(x=k))+' \\approx %s$'%f(x=k).n(digits=5)))
	</input>
</sage>
	
</section>

<section><title>Exercises</title>

<exercise><title> - The Proverbial Urn Problem</title>
<p>
You have an urn with 10 marbles of which <m>n_1 = 6</m> are red and <m>N_2 = 4</m> are blue. You select randomly r = 3 of the marbles without replacement and let X represent the number of red marbles in your sample. With R = {0, 1, 2, 3}, determine:
<ul>
	<li>f(x)</li>
	<li>P(2 of the 3 are red) = f(2)</li>
	<li>P(at most 2 of the 3 are red) = f(0) + f(1) + f(2)</li>
</ul> 
</p>
</exercise>

<exercise><title> - Playing Cards</title>
<p>
You randomly select a hand of five cards without replacement from an ordinary deck of playing cards.  
<ul>
	<li>Determine the probability that four of the five are spades.</li>
	<li>Determine the probability that three of the five are face cards (ie, Jacks, Queens, Kings, or Aces).</li>
</ul>
</p>
</exercise>

<exercise><title> - Starting Seniors</title>
<p>
You are picking an eleven member football starting team by picking randomly from a group with 15 seniors and 35 others.  Using a hypergeometric distribution, determine:
<ul>
	<li>P(all seniors)</li>
	<li>P(exactly 6 seniors)</li>
	<li>the expected number of seniors on the team</li>
	<li>If your team has all seniors, explain whether someone could suggest that your decision on members was unfair</li>
</ul>
</p>
</exercise>

<exercise><title> - Old Faithful</title>
<p>
Ole Faithful geyser in Yellowstone National Park erupts every 91 minutes. You show up at some random time in the eruption cycle and your tour bus plans to stay for 25 minutes. Determine the likelihood that you will be able to see it erupt.  Express your answer in terms of the continuous uniform distribution by giving f(x), F(x), and the specific answer to this question.
</p>
</exercise>

<exercise><title> - Continuous Uniform Random Variable Scenarios</title>
<p>
Explain how the following situations can be modeled using a continuous uniform distribution by identifying the space R and the corresponding f(x) for each situation.
<ul>
	<li>The location on a prize wheel where the spun wheel will stop.</li>
	<li>Given a clock with only a minute hand, the current one second interval.</li>
	<li>The location on a automobile tire where the next puncture will occur.</li>
</ul>
</p>
</exercise>

<exercise><title> - Louisiana Mega Millions Lottery</title>
<p>
To play the Mega Millions Louisiana Lottery consists of picking five numbers from 1 to 75 and one yellow Mega Ball number from 1 through 15. (You can play up to five different sets of numbers on each playslip but we will just assume one play per ticket to keep things straight.) Each play costs $1 and you can pay an additional $1 to apply a "multiplier" which multiplies any non-Jackpot prize by the Multiplier number (2, 3, 4, or 5) randomly selected at the time of the drawing.</p>
<p> On October 10, 2016 the jackpots listed were
<ul>
	<li>Match 5 plus Mega ball = Jackpot of $49,000,000 with cash value of $32,600,000</li>
	<li>Match only 5 = $1,000,000</li>
	<li>Match 4 plus Mega ball = $5,000</li>
	<li>Match only 4 =$500</li>
	<li>Match 3 plus Mega ball = $50</li>
	<li>Match only 3 = $5</li>
	<li>Match 2 plus Mega ball = $5</li>
	<li>Match 1 plus Mega ball = $2</li>
	<li>Match only the Mega ball = $1</li>
</ul>
Verify the posted odds
<ul>
	<li>Match 5 plus Mega ball = 1 in 258,890,850</li>
	<li>Match only 5 = 1 in 18,492,204</li>
	<li>Match 4 plus Mega ball = 1 in 739,688</li>
	<li>Match only 4 = 1 in 52,835</li>
	<li>Match 3 plus Mega ball = 1 in 10,720</li>
	<li>Match only 3 = 1 in 766</li>
	<li>Match 2 plus Mega ball = 1 in 473</li>
	<li>Match 1 plus Mega ball = 1 in 56</li>
	<li>Match only the Mega ball = 1 in 21</li>
</ul>
Determine the expected payout for each ticket purchased. Also, determine what the Jackpot would need to be in order for the game to be considered "fair" with an expected value of zero.

<solution>
<p>
Throughout these calculations, you can presume that the first five numbers are selected independently from the Mega Ball number. However, the first five numbers are selected without replacement so computing probabilities with those does not allow for independence. This part is hypergeometric with the <m>n_1 = 5</m> numbers you selected being the "desired" numbers and the Lottery Commission picking a subset of size r = 5 from the 75 possible numbers.  So, your likelihood of matching all five would be
<me>\frac{\binom{5}{5} \cdot \binom{70}{0}}{\binom{75}{5}} = \frac{1}{17259390}.</me>
Multiplying this by the 1 chance in 15 that you also match the Mega Ball gives
<me>P(\text{Match 5 plus Mega Ball}) = \frac{1}{17259390} \cdot \frac{1}{15} = \frac{1}{258,890,850}.</me>
To match only 5 means you also MUST miss the Mega Ball which has probability 14/15 to give
<me>\frac{1}{17259390} \cdot \frac{14}{15} = \frac{1}{17259390 \cdot \frac{15}{14}} \approx \frac{1}{18492204}.</me>
Continue in this manner to determine the other odds.
</p>
<p>
For the expected earnings, first determine a value function corresponding to each outcome and apply the discrete expected value process. This gives
<md>
	<mrow> &amp; \$32600000 \cdot \frac{1}{258,890,850} + \$1000000 \cdot \frac{1}{18,492,204} </mrow>
	<mrow> &amp; + \$5000 \cdot \frac{1}{739,688} + \$500 \cdot \frac{1}{52,835}</mrow>
	<mrow> &amp; + \$50 \cdot \frac{1}{10,720} + \$5 \cdot \frac{1}{766} </mrow>
	<mrow> &amp; + \$5 \cdot \frac{1}{473} + \$2 \cdot \frac{1}{56} + \$1 \cdot \frac{1}{21}</mrow>
	<mrow> &amp; \approx \$0.3013.</mrow>
</md>
So, the expected payout is approximately 30 cents. Subtracting the cost of playing ($1) indicates that the average winnings per play of the Louisiana Lottery would be -70 cents. So, you would be better off to take, say, 50 cents and just give it to the local school system every time you consider playing this game rather than actually playing.
</p>
<p>
To determine the Jackpot A needed to make this a fair game means to solve the equation
<md>
	<mrow> &amp; A \cdot \frac{1}{258,890,850} + \$1000000 \cdot \frac{1}{18,492,204} </mrow>
	<mrow> &amp; + \$5000 \cdot \frac{1}{739,688} + \$500 \cdot \frac{1}{52,835}</mrow>
	<mrow> &amp; + \$50 \cdot \frac{1}{10,720} + \$5 \cdot \frac{1}{766} </mrow>
	<mrow> &amp; + \$5 \cdot \frac{1}{473} + \$2 \cdot \frac{1}{56} + \$1 \cdot \frac{1}{21}</mrow>
	<mrow> &amp; = 1</mrow>
</md>
for A.
</p>
<p>
Finally, to deal with the multiplier, note that all but the Jackpot payouts would be increased by the multiplier m where <m>m \in \{1,2,3,4,5\}</m>.  For the cost of an extra $1 (total cost of $2 per bet) the expected payout increases as the multiplier increases but each of these decreases likelihood of winning that payout by a factor of 1/5.  In general, let x = 1, 2, ..., 9 indicate the various winning options in order listed above, f(x) the corresponding probabilities listed for each option, and  u(x) the listed payouts. Then the expected payout is given by
<me> \$32600000 \cdot \frac{1}{258,890,850} + \sum_{m=1}^5
\sum_{x=2}^9 m \cdot u(x) f(x)/5 </me>
or
	<md>
		<mrow> \$32600000 \cdot \frac{1}{258,890,850} &amp; + \sum_{m=1}^5 \frac{m}{5} \sum_{x=2}^9 u(x) f(x) </mrow>
		<mrow> &amp; = \frac{\$32600000}{258890850} + \sum_{m=1}^5 \frac{m}{5} 0.17539</mrow>
		<mrow> &amp; = 0.12592 + 3 \cdot 0.17539</mrow>
		<mrow> &amp; = 0.65209</mrow>
	</md>
Therefore, the expect value of spending another dollar to get the multiplier effect is about -$1.35.  Since this is slightly less than doubling the expected loss of 70 cents for playing without the multiplier with $1, it make more sense to bet $2 once rather than betting $1 twice.  Or, you can send the extra nickel to this author of this text and call it quits.
</p>

</solution>
</p>
</exercise>

</section>


</chapter>