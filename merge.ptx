<?xml version="1.0" encoding="UTF-8"?>
<mathbook xmlns:xi="http://www.w3.org/2001/XInclude" xml:lang="en-US">
  <!--********************************************************************
Copyright 2016 John Travis
This file is part of MathBook XML.
MathBook XML is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 2 or version 3 of the
License (at your option).
MathBook XML is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with MathBook XML.  If not, see <http://www.gnu.org/licenses/>.
*********************************************************************-->
  <docinfo>
    <author-biographies length="short"/>
    <website>
        <title>math.mc.edu/travis</title>
        <url>math.mc.edu/travis</url>
    </website>
    <!-- Prefix to enhance Sage notebook contents -->
    <initialism/>
    <macros>

    </macros>
    <!-- tikz package and libraries for images -->
    <latex-image-preamble>
    \usepackage{tikz}
    \usetikzlibrary{backgrounds}
    \usetikzlibrary{arrows,matrix}
    \usetikzlibrary{snakes}
    </latex-image-preamble>
  </docinfo>
  <book xml:id="Essentials_Probability_And_Statistics">
    <title>Essentials of Mathematical Probability and Statistics</title>
    <!--    	<subtitle>A First Course For the Mathematically Inclined</subtitle>
 -->
    <frontmatter xml:id="index">
      <titlepage>
        <author>
          <personname>John Travis</personname>
          <department>Department of Mathematics</department>
          <institution>Mississippi College</institution>
          <email>travis@mc.edu</email>
        </author>
        <credit>
        </credit>
        <date>
          <today/>
        </date>
      </titlepage>
      <colophon>
        <copyright>
            <year>2015 <ndash/>today</year>
            <holder>John Travis</holder>
            <shortlicense>Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License, Version 1.2 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts.  A copy of the license is included in the appendix entitled <q>GNU Free Documentation License.</q></shortlicense>
        </copyright>
      </colophon>
      <biography>
        <p>
John Travis grew up in Mississippi and had his graduate work at the University of Tennessee and Mississippi State University. As a numerical analyst, since 1988 he has been a professor of mathematics at his undergraduate alma mater Mississippi College where he currently serves as Professor of Mathematics.
</p>
        <p>
John is married to Ruth Page Travis and together they have three unique daughters who all are good at mathematics.
</p>
        <p>You can find him playing racquetball or guitar but not generally at the same time. He is also an active supporter and organizer for the opensouce online homework system WeBWorK.
</p>
      </biography>
      <preface>
        <p>
This text is intended for a one-semester course in probability and statistics that presumes calculus knowledge up to integration techniques. It is perhaps helpful if a student has already been exposed to sequences and series but much of what is needed is reviewed in the text.
</p>
        <p>An interactive version of this text is available at 
<url href="http://math.mc.edu/travis/mathbook/Probability/Essentials_Probability_And_Statistics.html">http://math.mc.edu/travis/mathbook/Probability/Essentials_Probability_And_Statistics.html</url>

and an pdf version with active links is available at

<url href="http://math.mc.edu/travis/mathbook/Probability/Essentials_Probability_And_Statistics.pdf">http://math.mc.edu/travis/mathbook/Probability/Essentials_Probability_And_Statistics.pdf</url>. 
</p>
        <p>
A collection of WeBWorK online homework problems are available to correlate with the material in this text. Copies of these sets of problems are available by contacting the author. These exercises are considered an integral part when using this text although a static version of these is included in the appendix.
</p>
        <p>
To successfully utilize this text, a student should review the requisite material and perhaps review the proofs and derivations if appropriate. While moving through the text, the student should review each of the examples and then attempt each of the interactive WeBWorK exercises. Whenever an interactive cell comes up, the student should play around with the cell and perhaps change the input data as appropriate to experiment. When a section is completed, a student should work the WeBWorK exercises (not part of this text) or some other exercises provided by the instructor and attempt the exercises provided in this text...many of which are famous examples or exercises that might have special significance.  Some are (of course) just easy and most of the textbook exercises have solutions provided.
</p>
        <p>        
WeBWorK (<url href="http://webwork.maa.org">webwork.maa.org</url>) is an open-source online homework system for math and science courses. WeBWorK is supported by the MAA and the NSF and comes with a Open Problem Library (OPL) of over 35,000 homework problems. Problems in the OPL target most lower division undergraduate math courses and some advanced courses. Supported courses include college algebra, discrete mathematics, probability and statistics, single and multivariable calculus, differential equations, linear algebra and complex analysis.
</p>
        <p>
Sage (<url href="http://sagemath.org">sagemath.org</url>) is a free, open-source, software system for advanced mathematics, which is ideal for assisting with a study of abstract algebra. Sage can be used either on your own computer, a local server, or on SageMathCloud (<url href="https://cloud.sagemath.com">https://cloud.sagemath.com</url>).  In this text, the sage cell is used also for interactive computations related to R and octave, as needed.
</p>
        <attribution>
            <line>John Travis</line>
            <line>Clinton, Mississippi 2015-2019</line>
        </attribution>
      </preface>
    </frontmatter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="RepresentingData">
      <title>Statistical Measures</title>
      <section>
        <title>Introduction</title>
        <p>
To compute your final grade in a class your teacher will likely consider the scores you have earned on various assignments and examinations completed during the duration of the course. However, she ultimately will likely be required to assign some numerical score indicating your level of success in the course. One grade to rule them all. This final grade can only be one value and it would make sense that the grade be a reflection of your work on these tasks. So, what is a fair way for your teacher to complete this task? 
</p>
        <p>
Through this process, you will also often need to take into account whether that data set is the entire list of possibilities--known as the population--or just a subset of that population perhaps obtained by taking repeated measurements --that is, a sample. 
</p>
        <p>
In general, it is often useful to make decisions using quantitative data but making those decisions can be somewhat arbitrary without a mathematical basis supporting those decisions. In this chapter, you will consider a number of ways to use point values to represent a given set of data. Each of these quantitative metrics will be called a "statistical measure" and will, in some fashion, describe using one number some property of the entire data set. Such measures are part of what is known as "descriptive statistics".  Later, you will learn about how other metrics can be used to predict properties of the underlying situation. Doing this is part of what is known as "inferential statistics".
</p>
        <p>
So, let's go and hopefully you will in some measure enjoy the ride!
</p>
      </section>
      <section>
        <title>Measurement Scales</title>
        <p>
In creating statistical measures, you might want to consider one of the following general types.
</p>
        <p>
	<ul><li><p>Nominal measures - In this case, data falls into mutually exclusive and exhaustive categories for which the numerical value is only used for identification purposes. For example, assigning Male = 1, Female = -1.</p></li><li><p>Ordinal measures - In this case, data consists of discrete numerical values which can be ranked from lowest to highest or vice versa. For example, your grades in a number of classes are used to compute your GPA--which is a single number.</p></li><li><p>Interval measures - In this case, data possesses an order and where the distance between data values is of significance. For example, heights and weights.</p></li><li><p>Ratio measures - In this case, data can be expressed as a position in some interval and where ratios between observations have meaning. For example, percentile rankings</p></li></ul>
</p>
        <p>In the subsequent sections of this chapter, you will see that a number of different measures are available for most data sets. Determining which "correct" measure to use for describing any given data set will depend the actual situation surrounding the collection of the data.
</p>
      </section>
      <section>
        <title>Statistical Measures of Position</title>
        <p>Given a collection of data, sorting the data may provide several useful descriptors. When sorting data, you can easily use something like a spreadsheet for larger data sets but in this section you will also see there are ways to perform a sort by hand. In either case, statistical measures of position generally involve very little computational work once the data is sorted and take into account only the order of the data from lowest to highest.  To assist with notation, we will generally use x-values to represent the original raw data and y-values to represent that same data when ordered with the subscript indicating the positional placement.
	</p>
        <p>	
<definition><title>Order Statistic</title><statement><p xml:id="OrderStatistics">From the data set <m>x_1, x_2, ... , x_n</m>, assume that when sorted it is denoted <m>y_1, y_2, ..., y_n</m> where  
	<me> y_1 \le y_2 \le ... \le y_n.</me> 
	Then, <m>y_k</m> is known as the kth order statistic. </p></statement></definition>
</p>
        <p>	
<example xml:id="PresidentAge"><title>Age of Presidents - order statistics</title><p>
	The age at inauguration for presidents from 1981-2019 gives the data <m>x_1 = 69, x_2 = 64, x_3 = 46, x_4 = 54, x_5 = 47, x_6 = 70</m> (Reagan, Bush, Clinton, Bush, Obama, Trump). For this data, the order statistics are denoted <m>y_1 = 46, y_2 = 47, y_3 = 54, y_4 = 64, y_5 = 69, y_6 = 71</m>.
	</p></example>
</p>
        <p>
	Once the data is sorted, it should be very easy for you to locate the smallest and largest values. 
	</p>
        <p>
<definition><title>Minimum/Maximum:</title><statement><p xml:id="MaxMin">For a given data set, the smallest and largest values are known as the minimum and maximum, respectively. In our notation, minimum = <m>y_1</m> and the maximum = <m>y_n</m></p></statement></definition>
</p>
        <p>	
<example><title>Age of Presidents - Minimum/Maximum</title><statement><p>
	Using the <xref ref="PresidentAge"> President inauguration data</xref>, minimum = <m>y_1 = 46</m> and maximum = <m>y_6 = 70</m>.
	</p></statement></example>
</p>
        <p>
A value that separates ordered data into two groups with a desired percentage on each side is called a percentile. There are multiple ways that have been created that achieve this goal. In this text we present two and will consistently use the first one presented below. For each, in general, a given percentile is a numerical value at which approximately a given percentage of the data is smaller. 
</p>
        <p>
The definition presented below provides for a unique measure for each unique value of p that corresponds to the PERCENTILE.EXC macro in Excel.  This version starts by computing <m>(n+1)p</m> where 
<m>0 &lt; p &lt; 1</m> and using this to linearly interpolate between two adjacent entries in the sorted list.  Another option that corresponds to PERCENTILE.INC (and PERCENTILE) in Excel is to start with <m>(n-1)p+1</m> for determining how to pick the two adjacent entries and then proceeding with linear interpolation. Again, the definition below utilizes the first approach.
</p>
        <p>	
<definition xml:id="PercentileDefn"><title>Percentiles</title><statement><p xml:id="Percentiles">For <m>0 \lt s \lt 1</m> and for order statistics <m>y_1, y_2, ..., y_n</m> define the 100s-th percentile to be 
		<me>P^{s} = (1-r)y_m + ry_{m+1}</me>
	where m is the integer part of (n+1)s, namely 
		<me>m = \left\lfloor (n+1)s \right\rfloor</me> 
	and 
		<me>r = (n+1)s - m,</me>
	
	the fractional part of (n+1)s. 
	</p></statement></definition> 
</p>
        <p><title>Computing Percentiles</title>
<exercise><introduction><p>
		Compute the following percentile values.
		</p></introduction><webwork-reps xml:id="extracted-webwork-1" ww-id="webwork-1">
    <pg source="Library/UVA-Stat/setStat212-Homework02/stat212-HW02-18.pg"/>

      
    <static source="Library/UVA-Stat/setStat212-Homework02/stat212-HW02-18.pg" seed="1">
      <statement><p>Consider the following data set:
      <me>\begin{array}{ccccccccc} 
      39 \amp  20 \amp  36 \amp  27 \amp  51 \amp  27 \amp  12 \amp  16 \amp  12\\
      51 \amp  39 \amp  28 \amp  51 \amp  13 \amp  27 \amp  34 \amp  49 \amp  40  
      \end{array}</me></p><p>Find the 15th and 88th percentiles for this data.</p><p>15th percentile = <fillin name="AnSwEr0001" characters="15"/></p><p>88th percentile = <fillin name="AnSwEr0002" characters="15"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=1&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework02/stat212-HW02-18.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=1&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework02/stat212-HW02-18.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=1&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework02/stat212-HW02-18.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=1&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework02/stat212-HW02-18.pg</server-url>

  </webwork-reps><conclusion><p>
		
		</p></conclusion></exercise>
</p>
        <p>
<example><title>Presidential Percentile</title><p>To compute, say, the 42nd percentile for the 
<xref ref="PresidentAge"> President inauguration data presented earlier </xref> consider s = 0.42. Since there are 6 numbers in our data set, then

<me>(n+1)s = 7 \cdot 0.42 = 2.94</me>

and so m = 2 and r = 0.94.  Thus, the percentile will lie between <m>y_2 = 47</m> and <m>y_3 = 54</m> and much closer to 54 than 47.  Numerically
<me>P^{0.42} = 0.06 \cdot 47 + 0.94 \cdot 54 = 53.58.</me> 
</p></example>
</p>
        <p>
The formula for percentiles determines a weighted average between <m>y_m</m> and <m>y_{m+1}</m> which is unique for distinct values of p provided each of the data values are distinct. Note that if some of the y-values are equal then some of these averages might be averages of equal numbers and will therefore be the common value.
</p>
        <p>
Some special percentiles are provided special names...
</p>
        <p>
<definition><title>Quartiles</title><statement><p xml:id="Quartiles">Given a sorted data set, the first, second, and third quartiles are the values of 
	<m>Q_1 = P^{0.25}, Q_2 = P^{0.5}</m> and <m>Q_3 = P^{0.75}</m>.
	</p></statement></definition>
</p>
        <p>
It should be noted that many graphing calculators often compute quartiles using a straight average of two adjacent entries rather than by using the formula above. This causes some difficulty and especially so when n mod 4 = 2. 
</p>
        <p>
<example><title><m>Q_1</m> and <m>Q_3</m> when n mod 4 = 2</title><p>
Suppose n = 22 = 5(4) + 2. Computing the first quartile as defined above gives (n+1)p = 23(0.25) = 5.75 = 5 + 0.75 = m + r.  Therefore,
<me>Q_1 = 0.25 \times y_5 + 0.75 \times y_6</me>
which is a value closer to <m>y_6</m>.  Many graphing calculators however quickly approximate this with
<me>0.5 \times y_5 + 0.5 \times y_6</me>
so you should be aware of this possible difference.  You should also notice that in this case p = 0.25 but r = 0.75 so these values are not required to be the same. 
</p></example>
</p>
        <p>
<definition><title>Deciles:</title><statement><p xml:id="Deciles">Given a sorted data set, the first, second, ..., ninth deciles are the value of 
	<m>D_1 = P^{0.1}, D_2 = P^{0.2}, ... , D_9 = P^{0.9}</m>
	</p></statement></definition>
</p>
        <p>	
<example><title>Small Example - Quartiles</title><statement><p>
Consider the following data set: {2,5,8,10}. The 50th percentile should be a numerical value for which approximately 50% of the data is smaller. In this case, that would be some number between 5 and 8.  For now, let's just take 6.5 so that two numbers in the set lie below 6.5 and two lie above. This is a perfect 50% for the 50th percentile. In a similar manner, the 25th percentile would be some number between 2 and 5, say 2.75, so that one number lies below 2.75 and three numbers lie above.
	</p><p>Using the <xref ref="PercentileDefn"> definition </xref>, the 25th percentile is computed by considering 
	<me>(n+1)p = (4+1)0.25 = 5/4 = 1.25</me>.  
	So, m = 1 and r = 0.25. Therefore 
	<me>P^{0.25} = 0.75 \times 2 + 0.25 \times 5 = 2.75</me> 
	as noted above. 
	</p><p>
	Similarly, the 75th percentile is given by
	<me>(n+1)p = (4+1)0.75 = 15/4 = 3.75</me>.  
	So, m = 3 and r = 0.75. Therefore 
	<me>P^{0.75} = 0.25 \times 8 + 0.75 \times 10 = 9.5</me> 
	
	It is interesting to note that 3 also lies between 2 and 5 as does 2.75 and has the same percentages above (75 percent) and below (25 percent). However, it should designate a slightly larger percentile location. Indeed, going backward:
	<md><mrow>3 = (1-r) \times 2 + r \times 5</mrow><mrow>\Rightarrow r = \frac{1}{3}</mrow><mrow>\Rightarrow (n+1)p = 1 + \frac{1}{3} = \frac{4}{3}</mrow><mrow>\Rightarrow p = \frac{4}{15} \approx 0.267</mrow></md>
	and so 3 would actually be at approximately the 26.7th percentile.
	</p></statement></example>
</p>
        <p>
<exercise><p>
In general, given a numerical value within the range of a given data set, one can determine the percentile ranking of that value by reversing the general formula for percentile and solving for p, given <m>P^s</m>.  Determine such a formula/process for doing this in general.
</p></exercise>
</p>
        <p>
	For your data set {2,5,8,10}, 
	<m>Q_1 = 2.75, Q_2 = 6.5,</m> and <m>Q_3 = 9.5</m>.
</p>
        <p>
	For a given data set, a summary of these statistics is often desired in order to give the user a quick overview of the more important order statistics.
</p>
        <p>
<definition><title>5-number summary</title><statement><p xml:id="FiveNumberSummary">Given a set of data, the 5-number summary is a vector of the order statistics given by 
	
	<me>\lt \text{minimum}, Q_1, Q_2, Q_3, \text{maximum} \gt .</me> 
	</p></statement></definition>
</p>
        <p>
You can also compute these statistics automatically using the opensource statistical software known simply as "R".  The following interactive cell uses the opensource software "Sage" to perform this calculation using the freely available web portal at sagemath.sagecell.org. You can change the data list if you want to use this to compute values for a different collections of numbers. The five-number-summary is displayed graphically using a "Box-Plot". Graphical representations of data will be discussed later in this chapter. You should compare the answers found using R with the values produced by our <xref ref="PercentileDefn"> definition </xref>
</p>
        <p>
<sage language="r"><input>
data &lt;- c( 1, 2, 5, 7, 7, -1, 3, 2)   # concatenate the following items into a list
paste("Quartiles:")
quantile(data)
paste("Specific Percentiles:")
quantile(data, c(.32, .57, .98))   # find the 32nd, 57th and 98th percentiles
paste("Box and Whisker Diagram:")
boxplot(data, horizontal=TRUE) 
</input></sage>
</p>
        <p>	
<example><title>Small example - 5 number summary</title><statement><p>Returning to our previous example, the five number summary would be
	<me>\lt 2, 2.75, 6.5, 9.5, 10 \gt .</me>
	</p></statement></example>
</p>
      </section>
      <section>
        <title>Statistical Measures of the Middle</title>
        <definition>
          <title>Arithmetic Mean</title>
          <statement>
            <p xml:id="Mean">Suppose X is a discrete random variable with range 
	<m>R = {x_1, x_2, ..., x_n}</m>. 
	The arithmetic mean is given by
		<me>
		\frac{x_1 + ... + x_n}{n} = \frac{\sum_{k=1}^n x_k}{n}.
		</me>
	If this data comes from sample data then we call it a sample mean and denote this value by <m>\overline{x}</m>. If this data comes from the entire universe of possibilities then we call it a population mean and denote this value by <m>\mu</m>.  When presented with raw data, it might be good to generally presume that data comes from a sample and utilize <m>\overline{x}</m>.
	</p>
          </statement>
        </definition>
        <p>
	To illustrate, consider the previous data set: {2,5,8,10}. The arithmetic mean is given by
	<me>\overline{x} = \frac{2+5+8+10}{4} = \frac{25}{4} = 6.25.</me>
	</p>
        <p>
	The mean is often called the centroid in the sense that if the x values were locations of objects of equal weight, then the centroid
	would be the point where this system of n equal masses would balance. Play around with the interactive cell below by entering your own data values into the first list.
	</p>
        <p>
<sage><input>
x = [2, 5, 8, 10, 11]     # Put your data values in this list
x.sort()

mu = mean(x)
n = len(x)
pts = [(x[0],0.05)]
M = 0.2
for k in range(1,n):
    if x[k]==x[k-1]:
        pts.append((x[k],pts[k-1][1]+0.1))
        M += 0.1
    else:
        pts.append((x[k],0.05))
G = points(pts,size=100,figsize=[10,2])
G += polygon([(mu,0), (mu+0.2,-0.5), (mu-0.2,-0.5)],color='brown')
G.show(ymin=-0.5, ymax = M)
</input></sage>
</p>
        <p>
	The values can all be provided with varying weights if desired and the result is called the weighted arithmetic mean and is given by
		<me>
		\frac{m_1 x_1 + ... + m_n x_n}{m_1 + ... + m_n} = \frac{\sum_{k=1}^n m_k x_k}{\sum_{k=1}^n m_k}.
		</me>
	This is often how your teacher will actually compute your final grade in a class where the <m>m_k</m> are the relative weights for each assignment grade.
	</p>
        <p>
<sage><input>
x = [2, 5, 8, 10]     # Put _unique_ data values in this list
w = [1, 2.5, 2.5, 4]  # Scale to be at most 10 and not tiny for good image
wsum = sum(w)

n = len(x)
pts = [(x[0],0.05)]
M = 0.2
mu = 0
for k in range(1,n):
    mu += x[k]*w[k]
    if x[k]==x[k-1]:
        pts.append((x[k],pts[k-1][1]+0.1))
        M += 0.2
    else:
        pts.append((x[k],0.05))
mu = mu/wsum
G = Graphics()
for k in range(n):
    G += point(pts[k],size=100*w[k]) 
P = polygon([(mu,0), (mu+0.2,-0.5), (mu-0.2,-0.5)],color='brown')
(G+P).show(ymin=-0.5, ymax = M)
</input></sage>
</p>
        <p>
<example><title>Computing class final grade</title><p>
Suppose in a given class you have a daily grade of 92, exam 1 grade of 85, exam 2 grade of 87, and a final exam grade of 93.  IF the daily grade counts 10 percent, the first two exams count 25 percent each and the final counts 40 percent then your final grade would be
<me>\frac{0.10 \cdot 92 + 0.25 \cdot 85 + 0.25 \cdot 87 + 0.40 \cdot 0.93}{0.10 + 0.25 + 0.25 + 0.40} = 89.4 .</me>
It would then appear that you might want to do some bargaining with your teacher about how nice it would be to round that up.
</p></example>
</p>
        <p>
<definition><title>Median:</title><statement><p xml:id="Median">A positional measure of the middle is often utilized by finding the location of the 50th percentile. This value is also called the median and indicates the value at which approximately half the sorted data lies below and half lies above.
</p></statement></definition>
</p>
        <p>
For data sets with an odd number of values, this is the "middle" data value if one were to successively cross off pairs from the two ends of the sorted data. For data sets with an even number of values, this is a average of the two data values left after crossing off all other pairs.  Using the order statistics, the median equals
	<me>y_{\frac{n+1}{2}}</me>
if n is odd and
	<me>\frac{y_\frac{n}{2} + y_{\frac{n}{2}+1}}{2}</me>
if n is even.
</p>
        <p>
From the <xref ref="PresidentAge"> Presidential data </xref>, note that you are considering an even number of data values and so the median is given by (54+64)/2 = 59. 
</p>
        <p>
<definition><title>Midrange:</title><statement><p xml:id="Midrange">The midrange is a mixture of the mean and median where one takes the simple average of the maximum and minimum values in the data set. Using the order statistics, this equals 
	<me>\frac{y_1+y_n}{2}</me>
</p></statement></definition>
</p>
        <p>
From the <xref ref="PresidentAge"> Presidential data </xref>, the maximum is 70 and the minimum is 46 so the midrange is 58, the average of these two. 
</p>
        <p>
There are several advantages and disadvantages associated with each of these measures. The mean utilizes all of the data values so each term is important. Utilizes them all even if some of the data values might suffer from collection errors. The median ignores outliers (which might be a result of collection errors) but does not account for the relative differences between terms. The midrange is very easy to compute but ignores the relative differences for all terms but the two extremes. A similar collection of features and drawbacks are associated with all descriptive statistics. 
</p>
        <p>
You can again compute many statistics automatically using R...
<sage language="r"><input>
data &lt;- c( 1, 2, 5, 7, 7, -1, 3, 2)   # concatenate the following items into a list
paste("Mean = ", mean(data))
paste("Median =", median(data))
</input></sage>
</p>
        <p>
<example xml:id="StatePopulations"><title>USA State Population Measures of the Middle</title><statement><p>The US Census Bureau reported the following state populations (in millions) for 2013:
<url href="Data/USA_States_Populations_2014.xlsx">Spreadsheet</url>
</p><p>
<table halign="left"><caption>USA State Populations - 2014</caption><tabular halign="right"><row><cell bottom="medium">State</cell><cell bottom="medium">Population</cell></row><row><cell>Wyoming</cell><cell>0.6</cell></row><row><cell>Vermont</cell><cell>0.6</cell></row><row><cell>District of Columbia</cell><cell>0.6</cell></row><row><cell>North Dakota</cell><cell>0.7</cell></row><row><cell>Alaska</cell><cell>0.7</cell></row><row><cell>South Dakota</cell><cell>0.8</cell></row><row><cell>Delaware</cell><cell>0.9</cell></row><row><cell>Montana</cell><cell>1</cell></row><row><cell>Rhode Island</cell><cell>1.1</cell></row><row><cell>New Hampshire</cell><cell>1.3</cell></row><row><cell>Maine</cell><cell>1.3</cell></row><row><cell>Hawaii</cell><cell>1.4</cell></row><row><cell>Idaho</cell><cell>1.6</cell></row><row><cell>West Virginia</cell><cell>1.9</cell></row><row><cell>Nebraska</cell><cell>1.9</cell></row><row><cell>New Mexico</cell><cell>2.1</cell></row><row><cell>Nevada</cell><cell>2.8</cell></row><row><cell>Kansas</cell><cell>2.9</cell></row><row><cell>Utah</cell><cell>2.9</cell></row><row><cell>Arkansas</cell><cell>3</cell></row><row><cell>Mississippi</cell><cell>3</cell></row><row><cell>Iowa</cell><cell>3.1</cell></row><row><cell>Connecticut</cell><cell>3.6</cell></row><row><cell>Oklahoma</cell><cell>3.9</cell></row><row><cell>Oregon</cell><cell>3.9</cell></row><row><cell>Kentucky</cell><cell>4.4</cell></row><row><cell>Louisiana</cell><cell>4.6</cell></row><row><cell>South Carolina</cell><cell>4.8</cell></row><row><cell>Alabama</cell><cell>4.8</cell></row><row><cell>Colorado</cell><cell>5.3</cell></row><row><cell>Minnesota</cell><cell>5.4</cell></row><row><cell>Wisconsin</cell><cell>5.7</cell></row><row><cell>Maryland</cell><cell>5.9</cell></row><row><cell>Missouri</cell><cell>6</cell></row><row><cell>Tennessee</cell><cell>6.5</cell></row><row><cell>Indiana</cell><cell>6.6</cell></row><row><cell>Arizona</cell><cell>6.6</cell></row><row><cell>Massachusetts</cell><cell>6.7</cell></row><row><cell>Washington</cell><cell>7</cell></row><row><cell>Virginia</cell><cell>8.3</cell></row><row><cell>New Jersey</cell><cell>8.9</cell></row><row><cell>North Carolina</cell><cell>9.8</cell></row><row><cell>Michigan</cell><cell>9.9</cell></row><row><cell>Georgia</cell><cell>10</cell></row><row><cell>Ohio</cell><cell>11.6</cell></row><row><cell>Pennsylvania</cell><cell>12.8</cell></row><row><cell>Illinois</cell><cell>12.9</cell></row><row><cell>Florida</cell><cell>19.6</cell></row><row><cell>New York</cell><cell>19.7</cell></row><row><cell>Texas</cell><cell>26.4</cell></row><row><cell>California</cell><cell>38.3</cell></row></tabular></table>

Determine the minimum, maximim, midrange, and mean for this data.
</p></statement><solution><p>Notice that these are already in order so you can presume 
		<m>y_1 = 0.6</m> million is the minimum and <m>y_{50} = 38.3</m> 
		million is the maximum. Therefore, the midrange is given by
		<me>\frac{0.6+38.3}{2} = \frac{38.9}{2} = 19.45  \text{million}.</me>

		In this collection of "states" data the District of Columbia is included so that the number of data items is n=51. The mean of this data takes a bit of arithmetic but gives
		<me>\overline{x} = \frac{\sum_{k=1}^{51} y_k }{51} = \frac{316.1}{51} \approx 6.20</me>
		million residents. 
		</p><p>
		Since the number of states is odd, the median is found by looking at the 26th order statistic. In this case, that is the 4.4 million residents of Kentucky, i.e. <m>y_{26} = 4.4</m>.
		</p></solution></example>
</p>
      </section>
      <section>
        <title>Statistical Measures of Variation</title>
        <p>These measures provide some indication of how much the data set is "spread out". Indeed, note that the data sets {-2,-1,0,1,2} and {-200,-100,0,100,200} have the same mean but one is much more spread out than the other. Measures of variation should catch this difference.
</p>
        <p>
<definition><title>Range:</title><statement><p xml:id="Range">Using the order statistics, <me>y_n - y_1.</me>  
</p></statement></definition>
</p>
        <p>
It is trivial to note that the range is very easy to compute but it completely gnores all data values but the two ends.
</p>
        <p>From the <xref ref="PresidentAge"> Presidential data </xref>, the maximum is 69 and the minimum is 46 so the range is 23, the difference of these two. </p>
        <p>
<definition><title>Interquartile Range (IQR):</title><statement><p xml:id="IQR">
<me>IQR = P^{0.75} - P^{0.25}.</me> 
</p></statement></definition>
</p>
        <p>
For the data set {2, 5, 8, 10}, you have found that <m>Q_1 = 2.75</m> and <m>Q_3 = 9.5</m>. Therefore, <me>IQR = 9.5 - 2.75 = 6.75.</me>
</p>
        <p>
Average Deviation from the Mean (Population):  Given a population data set <m>x_1, x_2, ... , x_n</m> with mean <m>\mu</m> each term deviates from the mean by the value <m>x_k - \mu</m>. So, averaging these gives
<me> \frac{\sum_{k=1}^n (x_k-\mu)}{n} = \frac{\sum_{k=1}^n x_k}{n} - \frac{\sum_{k=1}^n \mu}{n} = \mu - \mu = 0.</me>
This metric is therefore always zero for any provided set of data since cancellation makes this not useful. So, we need to determine ways to avoid cancellation.
</p>
        <p>Average Absolute Deviation from the Mean (Population):  
<me> \frac{\sum_{k=1}^n \left | x_k-\mu \right |}{n} </me>
which, although nicely stated, is difficult to deal with algebraically since the absolute values do not simplify well algebraically. To avoid this algebraic roadblock, we can look for another way to nearly accomplish the same goal by squaring and then square rooting. 
</p>
        <p>Average Squared Deviation from the Mean (Population):
<me> \frac{\sum_{k=1}^n ( x_k-\mu )^2}{n} </me>
which will always be non-negative but can be easily expanded using algebra. Since this is a mouthful, this measure is generally called the "variance". 
</p>
        <p>
Using the average squared deviation from the mean, differences have been squared. Thus all of the squared differences added are non-negative but very small ones have been made even smaller and larger ones have been made relatively larger. To undo this scaling issue, one must take a square root to get things back into the right ball park. 
</p>
        <p>
<definition><title>Variance and Standard Deviation</title><statement><p xml:id="Variance">The variance is the average squared deviation from the mean. If this data comes from the entire universe of possibilities then we call it a population variance and denote this value by <m>\sigma^2</m>. Therefore
	<me>\sigma^2 = \frac{\sum_{k=1}^n ( x_k-\mu )^2}{n} </me>
</p><p>The standard deviation is the square root of the variance. If this data comes from the entire universe of possibilities then we call it a population standard deviation and denote this value by <m>\sigma</m>. Therefore
<me> \sigma = \sqrt{\frac{\sum_{k=1}^n ( x_k-\mu )^2}{n}}.</me>
</p><p>
If data comes from a sample of the population then we call it a sample variance and denote this value by v. Since sample data tends to reflect certain "biases" then we increase this value slightly by <m>\frac{n}{n-1}</m> to give the sample variance
<me>s^2 = \frac{n}{n-1}\frac{\sum_{k=1}^n ( x_k-\overline{x} )^2}{n} = \frac{\sum_{k=1}^n ( x_k-\overline{x} )^2}{n-1}.</me>
and the sample standard deviation similarly as the square root of the sample variance.
</p></statement></definition>
</p>
        <p>From the data {2,5,8,10}, you have found that the mean is 6.25. Computing the variance then involves accumulating and averaging the squared differences of each data value and this mean. Then
<md><mrow>&amp; \frac{1}{4} \left ( (2-6.25)^2 + (5-6.25)^2 + (8-6.25)^2 + (10-6.25)^2 \right ) </mrow><mrow>&amp; = \frac{18.0625 + 1.5625 + 3.0625 + 14.0625}{4} </mrow><mrow>&amp; = \frac{36.75}{4}</mrow><mrow>&amp; = 9.1875.</mrow>
	Therefore, the standard deviation for this data set is given by
	<me>\sqrt{9.1875} \approx 3.031.</me></md>
</p>
        <p>
<theorem xml:id="AlternateVariance"><title>Alternate Forms for Variance</title><statement><md><mrow>\sigma^2 &amp; = \left ( \frac{\sum_{k=1}^n x_k^2 }{n} \right ) - \mu^2 </mrow><mrow>&amp; = \left [ \frac{\sum_{k=1}^n x_k(x_k - 1)}{n} \right ] + \mu - \mu^2</mrow></md></statement><proof><p>
	<md><mrow>\sigma^2 &amp; = \frac{\sum_{k=1}^n ( x_k-\mu )^2}{n}</mrow><mrow> &amp; = \frac{\sum_{k=1}^n ( x_k^2 - 2x_k \mu + \mu^2 )}{n}</mrow><mrow> &amp; = \frac{\sum_{k=1}^n x_k^2 - 2\mu \sum_{k=1}^n x_k  + n \mu^2 )}{n}</mrow><mrow> &amp; = \left ( \frac{\sum_{k=1}^n x_k^2 }{n} \right ) - \mu^2</mrow></md>
	
</p><p>
The second part is proved similarly. Using the first part of the proof above,
	<md><mrow>\sigma^2 &amp; = \frac{\sum_{k=1}^n ( x_k-\mu )^2}{n}</mrow><mrow> &amp; = \left ( \frac{\sum_{k=1}^n x_k^2 }{n} \right ) - \mu^2</mrow><mrow> &amp; = \left ( \frac{\sum_{k=1}^n x_k (x_k - 1) + x_k }{n} \right ) - \mu^2</mrow><mrow> &amp; = \left ( \frac{\sum_{k=1}^n x_k (x_k - 1)}{n} \right ) + \mu - \mu^2</mrow></md>	
</p></proof></theorem>
</p>
        <p>
<example><title>Computing means and variances by hand</title><p>
In the data table below, notice that the <m>x_k</m> column would be the given data values but the column for <m>x_k^2</m> you could easily compute.

<table halign="left"><caption>Sample Grouped Data</caption><tabular halign="right"><row><cell bottom="medium"><m>x_k</m></cell><cell bottom="medium"><m>x_k^2</m></cell></row><row><cell>1</cell><cell>1</cell></row><row><cell>-1</cell><cell>1</cell></row><row><cell>0</cell><cell>0</cell></row><row><cell>2</cell><cell>4</cell></row><row><cell>2</cell><cell>4</cell></row><row><cell>5</cell><cell>25</cell></row></tabular></table>
So, <m>\Sigma x_k = 9</m> and <m>\Sigma x_k^2 = 35</m>.  Therefore <m>\overline{x} = \frac{9}{6} = \frac{3}{2}</m> and <m>v = \frac{\Sigma x_k^2}{6} - (\overline{x})^2 = ( \frac{35}{6} - \frac{3}{2}^2 = \frac{70-18}{12} = \frac{26}{6}</m>.  Therefore, <m>s^2 = \frac{6}{5} \times v = \frac{26}{5}</m>.
</p></example>
</p>
        <p>
Use R to compute these values...
<sage language="r"><input>
data &lt;- c( 1, -1, 0, 2, 2, 5)   # concatenate the following items into a list
paste("Variance = ", var(data))
paste("Standard Dev = ", sd(data))
paste("Inter Quantile Range =",IQR(data))
paste("Box and Whisker Diagram:")
boxplot(data, horizontal=TRUE) 
</input></sage>
</p>
        <p>Once again, the Population of the individual USA states according to the 2013 Census is considered below.</p>
        <p>
<exercise><title>USA State Population Measures of Variation</title><p>Using the <xref ref="StatePopulations"> US Census Bureau state populations </xref> (in millions) for 2014 provided earlier, determine the range, quartiles, and variance for this sample data.
</p><p>
<solution><p>Again, you should note that these are already in order so the range is quickly found to be 
	<me>y_n - y_1 = 38.3 - 0.6 = 37.7</me> 
	million residents.
	</p><p>
	For IQR, we first must determine the quartiles. The median (found earlier) already is the second quartile so we have <m>Q_2 = 4.5</m> million. For the other two, the formula for computing percentiles gives you the 25th percentiile
	<md><mrow>(n+1)p = 51(1/4) = 12.75</mrow><mrow>Q_1 = P^{0.25} = 0.25 \times 1.9 + 0.75 \times 2.1 = 2.05</mrow></md>
	and the 75th percentile
	<md><mrow>(n+1)p = 51(3/4) = 38.25</mrow><mrow>Q_3 = P^{0.75} = 0.75 \times 7 + 0.25 \times 8.3 = 7.325.</mrow></md>
	Hence, the IQR = 7.325 - 2.05 = 5.275 million residents.
	</p><p>
	From the computation before, again note that n=51 since the District of Columbia is included. The mean of this data found before was found to be approximately 6.20 million residents. So, to determine the variance you may find it easier to compute using the the alternate variance formulas <xref ref="AlternateVariance"/>. 
	<md><mrow> v &amp; = \left ( \frac{\sum_{k=1}^n y_k^2 }{n} \right ) - \mu^2
	</mrow><mrow> &amp; \approx \frac{4434.37}{51} - (6.20)^2
	</mrow><mrow> &amp; = 48.51
	</mrow></md>
	and so you get a sample variance of
	<me> s^2 \approx \frac{51}{50} \cdot 48.51 = 49.48</me>
	and a sample standard deviation of
	<me>s \approx \sqrt{49.48} \approx 7.03</me> million residents.
	</p></solution>
</p></exercise>
</p>
        <p>
The state population data set has been entered for you in the R cell below...
<sage language="r"><input>
data &lt;- c (0.6,0.6,0.6,0.7,0.7,0.8,0.9,1,1.1,1.3,1.3,1.4,1.6,
1.9,1.9,2.1,2.8,2.9,2.9,3,3,3.1,3.6,3.9,3.9,4.4,4.6,
4.8,4.8,5.3,5.4,5.7,5.9,6,6.5,6.6,6.6,6.7,7,8.3,
8.9,9.8,9.9,10,11.6,12.8,12.9,19.6,19.7,26.4,38.3)
paste("Variance = ", var(data))
paste("Standard Dev = ", sd(data))
paste("Inter Quantile Range =",IQR(data))

</input></sage>
</p>
      </section>
      <section>
        <title>Adjusting Statistical Measures for Grouped Data</title>
        <introduction>
          <p>As you considered the measures of the center and spread before, each data point was considered individually. Often, data may however be grouped into categories. The number of data items in each category is called the "frequency" of that outcome and the collection of these frequencies for all outcomes is called a "frequency distribution". 
</p>
        </introduction>
        <subsection>
          <title>Data Grouped into Single-valued Categories</title>
          <p>In this case, rather than considering <m>x_k</m> to be the kth data value can take advantage of the grouping to perhaps save a bit on arithmetic.</p>
          <p>Indeed, let's assume that data is grouped into m categories <m>x_1, x_2, ..., x_m</m> with corresponding frequencies <m>f_1, f_2, ..., f_m</m>. Then, for example, when computing the mean rather than adding <m>x_1</m> with itself <m>f_1</m> times just compute <m>x_1 \times f_1</m> for the first category and continuing through the remaining categories. This gives the following grouped data formula for the mean
		<me>
		\mu = \frac{x_1 f_1 + ... + x_m f_m}{f_1 + ... + f_m} = \frac{\sum_{k=1}^m x_k f_k}{\sum_{k=1}^m f_k}.
		</me>
and the following grouped data formula for the variance (along with one equivalent form)
		<me> 
		\sigma^2 = \frac{\sum_{k=1}^m ( x_k-\mu )^2 f_k}{\sum_{k=1}^m f_k} = \frac{\sum_{k=1}^m x_k^2 f_k}{\sum_{k=1}^m f_k} - \mu^2
		</me>

</p>
          <exercise>
            <p>
Consider the following data set
</p>
            <p>
{3,
1,
2,
2,
3,
1,
3,
4,
5,
5,
1,
4,
5,
1,
2,
4,
5,
3,
2,
5,
2,
1,
2,
2,
5}</p>
            <p>
Create a frequency distribution and determine the sample mean and variance.
</p>
            <p>
<solution><p>
	Collecting this data into a frequency distribution gives
	<table halign="left"><caption>Grouped Discrete Data</caption><tabular halign="right"><row><cell bottom="medium"><m>x_k</m></cell><cell bottom="medium"><m>f_k</m></cell></row><row><cell>1</cell><cell>5</cell></row><row><cell>2</cell><cell>7</cell></row><row><cell>3</cell><cell>4</cell></row><row><cell>4</cell><cell>3</cell></row><row><cell>5</cell><cell>6</cell></row></tabular></table>
	Therefore, 
		<me>
		\overline{x} = \frac{1 \times 5 + 2 \times 7 + 3 \times 4 + 4 \times 3 + 5 \times 6}{5+7+4+3+6} \\
		= \frac{5 + 14 + 12 + 12 + 30}{25} = \frac{43}{25}
		</me>
	and 
		<md><mrow>v &amp; = \frac{1^2 \times 5 + 2^2 \times 7 + 3^2 \times 4 + 4^2 \times 3 + 5^2 \times 6}{5+7+4+3+6} - \left ( \frac{43}{25} \right )^2 </mrow><mrow> &amp; = \frac{5 + 28 + 36 + 48 + 150}{25} - \left ( \frac{43}{25} \right )^2 </mrow><mrow> &amp; = \frac{4826}{625}</mrow><mrow> &amp; \approx 7.7216</mrow></md>
	and so <m>s^2 = \frac{25}{24} \frac{4826}{625} \approx 8.043</m>. 
	</p></solution>
</p>
          </exercise>
        </subsection>
        <subsection>
          <title>Data Grouped into Continuous Intervals</title>
          <p>For measures on data grouped into intervals, it is somewhat difficult to do calculations when the data no longer exists as individual values since all you know is the frequencies of each interval. You can use "class marks"...the midpoints of each interval...as representers for all of the items that fell into that interval for computing means and variances.  For positional measures, you want to approach this in the same manner as with percentiles before.  That is, my doing some sort of linear interpolation on the width of each interval.
</p>
          <p>So, for medians, consider the following approach:
</p>
          <p>
<ol><li>Compute frequencies <m>f_k</m> and cummulative frequencies <m>F_k</m> for each class</li><li>Set m = total cummulative frequency/2 = <m>F_{last}/2</m></li><li>Determine the interval <m>k</m> where <m>m \in [F_{k-1},F_k]</m></li><li>Set median = <m>(b_k-a_k)\frac{m - F_{k-1}}{f_k}+a_k</m></li></ol>
</p>
          <p>
<example><title>Computing Median for Interval Grouped Data</title><p>
	<table halign="left"><caption>Interval Frequency Distribution</caption><tabular halign="right"><row><cell bottom="medium"><m>[a_k,b_k]</m></cell><cell bottom="medium"><m>f_k</m></cell></row><row><cell>[0,5)</cell><cell>5</cell></row><row><cell>[5,10)</cell><cell>7</cell></row><row><cell>[10,20)</cell><cell>4</cell></row><row><cell>[20,23)</cell><cell>3</cell></row><row><cell>[23,30)</cell><cell>6</cell></row></tabular></table>
The total cummulative frequency is 25 and so <m>m = \frac{25}{2} = 12.5</m> which lies in the k = 3 interval [10,20) and <m>F_2 = 12</m>.  Therefore
<me>\text{median} = (20-10) \frac{12.5-12}{4} + 10 = 11.25</me>
</p></example>
</p>
        </subsection>
      </section>
      <section>
        <title>Other Statistical Point Measures</title>
        <p>Above, we have investigated statistical measures that help determine the middle and the spread of a given data set. There are however other metrics available that help describe the distribution of that data.  Skewness is one of those metrics and describes any lack of symmetry of the data set's distribution and whether data is stretched out to one side or the other.
</p>
        <p>
<definition><title>Skewness</title><statement><p xml:id="Skewness">For population data, the Skewness of <m>x_1, x_2, ..., x_n</m> is given by
<me> \frac{1}{\sigma^3} \frac{\sum_{k=1}^n ( x_k-\mu )^3}{n}.</me>
</p><p>For sample data, the Skewness of <m>x_1, x_2, ..., x_n</m> is given by
<me> \frac{1}{s^3} \frac{\sum_{k=1}^n ( x_k-\overline{x} )^3}{n}.</me>
</p></statement></definition>
</p>
        <p>
A positive skewness indicates that the positive <m>(x_k - \mu)^3</m> terms (likewise <m>(x_k - \overline{x})^3</m> terms) overwhelm the negative terms. So, a positive skewness indicates that the data set is strung out to the right. Likewise, a negative skewness indicates a data set that is strung out to the left.
</p>
        <p>
Data might tend to be clustered around the mean. The "kurtosis" can be used to measure how closely data resembles a "bell-shaped" collection.
</p>
        <p>
<definition><title>Kurtosis</title><statement><p xml:id="Kurtosis">For population data, the Kurtosis of <m>x_1, x_2, ..., x_n</m> is given by
<me> \frac{1}{\sigma^4} \frac{\sum_{k=1}^n ( x_k-\mu )^4}{n}.</me>
</p><p>For sample data, the Kurtosis of <m>x_1, x_2, ..., x_n</m> is given by
<me> \frac{1}{s^4} \frac{\sum_{k=1}^n ( x_k-\overline{x} )^4}{n}.</me>
</p></statement></definition>
</p>
        <p>
A kurtosis of 3 indicates that the data is perfectly bell shaped (a "normal" distribution) whereas data further away from 3 indicates data that is less bell shaped.
</p>
        <theorem>
          <title>Alternate Formulas for Skewness and Kurtosis</title>
          <statement>
Skewness = 
<me>\text{skewness} = \frac{1}{s^3} 
\left [ \frac{\sum_{k=1}^n x_k^3}{n} - 3 v \overline{x} - \overline{x}^3 \right ]</me>
and Kurtosis =
<me>\text{kurtosis} = \frac{1}{s^4} 
\left [ \frac{\sum_{k=1}^n x_k^4}{n} - 4 \overline{x} \frac{\sum_{k=1}^n x_k^3 }{n} + 6 \overline{x}^2 v - 3 \overline{x}^4  \right ]</me><proof><p>
For skewness, expand the cubic and break up the sum. Factoring out constants (such as <m>\overline{x}</m>) gives
<md><mrow>&amp; \frac{\sum_{k=1}^n ( x_k-\overline{x} )^3}{n}</mrow><mrow>&amp; = \frac{\sum_{k=1}^n x_k^3}{n} - 3 \overline{x} \frac{\sum_{k=1}^n x_k^2 }{n} + 3 \overline{x}^2 \frac{\sum_{k=1}^n x_k}{n} - \frac{\sum_{k=1}^n \overline{x}^3}{n}</mrow><mrow>&amp; = \frac{\sum_{k=1}^n x_k^3}{n} - 3 \overline{x}(v + \overline{x}^2) + 3 \overline{x}^3 - \overline{x}^3</mrow><mrow>&amp; = \frac{\sum_{k=1}^n x_k^3}{n} - 3 \overline{x}v - \overline{x}^3</mrow></md>
and divide by the cube of the standard deviation to finish. Note that the first expansion in the derivation above can be used quickly if the data is collected in a table and powers easily computed.
</p><p>
For kurtosis, similarly expand the quartic and break up the sum as before. Note that you can extract the value of the cubic term by solving for that term in the skewness formula above. Then,
<md><mrow>&amp; \frac{\sum_{k=1}^n ( x_k-\overline{x} )^4}{n}</mrow><mrow>&amp; = \frac{\sum_{k=1}^n x_k^4}{n} - 4 \overline{x} \frac{\sum_{k=1}^n x_k^3 }{n} + 6 \overline{x}^2 \frac{\sum_{k=1}^n x_k^2}{n} - 4 \overline{x}^3 \frac{\sum_{k=1}^n x_k}{n} + \frac{\sum_{k=1}^n \overline{x}^4}{n}</mrow><mrow>&amp; = \frac{\sum_{k=1}^n x_k^4}{n} - 4 \overline{x} \frac{\sum_{k=1}^n x_k^3 }{n} + 6 \overline{x}^2 (v+\overline{x}^2) - 4 \overline{x}^4 + \overline{x}^4</mrow><mrow>&amp; = \frac{\sum_{k=1}^n x_k^4}{n} - 4 \overline{x} \frac{\sum_{k=1}^n x_k^3 }{n} + 6 \overline{x}^2 v - 3 \overline{x}^4 </mrow></md>
and then divide by the fourth power of the standard deviation.  Note again that the first expansion in the derivation above might also be a useful shortcut.
</p></proof></statement>
        </theorem>
        <p>Going back to a previous example...</p>
        <p>
Computing skewness and kurtosis by hand can often be better organized using a table. Below, notice that the <m>x_k</m> column would be the given data values but the other columns you could again easily compute.

<table halign="left"><tabular halign="right"><row><cell bottom="medium"><m>x_k</m></cell><cell bottom="medium"><m>x_k^2</m></cell><cell bottom="medium"><m>x_k^3</m></cell><cell bottom="medium"><m>x_k^4</m></cell></row><row><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>-1</cell><cell>1</cell><cell>-1</cell><cell>1</cell></row><row><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>2</cell><cell>4</cell><cell>8</cell><cell>16</cell></row><row><cell>2</cell><cell>4</cell><cell>8</cell><cell>16</cell></row><row><cell>5</cell><cell>25</cell><cell>125</cell><cell>625</cell></row></tabular><caption>Computing data statistics by hand</caption></table>

So, <m>\Sigma x_k = 9</m> and <m>\Sigma x_k^2 = 35</m> as before and so
<m>\overline{x} = \frac{3}{2}</m>, <m>v = \frac{26}{6}</m>, <m>s^2 = \frac{6}{5} \times v = \frac{26}{5}</m>, and so <m>s = \sqrt{\frac{26}{5}} = \sqrt{5.2}</m>.

But also, <m>\Sigma x_k^3 = 141</m> and <m>\Sigma x_k^4 = 659</m>.  Use these in the formulas above to obtain skewness of

<me>\left [ \frac{141}{6} - 3 \cdot \frac{26}{5} \cdot \frac{3}{2} - \left ( \frac{3}{2} \right )^2 \right ] / s^3 </me>

and kurtosis of 

<me>\left [ \frac{659}{6} - 4 \cdot \frac{3}{2} \cdot \frac{141}{6} + 6 \left ( \frac{3}{2} \right )^2  \cdot \frac{26}{5}  - 3 \cdot \left ( \frac{3}{2} \right )^4 \right ] / s^4.</me>
</p>
      </section>
      <section>
        <title>Visual Statistical Measures - Graphical Representation of Data</title>
        <introduction>
          <p>Data sets can range from small to very large. Visual representations of these data sets often allow you to see trends and reveal a lot about the distribution of the data values.</p>
        </introduction>
        <subsection>
          <title>Histograms</title>
          <p>Frequency Histograms - height matters</p>
          <p>Consider the data set given by
		
<table halign="left"><caption>Basic Frequency Table</caption><tabular halign="right"><row><cell bottom="medium"><m>x_k</m></cell><cell bottom="medium"><m>f_k</m></cell></row><row><cell>1</cell><cell>8</cell></row><row><cell>2</cell><cell>12</cell></row><row><cell>3</cell><cell>6</cell></row><row><cell>4</cell><cell>3</cell></row><row><cell>5</cell><cell>1</cell></row><row><cell>6</cell><cell>2</cell></row></tabular></table>
</p>
          <p>	
A frequency histogram representing this data looks like

<image source="images/frequencyhistogram.png"/>
</p>
          <p>Experiment with creating your own histogram by inputting your data into the interactive Sage cell below.
<sage><input>
#  This function is used to convert an input string into separate entries
def g(s): return str(s).replace(',',' ').replace('(',' ').replace(')',' ').split()

@interact
def _(freq = input_box("1,1,1,1,2,2,2,3,3,3,3,1,5",label="Enter data separated by commas")):
    freq = g(freq)
    freq = [int(k) for k in freq]
    m = min(freq)
    M = max(freq)
    bn = M-m+1
    histogram( freq, range=[m-1/2,M+1/2], bins = bn, align="mid", linewidth=2, edgecolor="blue", color="yellow").show()
</input></sage>

</p>
          <p>
Relative Frequency Histograms - In this case, area describes relative frequency.  Notice in the interactive cell above that each bar is of width one. Therefore, frequency = area. In some instances where data may be grouped the total width of the interval may be different and so the height will need to be adjusted so that the total area of each bar corresponds to the relative frequency of that category.
</p>
          <p>Cummulative Histograms.  In these a running total is presented using all values from the given point and below.
<sage><input>
#  This function is used to convert an input string into separate entries
def g(s): return str(s).replace(',',' ').replace('(',' ').replace(')',' ').split()

@interact
def _(freq = input_box("1,1,1,1,2,2,2,3,3,3,3,1,5",label="Enter data separated by commas")):
    freq = g(freq)
    freq = [int(k) for k in freq]
    top = len(freq)
    m = min(freq)
    M = max(freq)
    bn = M-m+1
    histogram( freq, range=[m-1/2,M+1/2], cumulative = "true", bins = bn, align="mid", linewidth=2, edgecolor="blue", color="yellow").show(ymax=top)
</input></sage>		
</p>
        </subsection>
        <subsection>
          <title>Stem and Leaf Plot</title>
          <p> 
A Stem and Leaf Plot allows you to create a histogram of sorts but maintain the individual data values. To create one of these plots, you will need to consider your particular data set and create a two-step sieve for organizing the set.  The first part is to create "stems" that are often associated with the highest digit(s) of each data value and the "leaves" that are often associated with the remaining digit(s) of the data value.
</p>
          <p>
Once the data set is broken down into stems and leaves, it is often simple to sort the leaves under each stem to yield an "ordered Stem and Leaf Plot". Such as mechanism is a simple two-step procedure that allows you to sort a data set by hand.
</p>
          <p>
<example><title>Simple Stem and Leaf Plot</title><p>
Consider the data points 25, 3, 17, 12, 22, 34, 12, 11, 16, 42, 9, 12, 17.
In this case we will consider the stems to be the tens digits and the leaves to be the ones digits. This gives
</p><p>
<table halign="left"><caption>Stem and Leaf Plot (unordered)</caption><tabular halign="right"><row><cell bottom="medium">Stems</cell><cell bottom="medium">Leaves</cell></row><row><cell>0</cell><cell halign="left">3 9</cell></row><row><cell>1</cell><cell halign="left">7 2 2 1 6 2 7</cell></row><row><cell>2</cell><cell halign="left">5 2</cell></row><row><cell>3</cell><cell halign="left">4</cell></row><row><cell>4</cell><cell halign="left">2</cell></row></tabular></table>
Then, an ordered Stem and Leaf Plot would be

<table halign="left"><caption>Stem and Leaf Plot (ordered)</caption><tabular halign="right"><row><cell bottom="medium">Stems</cell><cell bottom="medium">Leaves</cell></row><row><cell>0</cell><cell halign="left">3 9</cell></row><row><cell>1</cell><cell halign="left">1 2 2 2 6 7 7</cell></row><row><cell>2</cell><cell halign="left">2 5</cell></row><row><cell>3</cell><cell halign="left">4</cell></row><row><cell>4</cell><cell halign="left">2</cell></row></tabular></table>
</p><p>
Notice, in each case you can extract the original data values by recombining the stem with a corresponding leaf. Indeed, for these 13 data values the median should be be 7th in the sorted list or the value in the 10's stem with leaf 6...that is, 16.
</p></example>
</p>
          <p>
<example><title>Stem and Leaf Plot for State Populations</title><p>
Using the state population data above, consider organizing the data but using a "two-pass sort" where you first roughly break data up into groups based upon ranges which relate to their first digit(s). In this case, let's break up into groups according to populations corresponding to 0-4 million, 5-9 million, 10-14 million, 15-19, million, 20-24 million, 25-29 million, 30-35 million, and 35-39 million. We can represent these classes by using the stems 0L, 0H, 1L, 1H, 2L, 2H, 3L, and 3H where the L and H represent the one's digits L in {0, 1, 2, 3, 4} and H in {5, 6, 7, 8, 9}.  Once we group the data into these smaller groups then we can write the remaining portion of the number horizontally as leaves (in this case with one decimal place for all values.) This gives a step-and-leaf plot. If we additionally sort the data in the leaves then this gives you an ordered stem-and-leaf plot. For the state population data, the ordered stem-and-leaf plot is given by
		
	
<image source="images/stemandleaf.png"/>

Notice how it is easy to now see that most state populations are relatively small and that there are relatively few states with larger population. Also, notice that you can use this plot to relatively easily identify minimum, maximum, and other order statistics.		
</p></example>
</p>
        </subsection>
        <subsection>
          <title>Box and Whisker Diagram (Box Plot)</title>
          <p>This graphical display identifies the "5-number-summary" associated with the minimum, quartiles, and the maximum. That is, <m>y_1, Q_1, Q_2, Q_3, y_n</m>.  These values separate the data roughly into quarters. To distinguish these quarters connect <m>y_1</m> and <m>Q_1</m> with a straight line (a whisker) and do the same with <m>Q_3</m> and <m>y_n</m>. Use a box to connect <m>Q_1</m> with <m>Q_2</m> and the same to connect <m>Q_2</m> with <m>Q_3</m>. Then the boxed areas also identify the IQR.  
</p>
          <p>
<sage language="r"><input>
data &lt;- c (0.6,0.6,0.6,0.7,0.7,0.8,0.9,1,1.1,1.3,1.3,
1.4,1.6,1.9,1.9,2.1,2.8,2.9,2.9,3,3,3.1,
3.6,3.9,3.9,4.4,4.6,4.8,4.8,5.3,5.4,5.7,
5.9,6,6.5,6.6,6.6,6.7,7,8.3,8.9,9.8,9.9,
10,11.6,12.8,12.9,19.6,19.7,26.4,38.3)
paste("Inter Quantile Range =",IQR(data))
paste("Box and Whisker Diagram - Box Plot):")
boxplot(data, horizontal=TRUE)
</input></sage>
</p>
          <p><title>Computing Percentiles</title>
<exercise><introduction><p>
		Let's use a box plot to determine some order statistics.
		</p></introduction><webwork-reps xml:id="extracted-webwork-2" ww-id="webwork-2">
    <pg source="Library/NAU/setStatistics/FiveNumFromPlot.pg"/>

      
    <static source="Library/NAU/setStatistics/FiveNumFromPlot.pg" seed="2">
      <statement><p>Consider the following box and whisker plot.  Find the indicated values of the represented data.</p><sidebyside widths="116.666666666667%"><image source="images/webwork-2-image-1.png"/></sidebyside><p>Median: <fillin name="AnSwEr0001" characters="5"/></p><p>Maximum: <fillin name="AnSwEr0002" characters="5"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=2&amp;sourceFilePath=Library/NAU/setStatistics/FiveNumFromPlot.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=2&amp;sourceFilePath=Library/NAU/setStatistics/FiveNumFromPlot.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=2&amp;sourceFilePath=Library/NAU/setStatistics/FiveNumFromPlot.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=2&amp;sourceFilePath=Library/NAU/setStatistics/FiveNumFromPlot.pg</server-url>

  </webwork-reps><conclusion><p>
		
		</p></conclusion></exercise>
</p>
        </subsection>
        <subsection>
          <title>Density Plots</title>
          <p>
A Density Plot can be created to visually interpret if the variable is close to normal
</p>
          <sage language="r">
            <input>
library(e1071)
par(mfrow=c(1,2))    # graph into two columns
plot(density(cars$speed), main="Density Plot: Speed", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(cars$speed),2)))

</input>
          </sage>
          <p>
www.machinelearningplus.com
</p>
        </subsection>
      </section>
      <section>
        <title>Summary</title>
        <introduction>
          <p>
Links to the main formulas related to descriptive statistics:
</p>
        </introduction>
        <p>
          <xref ref="OrderStatistics">Order Statistics</xref>
        </p>
        <p>
          <xref ref="MaxMin">Maximum and Minimum</xref>
        </p>
        <p>
          <xref ref="Percentiles">Percentiles</xref>
        </p>
        <p>
          <xref ref="Quartiles">Quartiles</xref>
        </p>
        <p>
          <xref ref="Deciles">Deciles</xref>
        </p>
        <p>
          <xref ref="FiveNumberSummary">5-number summary</xref>
        </p>
        <p>
          <xref ref="Mean">Mean</xref>
        </p>
        <p>
          <xref ref="Median">Median</xref>
        </p>
        <p>
          <xref ref="Midrange">Midrange</xref>
        </p>
        <p>
          <xref ref="Range">Range</xref>
        </p>
        <p>
          <xref ref="IQR">Inter Quartile Range</xref>
        </p>
        <p>
          <xref ref="Variance">Variance</xref>
        </p>
        <p>
          <xref ref="Skewness">Skewness</xref>
        </p>
        <p>
          <xref ref="Kurtosis">Kurtosis</xref>
        </p>
      </section>
      <section>
        <title>Exercises</title>
        <p>Complete the online WebWorK homework set "Computational Measures".</p>
        <exercise>
          <statement>
            <p>Create a data set with about 10 elements. For your data set, compute each of the measures from this chapter and present your data using a frequency histogram.</p>
          </statement>
        </exercise>
        <exercise>
          <statement>
            <p>Find a "real-world" data set (similar perhaps to the Census data presented above.) Compute each of the measures from this chapter. Interpret and present your conclusions in an electronic report which can include an excel spreadsheet.</p>
          </statement>
        </exercise>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="CurveEstimation">
      <title>Regression</title>
      <section>
        <title>Introduction</title>
        <p>
When computing means, medians, variances, etc. in the previous chapter, you took given data and create measures that in some sense describe the data using a single value. These single values can be called "descriptive statistics" or perhaps "point estimates" that help understand the properties of the original data set.  In this chapter, you will instead take a data set and create a mathematical model that can be used to predict or infer properties of the underlying problem. Statistical procedures such as in this chapter that are used to predict are often lumped into the world of "inferential statistics".
</p>
        <p> 
So, given a set of data points <m>(x_0,y_0), (x_1,y_1), ... (x_n,y_n)</m>, it is often desirable to have a nice continuous formula <m>y = f(x)</m> that expresses the general nature of those data points. Such a formula "interpolates" the data points if 
<me>y_k = f(x_k),</me> 
that is the formula gives a graph that exactly passes through each of the given data points.</p>
        <p>
On the other hand, sometimes the data points are known to be only approximate or the complexity of the formula needed to interpolate all of the data points exactly is too large. In this case, the formula may only be required to return values that are relatively close to the data points. Such a formula is said to "approximate" and gives 
<me>y_k \approx f(x_k).</me>
Let's consider ways to create useful models that approximate the data points.
</p>
        <p>
From basic algebra, if you are given two distinct points then there is one line which passes exactly through (i.e. interpolates) both. There are many ways to create this linear model but for points <m>(x_0,y_0), (x_1,y_1)</m>,

<me> y = \frac{y_1 - y_0}{x_1 - x_0}(x - x_0) + y_0</me>

is the linear function which passes through both points if the x-values are distinct.  If the x's are equal then 
<me> x = x_0</me>
is linear and interpolates both data points. 
However, once you collect three or more points it is likely that there is no line which exactly "interpolates" all of the points. If we desire a linear model then we must settle for a model that approximates. In this chapter, you will investigate how to create polynomial functions which in some manner approximate a collection of data point in some "best" manner.
</p>
      </section>
      <section>
        <title>Linear Regression - Best Fit Line</title>
        <p>
In the next few sections, we will presume only one independent variable x and one dependent variable y. Toward that end, consider a collection of data points 
<me>(x_0,y_0), (x_1,y_1), ... , (x_n,y_n)</me>
and a general linear function 
<me>f(x) = mx + b.</me>
It is possible but generally unlikely that each of the given data points will be interpolated exactly by the linear function. However, you may notice that the data points exhibit a linear tendency or that the underlying physics might suggest a linear model. A "scatter plot" of a example data set is created in teh interactive cell below and the provided data appears to indicate a linear trend. In general, if this is the case then you may find it easier to predict values of y for given values of x using a linear approximation. That is why this method for doing so is also often called a "best-fit line". 
</p>
        <p>
<sage><input>
var('x')
@interact
def _(Points = input_box([(-1,1),(3,2),(4,3),(6,4)])):   
    G = points(Points,size=20)
    G.show(title = "Scatter Plot")
</input></sage>
</p>
        <p>
But why even bother creating a formula (a line here) to approximate data that does not satisfy that formula? Remember that you would expect collected data to vary slightly as one repeatedly collects that data in the same way that you would expect to make a slightly different score on repeated attempts at exams on the same material. Creating a formula that is close to your data gives a well-defined way to predict a y value for a given x value. This predictive behavior is illustrated in the exercise below.
</p>
        <p>
<exercise><title>WebWork - Using an approximating line</title><webwork-reps xml:id="extracted-webwork-3" ww-id="webwork-3">
    <authored>
      
        <statement><p>An airline has determined that the relationship between the number of passengers on a flight and the total weight of luggage stored in the baggage compartment can be estimated by the least squares regression equation 
            <me>y = 127 + 28 x.</me> 
      Predict the weight of luggage for a flight with 121 passengers.</p><p>Answer: <var name="'3515'" width="15"/> pounds</p></statement>
        <solution>
            Since x represents weight, choose x = 121 and evaluate the line at that value to get the estimated total luggage weight to be
            <me>y = 127 + 28 (121) = 3515</me></solution>
      
    </authored>

    <pg>
      #######################################
      ###    Generated from PreTeXt source   
      ###    on 2018-11-07T13:06:50-06:00    
      ###                                    
      ###   http://mathbook.pugetsound.edu   
      ###                                    
      #######################################
      ## DBsubject()
      ## DBchapter()
      ## DBsection()
      ## Level()
      ## KEYWORDS()
      ## TitleText1(Essentials of Mathematical Probability and Statistics)
      ## EditionText1()
      ## AuthorText1(John Travis)
      ## Section1(not reported)
      ## Problem1(2.2.1)
      ## Author()
      ## Institution()
      ## Language(en-US)
      
      DOCUMENT();
      
      ############################################################
      # Load Macros
      ############################################################
      loadMacros(
        "PGstandard.pl",
        "MathObjects.pl",
        "PGML.pl",
        "AnswerFormatHelp.pl",
        "PGcourse.pl",
      );
      
      ############################################################
      # Header
      ############################################################
      COMMENT('Authored in PreTeXt');
      TEXT(beginproblem());
      
      ############################################################
      # PG Setup
      ############################################################
      Context('Numeric');
      
      ############################################################
      # Body
      ############################################################
      
      BEGIN_PGML
      An airline has determined that the relationship between the number of passengers on a flight and the total weight of luggage stored in the baggage compartment can be estimated by the least squares regression equation
      
      [```y = 127 + 28 x.```]
      
      Predict the weight of luggage for a flight with 121 passengers.
      
      Answer: [__]{'3515'}{width =&gt; 15} pounds
      
      END_PGML
      
      ############################################################
      # Solution
      ############################################################
      
      BEGIN_PGML_SOLUTION
      Since x represents weight, choose x = 121 and evaluate the line at that value to get the estimated total luggage weight to be
      
      [```y = 127 + 28 (121) = 3515```]
      
      END_PGML_SOLUTION
      
      ############################################################
      # End Problem
      ############################################################
      
      ENDDOCUMENT();
      
    </pg>

      
    <static seed="3">
      <statement><p>An airline has determined that the relationship between the number of passengers on a flight and the total weight of luggage stored in the baggage compartment can be estimated by the least squares regression equation</p><p><me>y = 127 + 28 x.</me></p><p>Predict the weight of luggage for a flight with 121 passengers.</p><p>Answer: <fillin name="AnSwEr0001" characters="15"/> pounds</p></statement>
      
      <solution><p>Since x represents weight, choose x = 121 and evaluate the line at that value to get the estimated total luggage weight to be</p><p><me>y = 127 + 28 (121) = 3515</me></p></solution>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=3&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkFuIGFpcmxpbmUgaGFzIGRldGVybWluZWQgdGhhdCB0aGUgcmVsYXRpb25zaGlwIGJldHdlZW4gdGhlIG51bWJlciBvZiBwYXNzZW5nZXJzIG9uIGEgZmxpZ2h0IGFuZCB0aGUgdG90YWwgd2VpZ2h0IG9mIGx1Z2dhZ2Ugc3RvcmVkIGluIHRoZSBiYWdnYWdlIGNvbXBhcnRtZW50IGNhbiBiZSBlc3RpbWF0ZWQgYnkgdGhlIGxlYXN0IHNxdWFyZXMgcmVncmVzc2lvbiBlcXVhdGlvbgoKW2BgYHkgPSAxMjcgKyAyOCB4LmBgYF0KClByZWRpY3QgdGhlIHdlaWdodCBvZiBsdWdnYWdlIGZvciBhIGZsaWdodCB3aXRoIDEyMSBwYXNzZW5nZXJzLgoKQW5zd2VyOiBbX117JzM1MTUnfXt3aWR0aD0%2BMTV9IHBvdW5kcwoKCkVORF9QR01MCgpCRUdJTl9QR01MX1NPTFVUSU9OClNpbmNlIHggcmVwcmVzZW50cyB3ZWlnaHQsIGNob29zZSB4ID0gMTIxIGFuZCBldmFsdWF0ZSB0aGUgbGluZSBhdCB0aGF0IHZhbHVlIHRvIGdldCB0aGUgZXN0aW1hdGVkIHRvdGFsIGx1Z2dhZ2Ugd2VpZ2h0IHRvIGJlCgpbYGBgeSA9IDEyNyArIDI4ICgxMjEpID0gMzUxNWBgYF0KCgpFTkRfUEdNTF9TT0xVVElPTgoKRU5ERE9DVU1FTlQoKTs%3D</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=3&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkFuIGFpcmxpbmUgaGFzIGRldGVybWluZWQgdGhhdCB0aGUgcmVsYXRpb25zaGlwIGJldHdlZW4gdGhlIG51bWJlciBvZiBwYXNzZW5nZXJzIG9uIGEgZmxpZ2h0IGFuZCB0aGUgdG90YWwgd2VpZ2h0IG9mIGx1Z2dhZ2Ugc3RvcmVkIGluIHRoZSBiYWdnYWdlIGNvbXBhcnRtZW50IGNhbiBiZSBlc3RpbWF0ZWQgYnkgdGhlIGxlYXN0IHNxdWFyZXMgcmVncmVzc2lvbiBlcXVhdGlvbgoKW2BgYHkgPSAxMjcgKyAyOCB4LmBgYF0KClByZWRpY3QgdGhlIHdlaWdodCBvZiBsdWdnYWdlIGZvciBhIGZsaWdodCB3aXRoIDEyMSBwYXNzZW5nZXJzLgoKQW5zd2VyOiBbX117JzM1MTUnfXt3aWR0aD0%2BMTV9IHBvdW5kcwoKCkVORF9QR01MCgpFTkRET0NVTUVOVCgpOw%3D%3D</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=3&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkFuIGFpcmxpbmUgaGFzIGRldGVybWluZWQgdGhhdCB0aGUgcmVsYXRpb25zaGlwIGJldHdlZW4gdGhlIG51bWJlciBvZiBwYXNzZW5nZXJzIG9uIGEgZmxpZ2h0IGFuZCB0aGUgdG90YWwgd2VpZ2h0IG9mIGx1Z2dhZ2Ugc3RvcmVkIGluIHRoZSBiYWdnYWdlIGNvbXBhcnRtZW50IGNhbiBiZSBlc3RpbWF0ZWQgYnkgdGhlIGxlYXN0IHNxdWFyZXMgcmVncmVzc2lvbiBlcXVhdGlvbgoKW2BgYHkgPSAxMjcgKyAyOCB4LmBgYF0KClByZWRpY3QgdGhlIHdlaWdodCBvZiBsdWdnYWdlIGZvciBhIGZsaWdodCB3aXRoIDEyMSBwYXNzZW5nZXJzLgoKQW5zd2VyOiBbX117JzM1MTUnfXt3aWR0aD0%2BMTV9IHBvdW5kcwoKCkVORF9QR01MCgpCRUdJTl9QR01MX1NPTFVUSU9OClNpbmNlIHggcmVwcmVzZW50cyB3ZWlnaHQsIGNob29zZSB4ID0gMTIxIGFuZCBldmFsdWF0ZSB0aGUgbGluZSBhdCB0aGF0IHZhbHVlIHRvIGdldCB0aGUgZXN0aW1hdGVkIHRvdGFsIGx1Z2dhZ2Ugd2VpZ2h0IHRvIGJlCgpbYGBgeSA9IDEyNyArIDI4ICgxMjEpID0gMzUxNWBgYF0KCgpFTkRfUEdNTF9TT0xVVElPTgoKRU5ERE9DVU1FTlQoKTs%3D</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=3&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkFuIGFpcmxpbmUgaGFzIGRldGVybWluZWQgdGhhdCB0aGUgcmVsYXRpb25zaGlwIGJldHdlZW4gdGhlIG51bWJlciBvZiBwYXNzZW5nZXJzIG9uIGEgZmxpZ2h0IGFuZCB0aGUgdG90YWwgd2VpZ2h0IG9mIGx1Z2dhZ2Ugc3RvcmVkIGluIHRoZSBiYWdnYWdlIGNvbXBhcnRtZW50IGNhbiBiZSBlc3RpbWF0ZWQgYnkgdGhlIGxlYXN0IHNxdWFyZXMgcmVncmVzc2lvbiBlcXVhdGlvbgoKW2BgYHkgPSAxMjcgKyAyOCB4LmBgYF0KClByZWRpY3QgdGhlIHdlaWdodCBvZiBsdWdnYWdlIGZvciBhIGZsaWdodCB3aXRoIDEyMSBwYXNzZW5nZXJzLgoKQW5zd2VyOiBbX117JzM1MTUnfXt3aWR0aD0%2BMTV9IHBvdW5kcwoKCkVORF9QR01MCgpFTkRET0NVTUVOVCgpOw%3D%3D</server-url>

  </webwork-reps></exercise>
</p>
        <p>
To determine this best-fit line, you need to determine what is meant by the word "best". For linear regression, to reach this goal consider the total of all vertical deviations between the desired line and the provided data points.  Indeed, this vertical error would be of the form
<me>e_k = f(x_k) - y_k</me>
and would be zero if f(x) exactly interpolated at the given data point.  Note, some of these errors will be positive and some will be negative. To avoid any possible cancellation of errors, we could consider taking absolute values (which is tough to deal with algebraically) or perhaps squaring the errors. This second option is the standard approach. This approach is similar to the approach taken earlier when developing formulas for the variance.
</p>
        <p>The best-fit line therefore will be the line <m>f(x) = mx+b</m> so that the "total squared error" is minimized. This total squared error is given by
<me>TSE(m,b) = \sum_{k=1}^n e_k^2 = \sum_{k=1}^n (f(x_k) - y_k)^2 = \sum_{k=1}^n (m x_k + b - y_k)^2.</me>
</p>
        <p>
For the following interactive cell, consider for the given data points various values for the slope and y-intercept and see if you can make the total squared error as small as possible. In doing so, notice the vertical distances from the line to the given data points generally decreases as this error measure gets smaller. 
</p>
        <p>
<sage><input>
var('x')
@interact
def _(Points = input_box([(-1,1),(3,1),(4,3),(6,4)]), m = slider(-4,4,1/50,1),b = slider(-2,2,1/50,1)):   
    G = points(Points,size=20)
    xpt = []
    ypt = []
    f = m*x + b
    TSE = 0
    for k in range(len(Points)):
        x0 = Points[k][0]
        xpt.append(x0)
        y0 = Points[k][1]
        ypt.append(y0)
        TSE += (f(x=x0) - y0)^2
        G += line([(x0,f(x=x0)),(x0,y0)],color='orange')
    G += plot(f,x,min(xpt)-0.2,max(xpt)+0.2,color='gray')
    T = 'Total Squared Error = $%s$'%str(n(TSE))
    G.show(title = T)
</input></sage>
</p>
        <p>
<exercise><title>Non-functional data</title><p>
Experiment in the interactive cell above using exactly two data points that have the same x-value.  Such as (1,1) and (1,2). Next, add some additional data points in the same general vicinity as your original two points. What is the effect to your best-fit line of adding non-functional points?
</p></exercise>
</p>
        <p>
So that we don't have to guess the best values for slope and intercept, we can appeal to calculus. Indeed, to minimize this function of the two variables m and b take partial derivatives and set them equal to zero to get the critical values:
<me>TSE_m = \sum_{k=1}^n 2(m x_k + b - y_k) \cdot x_k</me>
and
<me>TSE_b = \sum_{k=1}^n 2(m x_k + b - y_k) \cdot 1 .</me>
Setting each of these equations equal to zero (using calculus!) and solving gives what is known as the "normal equations":
<me>m \sum_{k=1}^n x_k^2 + b \sum_{k=1}^n x_k = \sum_{k=1}^n x_k y_k</me>
and
<me>m \sum_{k=1}^n x_k + b \sum_{k=1}^n 1 = \sum_{k=1}^n y_k.</me>
Notice that these normal equations are a linear system of equations and (among perhaps other reasons) is why this is called linear regression. Solving these for m and b gives the best fit line.
</p>
        <p>
So, let's see how to graph points against the best-fit line using R
</p>
        <p>
<sage language="r"><input>
x &lt;- c(1, 2, 3, 5, 5, 6)
y &lt;- c(5, 4, 2, 2, 3, 1)
cor(x,y)   # correlation coefficient
pts = data.frame(x, y)
plot(pts,pch = 16, cex = 1.0, col = "blue", main = "Scatter Plot vs Best-Fit Line", xlab = "x", ylab = "y")
# pch = 16 creates solid dots, while cex = 1.5 creates dots that are 1.5 times bigger than the default.
lm(y ~ x)
abline(lm(y ~ x))
</input></sage>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		Ok.  Let's see if you can apply this to get a best fit line.
		</p></introduction><webwork-reps xml:id="extracted-webwork-4" ww-id="webwork-4">
    <pg source="Library/ASU-topics/setStat/dueck4_2_4.pg"/>

      
    <static source="Library/ASU-topics/setStat/dueck4_2_4.pg" seed="4">
      <statement><p>A study was conducted to detemine whether a the final grade of a student in an introductory psychology
      course is linearly related to his or her performance on the verbal ability test administered before
      college entrance.  The verbal scores and final grades for <m>10</m> students are shown in the table below.</p><sidebyside><tabular top="medium" bottom="medium" left="medium" right="medium"><row><cell>Student</cell><cell>Verbal Score <m>x</m></cell><cell>Final Grade <m>y</m></cell></row><row><cell><m>1</m></cell><cell><m>49</m></cell><cell><m>60</m></cell></row><row><cell><m>2</m></cell><cell><m>49</m></cell><cell><m>54</m></cell></row><row><cell><m>3</m></cell><cell><m>72</m></cell><cell><m>89</m></cell></row><row><cell><m>4</m></cell><cell><m>66</m></cell><cell><m>75</m></cell></row><row><cell><m>5</m></cell><cell><m>30</m></cell><cell><m>40</m></cell></row><row><cell><m>6</m></cell><cell><m>33</m></cell><cell><m>36</m></cell></row><row><cell><m>7</m></cell><cell><m>70</m></cell><cell><m>82</m></cell></row><row><cell><m>8</m></cell><cell><m>57</m></cell><cell><m>68</m></cell></row><row><cell><m>9</m></cell><cell><m>79</m></cell><cell><m>95</m></cell></row><row><cell><m>10</m></cell><cell><m>65</m></cell><cell><m>79</m></cell></row></tabular></sidebyside><p>Find the least squares line.</p><p><m>\hat{y} =</m> <fillin name="AnSwEr0001" characters="10"/> <m>+</m> <fillin name="AnSwEr0002" characters="10"/> <m>x</m></p><p>Should the regression be used to predict the final grade of a student with a verbal score of 100?</p><p>answer: <fillin name="AnSwEr0003" characters="10"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=4&amp;sourceFilePath=Library/ASU-topics/setStat/dueck4_2_4.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=4&amp;sourceFilePath=Library/ASU-topics/setStat/dueck4_2_4.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=4&amp;sourceFilePath=Library/ASU-topics/setStat/dueck4_2_4.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=4&amp;sourceFilePath=Library/ASU-topics/setStat/dueck4_2_4.pg</server-url>

  </webwork-reps><conclusion><p>

		</p></conclusion></exercise>
</p>
      </section>
      <section>
        <title>Correlation</title>
        <p>
You can plot points and plot the resulting best-fit line determined in the previous section but the question remains whether the line is any good. In particular, the real use of the line often is to subsequently predict y-values for a given x-value. However, it is very likely that the best-fit line does not even pass through any of the provided data points.  So, how can something that misses every marker still be considered a good fit. To quantify this, we first need to discuss a way to measure how two variables might vary with each other.
</p>
        <p>
<definition xml:id="Covariance"><title>Covariance</title><statement><p>Given paired (sample) data 
<me>(x_0,y_0), (x_1,y_1), ... , (x_n,y_n)</me>
with corresponding means <m>\overline{x}</m> and <m>\overline{y}</m>, the covariance is given by
<me>Cov(X,Y) = \sum_{k=0}^n (x_k-\overline{x})(y_k-\overline{y})/n</me>
and similarly if using population data in which you would use instead the mean of the x-values <m>\mu_x</m> and the mean of the y-values <m>\mu_y</m>. 
</p></statement></definition>
</p>
        <p>
<theorem><title>Alternate Formula for Covariance</title><statement><me>Cov(X,Y) = \frac{\sum_{k=0}^n x_k y_k}{n} - \overline{x} \cdot \overline{y}</me></statement><proof><p>
<md><mrow>Cov(X,Y) &amp; = \sum_{k=0}^n (x_k-\overline{x})(y_k-\overline{y})/n</mrow><mrow> &amp; = \sum_{k=0}^n \left [ x_k y_k -\overline{x}  \cdot y_k-\overline{y} \cdot x_k + \overline{x} \cdot \overline{y} \right ]/n.</mrow><mrow>&amp; = \sum_{k=0}^n x_k y_k /n - \overline{x}  \cdot \sum_{k=0}^n y_k /n - \overline{y} \cdot \sum_{k=0}^n x_k /n + \overline{x} \cdot \overline{y} </mrow></md>
which simplifies to the desired result using the definition of the mean.
</p></proof></theorem>
</p>
        <p>This general definition provides a general measure which is a second order term (like variance) but also maintains "units". To provide a unit-less metric, consider the following measure.
</p>
        <p>
<definition xml:id="CorrelationCoefficient"><title>Correlation Coefficient</title><statement><p>Given a collection of data points, the correlation coefficient is given by
<me>r = \frac{Cov(X,Y)}{s_x s_y}</me>
where <m>s_x</m> is the standard deviation of the x-values only and <m>s_y</m> is the standard deviation of the y-values only. A similar statistics for population data would instead utilize <m>\sigma_x</m> and <m>\sigma_y</m> as the respective standard deviations of the x-values and y-values.
</p></statement></definition>
</p>
        <p>
<theorem><title>Correlation Coefficient for Linear Data</title><statement><p>
If the points are colinear with a positive slope then r=1 and if the points are collinear with a negative slope then r=-1.
</p></statement><proof><p>
Assume the data points are colinear with a positive slope. Then the 
<m>TSE(m_0,b_0) = 0</m> for some <m>m_0</m> and <m>b_0</m>. For this line notice that <m>f(x_k) = y_k</m> exactly for all data points. It is easy to show then that <m>\overline{y} = m_0 \overline{x} + b_0</m> and <m>s_y = | m_0 | s_x</m>.

Therefore,
<me>Cov(X,Y) = \sum_{k=0}^n (x_k-\overline{x})(m_0 x_k + b_0 - (m_0 \overline{x} + b_0))/n = m_0 s_x^2</me>
Putting these together gives correlation coefficient
<me>r = \frac{m_0 s_x^2}{s_x m_0 s_x} = 1.</me> 
A similar proof follows in the second case by noting that <m>m_0 / | m_0 | = -1</m>.
</p></proof></theorem>
</p>
        <p>
<definition><title>Coefficient of Determination</title><statement><p>
Given the correlation coefficient r, the coefficient of determination is given by <me>r^2.</me>
This measure indicates the percentage of the variation in y that can be explained by the collection of x values. Note, if r=1 (or r=-1), then the theorem above indicates that the linear model explains the variability for all of the y-values.
</p></statement></definition>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		Interpreting correlation coefficients.
		</p></introduction><webwork-reps xml:id="extracted-webwork-5" ww-id="webwork-5">
    <pg source="Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_10_ScatterCorrelation.pg"/>

      
    <static source="Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_10_ScatterCorrelation.pg" seed="5">
      <statement><p>For each problem, select the best response.</p><p>(a) A study found a correlation of <em> r</em> = -0.61 between the gender of a worker and his or her income.  You may correctly conclude</p><p><var form="buttons">
      <li>
      <p>an arithmetic mistake was made.  Correlation must be positive.</p>
      </li>
      <li>
      <p>women earn more than men on average.</p>
      </li>
      <li>
      <p>women earn less than men on average.</p>
      </li>
      <li>
      <p>this is incorrect because <em> r</em> makes no sense here.</p>
      </li>
      <li>
      <p>None of the above.</p>
      </li>
      </var></p><p>(b) For a biology project, you measure the weight in grams and the tail length in millimeters of a group of mice. The correlation is <em> r</em> = 0.8. If you had measured tail length in centimeters instead of millimeters, what would be the correlation? (There are 10 millimeters in a centimeter.)</p><p><var form="buttons">
      <li>
      <p>0.8/10 = 0.08</p>
      </li>
      <li>
      <p>(0.8)(10) = 8</p>
      </li>
      <li>
      <p>0.8</p>
      </li>
      <li>
      <p>None of the above.</p>
      </li>
      </var></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=5&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_10_ScatterCorrelation.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=5&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_10_ScatterCorrelation.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=5&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_10_ScatterCorrelation.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=5&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_10_ScatterCorrelation.pg</server-url>

  </webwork-reps><conclusion><p>
		
		</p></conclusion></exercise>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		Interpreting correlation coefficients.
		</p></introduction><webwork-reps xml:id="extracted-webwork-6" ww-id="webwork-6">
    <pg source="Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_07_ScatterCorrelation.pg"/>

      
    <static source="Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_07_ScatterCorrelation.pg" seed="6">
      <statement><p>For each problem, select the best response.</p><p>(a)   What are all the values that a correlation <em> r</em> can possibly take?</p><p><var form="buttons">
      <li>
      <p>0 <m>\le</m> <em> r </em> <m>\le</m> 1</p>
      </li>
      <li>
      <p><em> r </em> <m>\ge</m> 0</p>
      </li>
      <li>
      <p>-1  <m>\le</m> <em> r </em> <m>\le</m> 1</p>
      </li>
      <li>
      <p>None of the above.</p>
      </li>
      </var></p><p>(b)   You have data for many years on the average price of a barrel of oil and the average retail price of a gallon of unleaded regular gasoline. When you make a scatterplot, the explanatory variable on the <em> x </em> -axis</p><p><var form="buttons">
      <li>
      <p>can be either oil price or gasoline price.</p>
      </li>
      <li>
      <p>is the price of gasoline.</p>
      </li>
      <li>
      <p>is the price of oil.</p>
      </li>
      <li>
      <p>None of the above.</p>
      </li>
      </var></p><p>(c)   In a scatterplot of the average price of a barrel of oil and the average retail price of a gallon of gasoline, you expect to see</p><p><var form="buttons">
      <li>
      <p>a positive association.</p>
      </li>
      <li>
      <p>a negative association.</p>
      </li>
      <li>
      <p>very little association.</p>
      </li>
      <li>
      <p>None of the above.</p>
      </li>
      </var></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=6&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_07_ScatterCorrelation.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=6&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_07_ScatterCorrelation.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=6&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_07_ScatterCorrelation.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=6&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch04ScatterplotsAndCorrelation/04Stats_07_ScatterCorrelation.pg</server-url>

  </webwork-reps><conclusion><p>
		
		</p></conclusion></exercise>
</p>
        <p>
<exercise><title>Correlation equaling 0</title><p>
Consider the data points (1,1), (1,2), (2,1), (2,2).  Plot these points and consider the nature of the best fit line. Show using software that the correlation coefficient is zero. Justify why TSE(m,b) = 1 must be the minimum.
</p></exercise>
</p>
      </section>
      <section>
        <title>Higher Degree Linear Regression</title>
        <p>
Continuing in a similar fashion to the previous section, consider now an approximation using a quadratic function <m>f(x) = a x^2 + b x + c</m>.  In this case, the total squared error would be of the form
<me>TSE(a,b,c) = \sum_{k=0}^n (a x_k^2 + b x_k + c - y_k)^2.</me>
Taking all three partials gives
<me>TSE_a = \sum_{k=0}^n 2(a x_k^2 + b x_k + c - y_k) \cdot x_k^2</me>
<me>TSE_b = \sum_{k=0}^n 2(a x_k^2 + b x_k + c - y_k) \cdot x_k</me>
<me>TSE_c = \sum_{k=0}^n 2(a x_k^2 + b x_k + c - y_k) \cdot 1 .</me>
Once again, setting equal to zero and solving gives the normal equations for the best-fit quadratic
<me>a \sum_{k=0}^n x_k^4 + b \sum_{k=0}^n x_k^3 + c \sum_{k=0}^n x_k^2 = \sum_{k=0}^n x_k^2 y_k</me>
<me>a \sum_{k=0}^n x_k^3 + b \sum_{k=0}^n x_k^2 + c \sum_{k=0}^n x_k = \sum_{k=0}^n x_k y_k</me>
<me>a \sum_{k=0}^n x_k^2 + b \sum_{k=0}^n x_k + c \sum_{k=0}^n 1 = \sum_{k=0}^n y_k.</me>
</p>
        <p>Notice that even though you are creating the best-fit quadratic, to find that quadratic boils down to solving a (slightly larger) linear system.  In other words, linear regression again. Indeed, we can also approach the derivation of regression forumulas directly using a linear algebra approach. To do this, consider the equations generated by plugging in the data points <m>(x_0,y_0), (x_1, y_1), ... , (x_n, y_n)</m> into the quadratic model. This yields a (likely overdetermined) system of equations.  Appending an error term <m>\epsilon_k</m> for each equation gives the following matrix form: 
</p>
        <me>
\begin{bmatrix}
y_0
\\y_1
\\ y_2
\\ ...
\\ y_n
\end{bmatrix}
=

\begin{bmatrix}
 x_0^2 \amp x_0 \amp 1 \\ 
 x_1^2 \amp x_1 \amp 1 \\ 
 x_2^2 \amp x_2 \amp 1 \\ 
 ... \amp ... \amp ... \\ 
 x_n^2 \amp x_n \amp 1 
\end{bmatrix} 

\cdot 

\begin{bmatrix}
a
\\ 
b
\\
c
\end{bmatrix}
+
\begin{bmatrix}
 \epsilon_0 \\ 
 \epsilon_1 \\ 
 \epsilon_2 \\ 
 ... \\ 
 \epsilon_n 
\end{bmatrix}
</me>
        <p>
which in matrix form looks something like
<me>Y = XA + \epsilon.</me>
Solving for <m>\epsilon</m> and then minimizing <m>\epsilon^t \epsilon</m> yields the same solution as above. In matrix form, after some work this becomes
<me>A = (X^t X)^{-1} X^t Y</me>
with the matrix A containing the three unknowns a, b, and c.
</p>
        <p> We can also use Matlab (or the opensource alternative "octave") to compute this linear algebra for us. The graph here using the sagecell is a text graph and is very rudimentary but plugging this code into Matlab or a desktop version of octave should present a very nice graph.
</p>
        <p>
<sage language="octave"><input>
x = [-1 0 1 3 5 5]
y = [5 3 0 -1 3 6]
n = max(size(x));
for k = 1:n
  X(k,1) = x(k)^2;
  X(k,2) = x(k);
  X(k,3) = 1;
end
Y = y';  # transpose the set of y-values to be a column vector
A = inv(X'*X)*X'*Y;
a = A(1)
b = A(2)
c = A(3)
u = min(x):0.1:max(x);  # create a set of input values for plotting
v = a * u.^2 + b * u + c;
plot(x,y,'o',u,v,'.')
</input></sage>
</p>
        <p>
Cutting and pasting this code into perhaps http://octave-online.net gives a nice, non ASCII graph. Below, we do the same thing but using Sage.
</p>
        <p>
<sage><input>
var('x')
xpts = vector(RR,(-1, 0, 1, 3, 5, 5))
ypts = vector(RR,(5, 3, 0, -1, 3, 6))
ones = vector(RR,(1, 1, 1, 1, 1, 1))
xpts2 = []     # accumulate the squares
pts = []       # accumulate the (x,y) pairs for plotting purposes
for k in range(len(xpts)):
    xpts2.append(xpts[k]^2)
    pts.append((xpts[k],ypts[k]))
xpts2 = vector(xpts2)

X = matrix(RR,[xpts2]).stack(xpts).stack(ones).transpose()  # create X
Y = matrix(RR,ypts).transpose()
Xt = X.transpose()
A = (Xt*X).inverse()*Xt*Y
[a,b,c] = [A[0][0], A[1][0], A[2][0]]
f = a*x^2+b*x+c
banner = "The quadratic interpolant is given by \(%s\)"%str(latex(f))
G = points(pts,size=20)
H = plot(f,x,min(xpts)-0.2,max(xpts)+0.2,title=banner)
show(G+H)
</input></sage>
</p>
        <p>
<exercise><title>Creating a Cubic Linear Regression Interpolant</title><statement><p>
Modify the Sage code above to give a best-fit cubic interpolant.
</p></statement><solution><pre>
var('x')
xpts = vector((-1, 0, 1, 3, 5, 5))
ypts = vector((5, 3, 0, 4, 3, -1))
ones = vector((1, 1, 1, 1, 1, 1))
xpts3 = []
xpts2 = []
pts = []
for k in range(len(xpts)):
    xpts3.append(xpts[k]^3)
    xpts2.append(xpts[k]^2)
    pts.append((xpts[k],ypts[k]))
xpts3 = vector(xpts3)
xpts2 = vector(xpts2)

X = matrix([xpts3]).stack(xpts2).stack(xpts).stack(ones).transpose()
Y = matrix(ypts).transpose()
Xt = X.transpose()

A = (Xt*X).inverse()*Xt*Y
[a,b,c,d] = [A[0][0],A[1][0],A[2][0],A[3][0]]


f = a*x^3 + b*x^2 + c*x + d
banner = "The cubic interpolant is given by $%s$"%str(latex(f))
G = points(pts,size=20)
H = plot(f,x,min(xpts)-0.2,max(xpts)+0.2,title=banner)
show(G+H)
</pre></solution></exercise>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		Doing Cubic Linear Regression...use your Sage work from above.
		</p></introduction><webwork-reps xml:id="extracted-webwork-7" ww-id="webwork-7">
    <pg source="Library/Rochester/setStatistics6CorrelationRegression/ur_stt_6_10.pg"/>

      
    <static source="Library/Rochester/setStatistics6CorrelationRegression/ur_stt_6_10.pg" seed="7">
      <statement><p>In some cases, the best-fitting multiple regression equation is of the form 
      <m>\hat{y} = b_0 + b_1 x + b_2 x^2 + b_3 x^3.</m> The graph of such an equation is called 
      a cubic. Using the data set given below, and letting <m>x_1 = x,</m> <m>x_2 = x^2,</m> and 
      <m>x_3 = x^3,</m> find the multiple regression equation for the cubic that best fits the
      given data.</p></statement>
      
      <statement><p><me>\begin{array}{c|ccccccc}
      x \amp  -8 \amp  -5 \amp  -2 \amp  -1 \amp  4 \amp  6 \amp  8 \cr
      \hline
      y \amp  36.2 \amp  14.7 \amp  2 \amp  -0.9 \amp  -19.9 \amp  -37.4 \amp  -61.7
      \end{array}</me></p><p>The equation is <m>\hat{y} =</m> <fillin name="AnSwEr0001" characters="10"/> <m>+</m> <fillin name="AnSwEr0002" characters="10"/> <m>x+</m>  
      <fillin name="AnSwEr0003" characters="10"/> <m>x^2 +</m> <fillin name="AnSwEr0004" characters="10"/> <m>x^3.</m></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=7&amp;sourceFilePath=Library/Rochester/setStatistics6CorrelationRegression/ur_stt_6_10.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=7&amp;sourceFilePath=Library/Rochester/setStatistics6CorrelationRegression/ur_stt_6_10.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=7&amp;sourceFilePath=Library/Rochester/setStatistics6CorrelationRegression/ur_stt_6_10.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=7&amp;sourceFilePath=Library/Rochester/setStatistics6CorrelationRegression/ur_stt_6_10.pg</server-url>

  </webwork-reps></exercise>
</p>
      </section>
      <section>
        <title>Multi-variable Linear Regression</title>
        <p>
The regression models that we have looked at presumed a single independent variable. It is much more likely when investigating cause and effect relationships that there are perhaps many independent variables that contribute. 
</p>
        <p>Let's consider a linear model with two independent variables.
Indeed, a basic two-variable linear model of the form
<me>z = \alpha_1 x + \alpha_2 y + \beta</me>

can be used to approximate data points <me>(x_0,y_0,z_0), (x_1,y_1,z_1), (x_2,y_2,z_2), ... , (x_n,y_n,z_n) . </me> 
Using a linear systems approach similar to the previous section by evaluating at these data points and appending an error term to each equation gives, in matrix form:
</p>
        <p>
<me>
\begin{bmatrix}
z_0
\\z_1
\\ z_2
\\ ...
\\ z_n
\end{bmatrix}
=

\begin{bmatrix}
 x_0 \amp y_0 \amp 1 \\ 
 x_1 \amp y_1 \amp 1 \\ 
 x_2 \amp y_2 \amp 1 \\ 
 ... \amp ... \amp ... \\ 
 x_n \amp y_n \amp 1 
\end{bmatrix} 

\cdot 

\begin{bmatrix}
\alpha_1
\\ 
\alpha_2
\\
\beta
\end{bmatrix}
+
\begin{bmatrix}
 \epsilon_0 \\ 
 \epsilon_1 \\ 
 \epsilon_2 \\ 
 ... \\ 
 \epsilon_n 
\end{bmatrix}
</me>
</p>
        <p>
where the <m>\epsilon_k</m> terms are the deviation between the exact data point and the approximation of that point on some plane. Symbolically
<me>Z = XA + \epsilon.</me>
If all of the points lie on the same plane (unlikely), then <m>\epsilon = 0</m>. Otherwise, once again applying a least squares solution approach is the same as minimizing <m> \epsilon^t \epsilon</m> and eventually gives
<me>A = (X^t X)^{-1} X^t Z</me>
in general.  Evaluating this with X and Z as above gives the needed coefficients  
 
<me> A = \begin{bmatrix}
 \alpha_1 \\ 
 \alpha_2 \\  
 \beta 
\end{bmatrix}
</me>

</p>
        <p>Let's first see how this is done automatically in R using one of the built-in data sets
</p>
        <p>
<sage language="r"><input>
x1 &amp;- c(1, 2, 3, 5, 5)
x2 &amp;- c(1, 1, 2, 2, 3)
y &amp;- c(5, 1, 4, 3, -1)
fit &lt;- lm(y ~ x1+x2, data=(x,y,z))
summary(fit)             # basic results
coefficients(fit)        # a,b,c, for y = a x1 + b x2 + c x3
fitted(fit)              # predicted values
residuals(fit)           # errors
</input></sage>
</p>
        <p>
A good example of the usefulness and limitations of multi-variate linear regression is the calculation of the "Heat Index". This measure determines a measure of discomfort relative to the ambient temperature and the relative humidity. Indeed, in warm climates a high temperature is more difficult to bear if the humidity is also high. One reason is that with high humidity the body is less effective in shedding heat through evaporation of body sweat.
</p>
        <p>
The National Weather Service in 1990 published the following multiple regression equation for Heat Index (HI) relative to the ambient temperature (T) and the relative humidity (RH)
<md><mrow>H &amp; = -42.379 + 2.04901523 \cdot T + 10.14333127 \cdot R - 0.22475541 \cdot T \cdot R </mrow><mrow> &amp; - 6.83783 \cdot 10^{-3} \cdot T^2 - 5.481717 \cdot 10^{-2} \cdot R^2 + 1.22874 \cdot 10^{-3} \cdot T^2 \cdot R </mrow><mrow> &amp; + 8.5282 \cdot 10^{-4} \cdot T \cdot R^2-1.99 \cdot 10^{-6} \cdot T^2 \cdot R^2.</mrow></md>
Since this model utilizes a linear combination of terms and it's derivation could also be generated using a generalization of the linear regression method presented above. Details on how this equation was determined and other details are available at https://www.wpc.ncep.noaa.gov/html/heatindex_equation.shtml .
</p>
        <p>
<sage><title> Computing Heat Index Values</title><input>
@interact
def _(T = (90),R = (95)):
    H =-42.379+2.04901523*T+10.14333127*R \
    -0.22475541*T*R-6.83783*10^(-3)*T^2 \
    -5.481717*10^(-2)*R^2+1.22874*10^(-3)*T^2*R \
    +8.5282*10^(-4)*T*R^2-1.99*10^(-6)*T^2*R^2
    print "For T = ",T," with humidity = ",R,"percent , Heat Index =",H
</input></sage>
</p>
        <p>
Below one can compute a table for various ambient Temperature readings given one value for relative humidity.  Notice what happens for a relatively high humidity and relatively high temperature.
</p>
        <p>
<sage><title> Computing Heat Index Table</title><input>
R = 95
for T in range(80,121):
    H = -42.379+2.04901523*T+10.14333127*R \
    -0.22475541*T*R-6.83783*10^(-3)*T^2 \
    -5.481717*10^(-2)*R^2+1.22874*10^(-3)*T^2*R \
    +8.5282*10^(-4)*T*R^2-1.99*10^(-6)*T^2*R^2
    print "For T = ",T," with humidity = ",R,"percent , Heat Index =",H	
</input></sage>
</p>
        <p>
Indeed, you cannot roast a turkey by simply turning the oven on 120 and pumping in a lot of humidity since the turkey is not trying to cool itself anymore. Any discomfort measured on the turkey's behalf would certainly be matched by the human since the bird would be a rare bird and remain very much uncooked. The issue is that this model doesn't presume the possibility of 120F and 95% humidity. Often, in situations where the temperature is able to reach that level, such as a desert, then the relative humidity is correspondingly low. This idea of using a model to predict extreme values beyond the measured data is called extrapolation and should be utilized with care. Interpolation to estimate values within the confines of the measured data is however generally a safe bet.

</p>
      </section>
      <section>
        <title>Summary</title>
        <introduction>
          <p>
Here are the important formulas from this section:
</p>
        </introduction>
        <p>
Later
</p>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="Combinatorics">
      <title>Counting and Combinatorics</title>
      <section>
        <title>Introduction</title>
        <p>One of the earliest applications of mathematics you probably remember is how you could use number to count things. For many, this is what they think people do when they do mathematics. In this chapter, we will discover that it is possible to count items without actually listing them all.</p>
        <p>
<example><title>Counting by actually listing out all possibilities</title><p>Consider counting the number of ways one can arrange Peter, Paul, and Mary with the order important.  Listing the possibilities:
<ul><li>Peter, Paul, Mary</li><li>Peter, Mary, Paul</li><li>Paul, Peter, Mary</li><li>Paul, Mary, Peter</li><li>Mary, Peter, Paul</li><li>Mary, Paul, Peter</li></ul>
So, it is easy to see that these are all of the possible outcomes and that the total number of such outcomes is 6. What happens however if we add Simone to the list?
<ul><li>Simone, Peter, Paul, Mary</li><li>Simone, Peter, Mary, Paul</li><li>Simone, Paul, Peter, Mary</li><li>Simone, Paul, Mary, Peter</li><li>Simone, Mary, Peter, Paul</li><li>Simone, Mary, Paul, Peter</li><li>Peter, Simone, Paul, Mary</li><li>Peter, Simone, Mary, Paul</li><li>Paul, Simone, Peter, Mary</li><li>Paul, Simone, Mary, Peter</li><li>Mary, Simone, Peter, Paul</li><li>Mary, Simone, Paul, Peter</li><li>Peter, Paul, Simone, Mary</li><li>Peter, Mary, Simone, Paul</li><li>Paul, Peter, Simone, Mary</li><li>Paul, Mary, Simone, Peter</li><li>Mary, Peter, Simone, Paul</li><li>Mary, Paul, Simone, Peter</li><li>Peter, Paul, Mary, Simone</li><li>Peter, Mary, Paul, Simone</li><li>Paul, Peter, Mary, Simone</li><li>Paul, Mary, Peter, Simone</li><li>Mary, Peter, Paul, Simone</li><li>Mary, Paul, Peter, Simone</li></ul>
Notice how the list quickly grows when just one more choice is added. This example illustrates how keeping track of the number of items in a set can quickly get impossible to manage unless we can use a more mathematical approach that allows you to count the number of possibilities without having to list them all.
</p></example>
</p>
      </section>
      <section>
        <title>General Counting Principles</title>
        <p>
<definition><title>Cardinality</title><statement><p>Given a set of elements A, the number of elements in the 
		set is known as its cardinality and is denoted |A|. If the set has 
		an infinite number of elements then we set |A| = <m>\infty</m>.
		</p></statement></definition>
</p>
        <p>
In order to "count without counting" we establish the following foundational principle:
</p>
        <p>	
<theorem xml:id="MultiplicationPrinciple"><title>Multiplication Principle</title><statement><p>
		Given two successive events A and B, the number of ways 
		to perform A and then B is |A||B|.
		</p></statement><proof><p>If either of the events has infinite cardinality, then it is 
			clear
			that the number of ways to perform A and then B will also be 
			infinite. So, assume that both |A| and |B| are finite.
			In order to count the successive events, enumerate the elements in
			each set
			<md><mrow>A = \left \{ a_1, a_2, a_3, ... , a_{|A|} \right \}</mrow> 	
				and
				<mrow>B = \left \{  b_1, b_2, b_3, ... , b_{|B|} \right \}</mrow></md>
			and consider the function f(k,j) = (k-1)|B| + j. This function is 
			one-to-one and onto from the set 
			<md><mrow>\left \{ (k,j): 1 \le k \le |A|, 1 \le j \le |B| \right \} </mrow></md> 
			onto 
			<md><mrow>\left \{ s : 1 \le s \le |A| |B| \right \}.</mrow></md> 
			Since this
			second set has |A| |B| elements then the conclusion follows. 
			coordinates.
			</p></proof></theorem>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		Let's apply the Multiplication Principle.
		</p></introduction><webwork-reps xml:id="extracted-webwork-8" ww-id="webwork-8">
    <pg source="Library/Mizzou/Finite_Math/Set_Theory_Addition_and_Multiplication_Principles/MultiplicationPrinciple2.pg"/>

      
    <static source="Library/Mizzou/Finite_Math/Set_Theory_Addition_and_Multiplication_Principles/MultiplicationPrinciple2.pg" seed="8">
      <statement><p>A fair <m>6</m>-sided die is rolled <m>10</m> times and the resulting sequence of <m>10</m> numbers is recorded.</p><p>How many different sequences are possible?  <fillin name="AnSwEr0001" characters="20"/></p><p>How many different sequences consist entirely of even numbers? <fillin name="AnSwEr0002" characters="20"/></p><p>How many different sequences are possible if the first, third, and fourth numbers must be the same? <fillin name="AnSwEr0003" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=8&amp;sourceFilePath=Library/Mizzou/Finite_Math/Set_Theory_Addition_and_Multiplication_Principles/MultiplicationPrinciple2.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=8&amp;sourceFilePath=Library/Mizzou/Finite_Math/Set_Theory_Addition_and_Multiplication_Principles/MultiplicationPrinciple2.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=8&amp;sourceFilePath=Library/Mizzou/Finite_Math/Set_Theory_Addition_and_Multiplication_Principles/MultiplicationPrinciple2.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=8&amp;sourceFilePath=Library/Mizzou/Finite_Math/Set_Theory_Addition_and_Multiplication_Principles/MultiplicationPrinciple2.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		</p></introduction><webwork-reps xml:id="extracted-webwork-9" ww-id="webwork-9">
    <pg source="Library/Rochester/setDiscrete9Counting/ur_dis_9_2.pg"/>

      
    <static source="Library/Rochester/setDiscrete9Counting/ur_dis_9_2.pg" seed="9">
      <statement><p>Find how many positive integers with exactly four decimal digits, that
      is, positive integers between 1000 and 9999 inclusive, have the
      following properties:</p><p>(a) are not divisible by either 5
      or 7.</p><p><fillin name="AnSwEr0001" characters="30"/></p><p>(b) are divisible by 5 but not by 7.</p><p><fillin name="AnSwEr0002" characters="30"/></p><p>(c) are
      divisible by 7.</p><p><fillin name="AnSwEr0003" characters="30"/></p><p>(d) are divisible by 5 and by 7.</p><p><fillin name="AnSwEr0004" characters="30"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=9&amp;sourceFilePath=Library/Rochester/setDiscrete9Counting/ur_dis_9_2.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=9&amp;sourceFilePath=Library/Rochester/setDiscrete9Counting/ur_dis_9_2.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=9&amp;sourceFilePath=Library/Rochester/setDiscrete9Counting/ur_dis_9_2.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=9&amp;sourceFilePath=Library/Rochester/setDiscrete9Counting/ur_dis_9_2.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<definition xml:id="Factorial"><title>Factorial</title><statement><p>For any natural number n, 
		<md><mrow>n! = n(n-1)(n-2) ... 3 \cdot 2 \cdot 1</mrow></md>
		and by convention set 0! = 1.
		</p></statement></definition>
</p>
        <p>	
<example><title>iPad security code</title><p>Consider your ipad's security. To unlock the screen suppose you need to enter a four digit pass code. How easy is it to guess this pass code?</p><p>Using the standard 10 digit keypad, we first have two questions to consider?
		<ol><li>Does the order in which the digits are entered matter?</li><li>Can you reuse a digit more than once?</li></ol>
		For the ipad, if the order does matter and you cannot reuse digits, the number of possible codes can be determined by considering each digit as a separate event with four such events in succession providing the right code. By successively applying the multiplication principle, you find that the number of possible codes is the number of remaining available digits at each step.  Namely, <m>10 \times 9 \times 8 \times 7 = 5040.</m>
		</p><p>
		On the other hand, if you were allowed to reuse the digits then the number of possible outcomes would be more since all 10 digits would be available for each event.  Namely, <m>10 \times 10 \times 10 \times 10 = 10000.</m>
		</p><p>
		Now, consider how this changes if you can use a 4 or 6 digit passcode. Determine the number of possible passcodes.
		</p></example>
</p>
        <p>	
<example><title>iPad security code with greasy fingers</title><p>Reconsider your ipad's security. In this case, you like to eat
		chocolate bars and have greasy fingers. When you type in your passcode
		your fingers leave a residue over the four numbers pressed. If someone
		now tries to guess your passcode, how many possible attempts are necessary?</p><p>Since there are only four numbers to pick from with order important, the number of possible passcodes remaining is <m>4 \times 3 \times 2 \times 1 = 24</m></p></example>
</p>
        <p>	
<example><title>National Treasure</title><p>In the 2004 movie National Treasure, Ben and Riley are attempting 
		to guess Abagail's password to enter the room with the Declaration. 
		They are able
		to determine the passphrase to get into the vault room by doing a scan
		that detects the buttons pushed (not due to chocolate but just due to 
		the natural oils on fingers). They notice that the buttons pushed 
		include the characters AEFGLORVY.</p><p>Assuming these characters are used only once each, how many possible
		passphrases are possible?</p><p>
		In this case, the order of the characters matters but all of the 
		characters are distinct. Since we have 9 characters provided, the we can
		consider each character as an event with the first event as a choice
		from the 9, the second event as a choice from the remaining 8, etc. This
		gives <m>9 \times 8 \times ... \times 1 = 362880</m> possible 
		passphrases.
		</p><p>Assuming that some of the characters could be used more than once, 
		how many passphrases need to be considered if the total length
		of passphrase can be at most 12 characters?</p><p>Notice, in this case you don't know which characters might be reused and so the number of possible outcomes will be much larger. What is the answer?</p><p>You can break this problem down into distinct cases:
		<ul><li><p>Using 9 characters: The answer was computed above.</p></li><li><p>Using 10 characters: In this case, 1 character can be used twice. To determine the number of possibilities, let's first pick which character can be doubled. There are 9 options for picking that character.  Next, if we consider the two instances of that letter as distinct values then we can just count the number of ways to arrange unique 10 characters which is 10! However, swapping the two characters (which are actually identical) would not give a new passphrase. Since these are counted twice, let's divide these out to give 10!/2.</p></li><li><p>Using 11 characters: In this situation we have two unique options:
				<ul><li><p>One character is used three times and the others just once.</p>
					<p>Continuing as in the previous case, 11!/3!.</p>
					<li>Two characters are used twice and the others just once.</li>
					</li></ul>
				</p>
			</li><li><p>Using 12 characters</p></li><ol><li>One letter from the nine is used four times and all the others are used once.</li><li>One letter is used three times, another letter is used two times, and the others are used once.</li><li>Three letters are used twice and the others are used once.</li></ol></ul>
			</p><p>With this large collection of possible outcomes, how are the movie
		characters able to determine the correct "VALLEYFORGE" passphrase?</p></example>
</p>
      </section>
      <section>
        <title>Permutations</title>
        <p>
When counting various outcomes the order of things sometimes matters. When the order of a set of elements changes we call the second a permutation (or an arrangement) of the first.
</p>
        <p>
	<theorem><title>Permutations of everything</title><statement><p>The number of permutations of n distinct items is n!</p></statement><proof><p>Notice that if n=1, then there is only 1 item to arrange and 
			that there is only one possible arrangment.</p><p>
			By induction, assume that any set with n elements has n! arrangments 
			and assume that 
			<md><mrow>A = \left \{ a_1, a_2, ... , a_n, a_{n+1} \right \}.</mrow></md>
			Notice that there are n+1 ways to choose 1 element from A and that in doing so leaves a set with n elements. Combining the induction hypothesis with the multiplication principle this gives (n+1)n! = (n+1)! possible outcomes.
			</p></proof></theorem>
</p>
        <p>
One can interpret successive ordered selections as branching through a "tree" structure.  Indeed, starting with the set {A,B,C} one may pick any of the three but then a subsequent selection only has two possibilities for the next selection and so forth. The tree below illustrates that there are six ways to order two items from a group of size three.
<image source="images/PermutationSmall.png"/>
</p>
        <p>
Going one step further, what about ordering the letters in {A, B, C, D}? You can start by picking one of the four letters, say A, and then arranging B, C, and D.  Then, start with B and arrange A, C, and D and so on.  This gives:
	</p>
        <p>	ABCD, ABDC, ACBD, ACDB, ADBC, ADCB</p>
        <p>	BACD, BADC, BCAD, BCAB, BDAC, BDCA</p>
        <p>	CBAD, CBDA, CABD, CADB, CDBA, CDAB</p>
        <p>	DBCA, DBAC, DCBA, DCAB, DABC, DACB</p>
        <p>which is 24 different options or <m>4! = 4 \cdot 3 \cdot 2 \cdot 1 = 24</m>.  This can be viewed using a tree structure where each decision creates a new branch.
	
<image source="images/PermutationAllTree.png"/>

</p>
        <p>
<theorem xml:id="PermutationWithoutReplacementDistinguishable"><title>Permutations of a subset without replacement</title><statement><p> 
			The number of ways to arrange r items from a set of n distinct items 
			is 
			<me> _nP_r = \frac{n!}{(n-r)!} </me>
			This is sometimes denoted also as P(n,r) or <m>P_r^n</m>.
			</p></statement><proof><p>
			If <m>r \gt n</m> or <m>r \lt 0 </m> then this is not possible and so the result would be no permuatations. Otherwise, apply the multiplication principle r times noting that there are 
			n choices for the first selection, n-1 choices for the second
			selection, and with n-r+1 choices for the rth selection. This gives
			<md><mrow>_nP_r &amp; = n(n-1) ... (n-r+1)</mrow><mrow>&amp; = n(n-1) ... (n-r+1)\frac{(n-r)!}{(n-r)!}</mrow><mrow>&amp; = \frac{n(n-1) ... (n-r+1)(n-r)!}{(n-r)!}</mrow><mrow>&amp; = \frac{n!}{(n-r)!}</mrow></md>
			</p></proof></theorem>
</p>
        <p>
Following the tree idea from above, continue for several steps but then stop once you have gone r steps in.  For example, it is easy to see that <m>_5P_2 = 20</m> using a tree.

<image source="images/PermutationSubTree.png" width="50%"/>


</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		Let's apply the the Permutation formula.
		</p></introduction><webwork-reps xml:id="extracted-webwork-10" ww-id="webwork-10">
    <pg source="Library/Rochester/setProbability1Combinations/ur_pb_1_9.pg"/>

      
    <static source="Library/Rochester/setProbability1Combinations/ur_pb_1_9.pg" seed="10">
      <statement><p>In how many ways can 3 different
      novels, 4 different mathematics books, and 1 biology book be arranged on a bookshelf if</p><p>(a) the books can be arranged in any order?</p><p>Answer: <fillin name="AnSwEr0001" characters="20"/></p><p>(b) the mathematics books must be together and the novels must be together?</p><p>Answer: <fillin name="AnSwEr0002" characters="20"/></p><p>(c) the novels must be together but the other books can be arranged in any order?</p><p>Answer: <fillin name="AnSwEr0003" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=10&amp;sourceFilePath=Library/Rochester/setProbability1Combinations/ur_pb_1_9.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=10&amp;sourceFilePath=Library/Rochester/setProbability1Combinations/ur_pb_1_9.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=10&amp;sourceFilePath=Library/Rochester/setProbability1Combinations/ur_pb_1_9.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=10&amp;sourceFilePath=Library/Rochester/setProbability1Combinations/ur_pb_1_9.pg</server-url>

  </webwork-reps><conclusion><p>
		So, these are simple calculations.
		</p></conclusion></exercise>	
</p>
        <p>	
<theorem xml:id="PermutationWithReplacementDistinguishable"><title>Permutations of a subset with replacement</title><statement><p>The number of ways to obtain an arrangement of r choices from a group of size n is 
		<me>n^r</me>
		</p></statement><proof><p>
			Use the multiplication principle r times and see that for each choice all n objects in the universe remain available.  That is, 
			<me>n \cdot n \cdot n ... n = n^r</me>
			</p></proof></theorem>
</p>
        <p><theorem xml:id="MultinomialCoefficients"><title>Permutations when not all items are distinguishable (Multinomial Coefficients)</title><statement><p>
If n items belong to s categories, <m>n_1</m> in first, <m>n_2</m> in second, ... , <m>n_s</m> in the last, the number of ways to pick all is
		<me>\frac{n!}{n_1! \cdot n_2! ... n_s!}</me>	
	</p></statement><proof><p>
	Enumerate all of the n data items individually with the <m>n_1!</m> identical values first and the remaining groups in like manner to get the enumerated list 
	<me>
	  \left { x_{1,1}, ..., x_{1,n_1}, x_{2,1}, ..., x_{2,n_2}, ... , x_{s,1}, ..., x_{s,n_2}, \right }
	</me>
	In this order, there are <m>n_1!</m> ways to arrange the first group, <m>n_2!</m> ways to arrange the second, etc. There are <m>n_1! \times n_2! \times ... \times \n_s!</m> ways to arrange all of the categories together with groups in this order but none of those group reorders does anything since those data values are all the same. Dividing out those from the <m>n!</m> original permutations of all items leaves one with the multinomial coefficient. 
	</p></proof></theorem>
</p>
        <p>	
<exercise><title>WebWork</title><introduction><p>
		Let's apply the this new Permutation formula.
		</p></introduction><webwork-reps xml:id="extracted-webwork-11" ww-id="webwork-11">
    <pg source="Library/NAU/setCounting/RepeatedCombination1.pg"/>

      
    <static source="Library/NAU/setCounting/RepeatedCombination1.pg" seed="11">
      <statement><p>How many anagrams can be created from the word 'accommodate' if the new words do not need to be meaningful?
      <fillin name="AnSwEr0001" characters="35"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=11&amp;sourceFilePath=Library/NAU/setCounting/RepeatedCombination1.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=11&amp;sourceFilePath=Library/NAU/setCounting/RepeatedCombination1.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=11&amp;sourceFilePath=Library/NAU/setCounting/RepeatedCombination1.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=11&amp;sourceFilePath=Library/NAU/setCounting/RepeatedCombination1.pg</server-url>

  </webwork-reps><conclusion><p>
		Another one bites the dust.
		</p></conclusion></exercise>	
</p>
      </section>
      <section>
        <title>Combinations</title>
        <p>When counting various outcomes sometimes the order of things does not matter.
If so, each unique unordered outcome is called a combination. </p>
        <p>
Once again, consider the permutations when selecting three letters from {A, B, C, D}.
<ol><li>
<ul><li>A,B,C</li><li>A,C,B</li><li>B,A,C</li><li>B,C,A</li><li>C,A,B</li><li>C,B,A</li></ul>
</li><li>
<ul><li>A,B,D</li><li>A,D,B</li><li>B,A,D</li><li>B,D,A</li><li>D,A,B</li><li>D,B,A</li></ul>
</li><li>
<ul><li>A,C,D</li><li>A,D,C</li><li>C,A,D</li><li>C,D,A</li><li>D,A,C</li><li>D,C,A</li></ul>
</li><li>
<ul><li>B,C,D</li><li>B,D,C</li><li>C,B,D</li><li>C,D,B</li><li>D,B,C</li><li>D,C,B</li></ul>
</li></ol>

Notice how these 24 permutations fall into only four distinct categories if the order does not matter. Therefore, from a group of size four you can pick an unordered subset of size three in only 4 ways rather than the original 24.
</p>
        <p>
In general, it would be nice to have a direct formula to determine the number of such combinations without having to explicitly list them all out.
</p>
        <p>
<theorem xml:id="CombinationWithoutReplacementDistinguishable"><title>Combinations of a subset without replacement</title><statement><p>
			The number of ways to arrange r items from a set of n distinct items 
			is 
			<me> _nC_r = \frac{n!}{r!(n-r)!} </me>
			This is sometimes denoted C(n,r) or <m>C_r^n</m> or <m>{n \choose r}</m>.
			</p></statement><proof><p>
			Consider creating a permutation of r objects from a set of size n
			by first picking an unordered subset of size r and then counting 
			the number of ways to order that subset. Using our notation and the
			multiplication principle,
		
				<me>_nP_r = _nC_r \cdot r!</me>
	
			Dividing by <m>r!</m> gives the result.
			</p></proof></theorem>
</p>
        <p>
<theorem xml:id="CombinationWithReplacementDistinguishable"><title>Combinations of a subset with replacement</title><statement><p>
			The number of ways to arrange r items from a set of n distinct items 
			is 
			<me> _{n+r-1}C_r = {{n+r-1} \choose r} = \frac{(r+n-1)!}{r!(n-1)!} </me>
			</p></statement><proof><p>
			Label each item in your group in some defined order. Since order doesn't matter, as you repeatedly sample r times with replacement you can always write down your outcomes sorted from low to high placement. Finally, separate like values by some symbol, say "|", and consider each of the n distinct objects as indistinct *'s. There will be n-1 of these separators since there will be n to choose from. For example, if choosing r=6 times from the set {a, b, c, d}, then the outcome b, b, a, d, a, b could be collected as a, a, b, b, b, d and written in our code as **|***||* .  Notice that shuffling around the identical *'s would not change the code (and similarly for the identical |'s) but swapping a * with a | would be a different outcome. Therefore, we can consider this to be a <xref ref="MultinomialCoefficients">multinomial coefficient</xref> and the number of ways to rearrange this code is
			<me>\frac{(r + n-1)!}{r!(n-1)!}.</me>
			</p></proof></theorem>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		Let's apply the this new Combination forumula.
		</p></introduction><webwork-reps xml:id="extracted-webwork-12" ww-id="webwork-12">
    <pg source="Library/Mizzou/Finite_Math/Set_Theory_Permutations_Combinations/7cardPokerhand.pg"/>

      
    <static source="Library/Mizzou/Finite_Math/Set_Theory_Permutations_Combinations/7cardPokerhand.pg" seed="12">
      <statement><p>A standard deck of cards consists of four suits (clubs, diamonds, hearts, and spades), with each suit containing 13 cards (ace, two through ten, jack, queen, and king) for a total of 52 cards in all.</p><p>How many 7-card hands will consist of exactly 4 hearts and 3 clubs?</p><p><fillin name="AnSwEr0001" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=12&amp;sourceFilePath=Library/Mizzou/Finite_Math/Set_Theory_Permutations_Combinations/7cardPokerhand.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=12&amp;sourceFilePath=Library/Mizzou/Finite_Math/Set_Theory_Permutations_Combinations/7cardPokerhand.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=12&amp;sourceFilePath=Library/Mizzou/Finite_Math/Set_Theory_Permutations_Combinations/7cardPokerhand.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=12&amp;sourceFilePath=Library/Mizzou/Finite_Math/Set_Theory_Permutations_Combinations/7cardPokerhand.pg</server-url>

  </webwork-reps><solution>
		A solution can be presented here.
		</solution><conclusion><p>
		Notice that to determine the number of outcomes required you to use the combination forumula several times and then multiply the results using the multiplication principle.
		</p></conclusion></exercise>	
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		Use the new Combination formula again.
		</p></introduction><webwork-reps xml:id="extracted-webwork-13" ww-id="webwork-13">
    <pg source="Library/Rochester/setAlgebra38Counting/sw10_2_60.pg"/>

      
    <static source="Library/Rochester/setAlgebra38Counting/sw10_2_60.pg" seed="13">
      <statement><p>A school dance committee is to consist of 2 freshmen, 3 sophomores, 4
      juniors, and 5 seniors. If 6 freshmen, 8 sophomores, 7 juniors,
      and 8 seniors are eligible to be on the committee, in how many ways can
      the committee be chosen?</p><p>Your answer is : <fillin name="AnSwEr0001" characters="25"/></p></statement>
      
      <solution>
      
      There are <m>{6 \choose 2}</m> ways to choose 2 freshmen for the committee, 
      <m>{8 \choose 3}</m> ways to choose 3 sophomores for the committee, 
      <m>{7 \choose 4}</m> ways to choose 4 juniors for the committee, and 
      <m>{8 \choose 5}</m> ways to choose 5 seniors for the committee.  
      So by the generalized basic principle of counting, there are a total of 
      <me>{6 \choose 2} \cdot {8 \choose 3} \cdot {7 \choose 4} \cdot {8 \choose 5}
      = \frac{6 !}{2!4 !} \cdot \frac{8 !}{3! 5 !} \cdot \frac{7 !}{4! 3 !} \cdot \frac{8 !}{5! 3 !} = 1646400</me>
      different possible committees.
      
      
      
      </solution>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=13&amp;sourceFilePath=Library/Rochester/setAlgebra38Counting/sw10_2_60.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=13&amp;sourceFilePath=Library/Rochester/setAlgebra38Counting/sw10_2_60.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=13&amp;sourceFilePath=Library/Rochester/setAlgebra38Counting/sw10_2_60.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=13&amp;sourceFilePath=Library/Rochester/setAlgebra38Counting/sw10_2_60.pg</server-url>

  </webwork-reps><conclusion><p>
		Once again, you can see that using the formulas can be easy and also can be part of a bigger problem pasted together using the multiplication principle.
		</p></conclusion></exercise>	
</p>
        <p>
<example><title>Ipad Security</title><p>Revisiting your ipad's security, what happens if the order in which the digits are entered does not matter? If so, then you would be picking a combination of 4 digits without replacement from a group of 10 digits. Namely, 
		<md><mrow>\frac{10!}{4!6!} &amp; = \frac{10 \times 9 \times 8 \times 7 \times 6!}{4 \times 3 \times 2 \times 1 \times 6!}</mrow><mrow>&amp; = \frac{10 \times 9 \times 8 \times 7}{4 \times 3 \times 2 \times 1}</mrow><mrow>&amp; = \frac{5040}{24}</mrow><mrow>&amp; = 210.</mrow></md>
		Notice that the total number of options is much smaller when order does not matter.
		</p><p>
		Note that if you were allowed to reuse the digits then the number of possible outcomes would be
		<md><mrow>\frac{13!}{4!9!} &amp; = \frac{13 \times 12 \times 11 \times 10}{4 \times 3 \times 2 \times 1} </mrow><mrow> &amp; = 715</mrow></md>
		which once again is more since numbers are allowed to repeat.
		</p></example>
</p>
        <p>		
<definition xml:id="BinomialCoefficients"><title>Binomial Coefficients</title><statement><p>
		The value <m>_nC_r</m> is known as the binomial coefficient. It is
		denoted by <m>{n \choose r}</m> and is read "n choose k".
		</p></statement></definition>
</p>
        <p>Binomial coefficients have a number of interesting properties.  Many of these are very useful as well in probability calculations.  Several of these properties are collected below. In particular, these relationships verify that the binomial coefficients are the values found in Pascal's Triangle.</p>
        <p>
<sage><title>Binomial Coefficients give Pascal's Triangle</title><input>
@interact
def _(n = slider(1,15,1,5)):
    for row in range(n+1):
        binoms = sorted(binomial_coefficients(row).items())
        given_n = []
        for k in range(row+1):
            given_n.append(binoms[k][1])
        pretty_print('%s'%given_n)
</input></sage>
</p>
        <p>
<theorem><title> Binomial Coefficient Formulas</title><statement><p> For <m> n \in \mathbb{N}</m>,
	<ol><li><m>\binom{n}{0} = 1</m></li><li><m>\binom{n}{n} = 1</m></li><li><m>\binom{n}{1} = n</m></li><li><m>\binom{n}{n-1} = n</m></li><li><m>\binom{n}{r} = \binom{n}{n-r}</m></li><li><m>\binom{n+1}{r+1} = \binom{n}{r} + \binom{n}{r+1}</m></li></ol>
	</p></statement><proof><p>
	<ol><li><m>\binom{n}{0} = \frac{n!}{0!(n-0)!} = 1</m></li><li><m>\binom{n}{n} = \frac{n!}{n!(n-n)!} = 1</m></li><li><m>\binom{n}{1} = \frac{n!}{1!(n-1)!} = n</m></li><li><m>\binom{n}{n-1} = \frac{n!}{(n-1)!(n-(n-1))!} = n</m></li><li><m>\binom{n}{r} = \frac{n!}{r!(n-r)!} = \frac{n!}{(n-r)!(n-(n-r))!} = \binom{n}{n-r}</m></li><li>
		<md><mrow>\binom{n}{r} + \binom{n}{r+1} &amp; = \frac{n!}{r!(n-r)!} + \frac{n!}{(r+1)!(n-(r+1))!}</mrow><mrow> &amp; = (r+1) \frac{n!}{(r+1)!(n-r)!} // + (n-r) \frac{n!}{(r+1)!(n-r))!}</mrow><mrow> &amp; = \frac{(r+1) n! + (n-r)n!}{(r+1)!(n-r)!}</mrow><mrow> &amp; = \frac{(n+1) n!}{(r+1)!((n+1)-(r+1))!}</mrow><mrow> &amp; = \binom{n+1}{r+1}</mrow></md>
		</li></ol>
	</p></proof></theorem>
</p>
      </section>
      <section>
        <title>Summary</title>
        <introduction>
          <p>
Here are the important results from this chapter:
</p>
        </introduction>
        <p>
<xref ref="MultiplicationPrinciple">Multiplication Principle</xref>
</p>
        <p>
<xref ref="Factorial">Factorial</xref>
</p>
        <p>
<xref ref="PermutationWithoutReplacementDistinguishable">Permutations without replacement</xref>
</p>
        <p>
<xref ref="PermutationWithReplacementDistinguishable">Permutations with replacement</xref>
</p>
        <p>
<xref ref="MultinomialCoefficients">Multinomial Coefficients</xref>
</p>
        <p>
<xref ref="CombinationWithoutReplacementDistinguishable">Combinations without replacement</xref>
</p>
        <p>
<xref ref="CombinationWithReplacementDistinguishable">Combinations with replacement</xref>
</p>
        <p>
<xref ref="BinomialCoefficients">Binomial Coefficients</xref>
</p>
      </section>
      <section>
        <title>Exercises</title>
        <p>Complete the online homework "Counting".</p>
        <p>
A standard deck of playing cards consists of 52 cards broken up into four "suits" known as Hearts, Spades, Diamonds, and Clubs. Each suit is broken up additionally into unique cards with "face values" from {2, 3, 4, 5, 6, 7, 8, 9, 10, Jack, Queen, King, Ace} and generally in that order from low to high.</p>
        <p>
1.  Pick two cards without replacement one after the other from this deck and determine the following number of possible outcomes:
<ul><li>The number of ways to get an Ace for both cards.</li><li>The number of ways to get an Ace for only one of the two cards.</li><li>The number of ways to get an Ace on the first draw and a Spade on the second draw.</li></ul>
2.  Pick five cards without replacement one after the other from a newly shuffled full deck and determine the following number of possible outcomes:
<ul><li>All cards have different faces</li><li>"A pair". That is, two cards have the same face but the others are from three other faces.</li><li>"Three of a kind".  That is, three cards have the same face but the others are from two other faces.</li><li>"Two Pair". That is, two cards come from one face, two other cards come from a common face that is not the same as the first two cards, and the last card comes from some other face.</li><li>"Full House". That is, three cards have the same face and the other two come from a common face that is not the same as the first three cards.</li><li>"Four of a Kind". That is, four cards have the same face and the other card comes from some other face.</li><li>"Flush". That is, the five cards for a sequence in order of adjacent faces in the original list and from the same suit.</li><li>"Royal Flush". That is, a flush but only with the cards {Ace, King, Queen, Jack, 10}.</li></ul>
</p>
        <p>Completely determine the number of possible passphrases for the National Treasure example started above. Present your answer in a report form.</p>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="ProbabilityGeneralities">
      <title>Probability Theory</title>
      <section>
        <title>Introduction</title>
        <p>
Mathematics generally focuses on providing precise answers with absolute certainty. For example, solving an equation generates specific (and non-varying) solutions. Statistics on the other hand deals with providing precise answers to questions when there is uncertainty. It might seem impossible to provide such precise answers but the focus of this text is to show how that can be done so long as the questions are properly posed and the answers properly interpreted.
</p>
        <p>Indeed, people often make claims about being the biggest, best, most often recommended, etc. One sometimes even believes these claims based upon subjective metrics. In this chapter, we will start by looking at relative frequency and notice several properties regarding relative frequencies as the number of trials increases. We will use these examples to motivate a definition for probability and investigate the resulting consequences of that definition.</p>
      </section>
      <section xml:id="RelativeFrequency">
        <title>Relative Frequency</title>
        <p>When attempting to precisely measure uncertainty one often resorts to examples or experiments that model the theoretical question of interest. Before we investigate statistical experiments, we need to create some notation that we will utilize throughout the rest of this text.</p>
        <ul>
          <li>S = Universal Set or Sample Space Experiment or Outcome Space. 
		This is the collection of all possiblilities.</li>
          <li>Random Experiment. A random experiment is a repeatable activity that has more than one
		possible outcome all of which can be specified in advance but can not be known in advance with certainty.</li>
          <li>Trial. Performing a Random Experiment one time and measuring the result.</li>
          <li>A = Event. A collection of outcomes.  Generally denoted by an upper case letter such as A, B, C, etc.</li>
          <li>Success/Failure. When recording the result of a trial, a success for event A occurs when the outcome
		lies in A. If not, then the trial was a failure. There is no qualitative meaning to this term.</li>
          <li>Mutually Exclusive Events. Two events that share no common outcomes. Also known as disjoint events.</li>
          <li>|A| = Frequency. In a sequence of n events, the frequency is the number of trials which resulted in 
		a success for event A.</li>
          <li>|A| / n = Relative Frequency. A proportion of successes to total number of trials.</li>
          <li>Histogram. A bar chart representation of data where area corresponds to the value being described.</li>
        </ul>
        <p>To investigate these terms and to motivate our discussion of probability, consider flipping coins using the interactive cell below. Notice in this case, the sample space S = \{ Heads, Tails \} and the random experiment consists of flipping a fair coin one time. Each trial results in either a Head or a Tail. Since we are measuring both Heads and Tails then we will not worry about which is a success or failure. Further, on each flip the outcomes of Heads or Tails are mutually exclusive events. We count the frequencies and compute the relative frequencies for a varying number of trials selected by you as you move the slider bar. Results are displayed using a histogram.</p>
        <p>
<sage><input>
coin = ["Heads", "Tails"]
@interact
def _(num_rolls = slider([5..5000],label="Number of Flips")):
	rolls = [choice(coin) for roll in range(num_rolls)]
	show(rolls)   
	freq = [0,0]
	for outcome in rolls:
		if (outcome=='Tails'):
			freq[0] = freq[0]+1
		else:
			freq[1] = freq[1]+1
	print("\nThe frequency of tails = "+ str(freq[0]))+" and heads = "+ str(freq[1])+"."
	rel = [freq[0]/num_rolls,freq[1]/num_rolls]
	print("\nThe relative frequencies for Tails and Heads:"+str(rel))
	show(bar_chart(freq,axes=False,ymin=0))     #  A histogram of the results
</input></sage>
</p>
        <p>
	Question 1: What do you notice as the number of flips increases?
	</p>
        <p>
	Question 2: Why do you rarely (if ever) get exactly the same number of Heads and Tails? Would you not "expect"
	that to happen?
</p>
        <p>You should have noticed that as the number of flips increases, the relative frequency of Heads (and Tails)
	stabilized around 0.5. This makes sense intuitively since there are two options for each 
	individual flip and 1/2 of those options are Heads while the other 1/2 is Tails.</p>
        <p>
	Let's try again
	by doing a random experiment consisting of rolling a single die one time. Note that the sample space 
	in this case will be the outcomes S = \{ 1, 2, 3, 4, 5, 6 \}.
</p>
        <p>
<sage><input>
@interact
def _(num_rolls = slider([20..5000],label='Number of rolls'),Number_of_Sides = [4,6,8,12,20]):
	die = list((1..Number_of_Sides))
	rolls = [choice(die) for roll in range(num_rolls)]
	show(rolls)   

	freq = [rolls.count(outcome) for outcome in set(die)]  # count the numbers for each outcome
	print 'The frequencies of each outcome is '+str(freq)

	print 'The relative frequencies of each outcome:'
	rel_freq = [freq[outcome-1]/num_rolls for outcome in set(die)]  # make frequencies relative
	print rel_freq
	fs = []
	for f in rel_freq:
		fs.append(f.n(digits=4))
	print fs
	show(bar_chart(freq,axes=False,ymin=0)) 
</input></sage>
</p>
        <p>
Notice for a single die there are a larger number of options (for example 6 on a regular die) but once again the relative frequencies of each  outcome was close to 1/n (i.e. 1/6 for the regular die) as the number of rolls increased.</p>
        <p>
In general, this suggests a rule: if there are n outcomes and each one has the same
	chance of occurring on a given trial then on average on a large number of trials the relative
	frequency of that outcome is 1/n.
	In general, if a number of outcomes are "equally likely" then this is a good model for measuring
	the proportion of outcomes that would be expected to have any given outcome. However, it is not
	always true that outcomes are equally likely. Consider rolling two die and measuring their sum:
</p>
        <p xml:id="TwoDiceSage">
<sage><title>Rolling Two Dice and Measuring their Sum</title><input>
@interact
def _(num_rolls = slider([20..5000],label='Number of rolls'),num_sides = slider(4,20,1,6,label='Number of sides')):
    die = list((1..num_sides))
    dice = list((2..num_sides*2))
    rolls = [(choice(die),choice(die)) for roll in range(num_rolls)]
    sums = [sum(rolls[roll]) for roll in range(num_rolls)]
    show(rolls)   

    freq = [sums.count(outcome) for outcome in set(dice)]  # count the numbers for each outcome
    print 'The frequencies of each outcome is '+str(freq)
    
    print 'The relative frequencies of each outcome:'
    rel_freq = [freq[outcome-2]/num_rolls for outcome in set(dice)]  # make frequencies relative
    print rel_freq        
    show(bar_chart(freq,axes=False,ymin=0))     #  A histogram of the results
    print "Relative Frequence of ",dice[0]," is about ",rel_freq[0].n(digits=4)
    print "Relative Frequence of ",dice[num_sides-1]," is about ",rel_freq[num_sides-1].n(digits=4)

</input></sage>
</p>
        <!--
	<exercise>
		<introduction>
		<p>
		Let's see if you understand the relationship between frequency and relative frequency.
		</p>
		</introduction>
		<webwork source="local/relative_frequency1.pg">
		</webwork>
		<conclusion>
		<p>
		So, these are simple calculations.
		</p>
		</conclusion>
	</exercise>
-->
        <p>
	Question 1: What do you notice as the number of rolls increases?
</p>
        <p>
	Question 2: What do you expect for the relative frequencies and why are they not all exactly the same?
</p>
        <p>Notice, not only are the answers not the same but they are not even close. To understand why this 
	is different from the examples before, consider the possible outcomes from each pair of die. Since we
	are measuring the sum of the dice then (for a pair of standard 6-sided dice) the possible sums are from 
	2 to 12. However, there is only one way to get a 2--namely from a (1,1) pair--while there are 6 ways to get
	a 7--namely from the pairs (1,6), (2,5), (3,4), (4,3), (5,2), and (6,1). So it might make some sense
	that the likelihood of getting a 7 is 6 times larger than that of getting a 2. Check to see if that
	is the case with your experiment above.
</p>
        <p>Play with the following several times to investigate what you might expect to get when you repeatedly receive a "hand" of 5 standard playing cards. Can you imagine how you might possible enumerate the entire list of possible outcomes by hand? However, using this interactive cell, you can shuffle and deal 5-card hands over and over easily and then count the number of special poker outcomes. 
</p>
        <p>
<sage><input>
var('A C D H J K Q S') 

suits = [S, D, C, H] 
values = [2, 3, 4, 5, 6, 7, 8, 9, 10, J, Q, K, A] 

full_deck = [(value, suit) for suit in suits for value in values]
@interact
def _(num_hands=slider[50..5000]):                  # Set up the number of hands to create
    hands= []                    # Start with a blank list. 
    for i in range(num_hands):   # This loops the following operation num_hands times. 
        deck = copy(full_deck)   # start over
        shuffle(deck)
        hands.append([deck.pop() for card in range(5)])
    freq_values = []
    one_pair = 0
    two_pair = 0
    three_kind = 0
    full_house = 0
    four_kind = 0
    for i in range(num_hands):
        hand = hands[i]
        hand_values = [hand[k][0] for k in range(5)]
        freq_values = [hand_values.count(value) for value in set(values)]
        freq_values.sort(reverse=True)
        if freq_values[0]==4:
            four_kind=four_kind+1
        if freq_values[0]==3:
            if freq_values[1]==2:
                full_house=full_house+1
            if freq_values[1]==1:
                three_kind=three_kind+1
        if freq_values[0]==2:
            if freq_values[1]==2:
                two_pair=two_pair+1
            if freq_values[1]==1:
                one_pair=one_pair+1
    print "       One Pair frequency = ",one_pair," with relative frequency ",one_pair/num_hands
    print "       Two Pair frequency = ",two_pair," with relative frequency ",two_pair/num_hands
    print "Three of a Kind frequency = ",three_kind," with relative frequency ",three_kind/num_hands
    print "     Full House frequency = ",full_house," with relative frequency ",full_house/num_hands
    print " Four of a Kind frequency = ",four_kind," with relative frequency ",four_kind/num_hands
</input></sage>
</p>
        <p>
Sometimes you will find it useful to keep a running total of the relative frequencies. Such a cumulative approach is often called a distribution function.
</p>
        <p>
<definition><title>Cumulative relative frequency</title><statement><p>
For a collection of ordered events <m>x_1 \lt x_2 \lt ... \lt x_s</m> with corresponding frequencies <m>f_1, f_2, ..., f_s</m>, the cumulative relative frequency is the function
<me>F(x) = \sum_{x_k \le x} f_{x_k}</me>
</p></statement></definition>
</p>
        <p>
Let's consider the cumulative relative frequency with the sum of dice example seen at the beginning of this chapter.

<p>
<sage><title>Two Dice Cumulative Relative Frequency</title><input>
@interact
def _(num_rolls = slider([20..5000],label='Number of rolls'),num_sides = slider(4,20,1,6,label='Number of sides')):
    die = list((1..num_sides))
    dice = list((2..num_sides*2))
    rolls = [(choice(die),choice(die)) for roll in range(num_rolls)]
    sums = [sum(rolls[roll]) for roll in range(num_rolls)]
    show(rolls)   

    freq = [sums.count(outcome) for outcome in set(dice)]  # count the numbers for each outcome
    n = len(freq)
    CF = freq
    for k in range(1,n):
        CF[k] = freq[k] + CF[k-1]
    
    print 'The cumulative relative frequencies of each outcome:'
    Crel_freq = [CF[outcome-2]/num_rolls for outcome in set(dice)]  # make frequencies relative
    print Crel_freq        
    show(bar_chart(CF,axes=False,ymin=0))     #  A histogram of the results
    print "Cumulative Relative Frequence of ",dice[0]," is about ",Crel_freq[0].n(digits=4)
    print "Cumulative Relative Frequence of ",dice[num_sides-1]," is about ",Crel_freq[num_sides-1].n(digits=4)
</input></sage>
</p>

</p>
      </section>
      <section>
        <title>Definition of Probability</title>
        <p>	
<introduction><p>
Relative frequency gives a way to measure the proportion of "successful" outcomes when doing an experimental approach. From the interactive applications above, it appears that the relative frequency does jump around as the experiment is repeated but that the amount of variation decreases as the number of experiments increases. This is known to be true in general and is known as the "Law of Large Numbers". 
</p><p>
We would like to formalize what these relative frequencies are approaching and will call this theoretical limit the "probability" of the outcome. In doing so, we will do our best to model our definition so that it follow the behavior of relative frequency.
</p></introduction>
</p>
        <p>
To generate a general definition for probability, we need to know what is is that we measuring. In general, we will be finding the probability of sets of possible outcomes...that is, a subset of the Sample Space S. Toward that end, it is important to briefly look at some properties of sets.
</p>
        <p>
<definition xml:id="DefnMutuallyExclusive"><title>Pairwise Disjoint Sets</title><statement><p>
	<m> \{ A_1, A_2, ... , A_n \}</m> are pairwise disjoint provided <m>A_k \cap A_j = \emptyset</m> so long as <m>k \ne j</m>.
	Disjoint sets as also often called mutually exclusive.
	</p></statement></definition>
</p>
        <p>Play around with the interactive cell below by adding and removing items in each of the three sets. Find elements so that the intersection of all three sets is empty but at least one of the paired sets are not disjoint.  See if you can make all of the paired sets not disjoint but the intersection of all three disjoint. This is why we need to consider "pairwise" disjoint sets.
</p>
        <p>
<sage><title>Playing around with intersections and unions of sets</title><input>
def f(s, braces=True): 
    t = ', '.join(sorted(list(s)))
    if braces: return '{' + t + '}'
    return t
def g(s): return set(str(s).replace(',',' ').split())

@interact
def _(X='1,2,3', Y='2,a,3,4,apple', Z='a,b,10,apple'):
    S = [g(X), g(Y), g(Z)]
    X,Y,Z = S
    XY = X &amp; Y
    XZ = X &amp; Z
    YZ = Y &amp; Z
    XYZ = XY &amp; Z

    Txy = " - NOT disjoint "
    if Set(XY).is_empty():
        Txy = ' - disjoint '
    pretty_print(html("$X \cap Y$ = %s"%f(XY)+"%s"%Txy))
    Txz = " - NOT disjoint "
    if Set(XZ).is_empty():
        Txz = ' - disjoint '
    pretty_print(html("$X \cap Z$ = %s"%f(XZ)+"%s"%Txz))
    Tyz = " - NOT disjoint "
    if Set(YZ).is_empty():
        Tyz = ' - disjoint ' 
    pretty_print(html("$Y \cap Z$ = %s"%f(YZ)+"%s"%Tyz))
    Txyz = " - NOT disjoint "
    if Set(XYZ).is_empty():
        Txyz = ' - disjoint ' 
    pretty_print(html("$X \cap Y \cap Z$ = %s"%f(XYZ)+"%s"%Txyz))
    centers = [(cos(n*2*pi/3), sin(n*2*pi/3)) for n in [0,1,2]]
    scale = 1.7
    clr = ['yellow', 'blue', 'green']
    G = Graphics()
    for i in range(len(S)):
        G += circle(centers[i], scale, rgbcolor=clr[i], 
             fill=True, alpha=0.3)
    for i in range(len(S)):
        G += circle(centers[i], scale, rgbcolor='black')

    # Plot what is in one but neither other
    for i in range(len(S)):
        Z = set(S[i])
        for j in range(1,len(S)):
            Z = Z.difference(S[(i+j)%3])
        G += text(f(Z,braces=False), (1.5*centers[i][0],1.7*centers[i][1]), rgbcolor='black')


    # Plot pairs of intersections
    for i in range(len(S)):
        Z = (set(S[i]) &amp; S[(i+1)%3]) - set(XYZ)
        C = (1.3*cos(i*2*pi/3 + pi/3), 1.3*sin(i*2*pi/3 + pi/3))
        G += text(f(Z,braces=False), C, rgbcolor='black')

    # Plot intersection of all three
    G += text(f(XYZ,braces=False), (0,0), rgbcolor='black')

    # Show it
    G.show(aspect_ratio=1, axes=False)
</input></sage>
</p>
        <p>
Consider how we might create a definition for the expectation of a given outcome. To do so, first consider a desired collection of outcomes A. If each outcome in A is chosen randomly then we might consider using a formula similar to relative frequency and set a measure of expectation to be |A|/|S|. For example, on a standard 6-sided die, the expectation of the outcome A={2} from the collection S = {1,2,3,4,5,6} could be
	|A|/|S| = 1/6.
</p>
        <p>From our example where we take the sum of two die, the outcome A = \{ 4,5 \} from the
	collection S = {2,3,4,...,12} would be
	<md><mrow>|A| = | \{ (1,3),(2,2),(3,1),(1,4),(2,3),(3,2),(4,1) \}| = 7</mrow><mrow>|S| = | \{ (1,1),...,(1,6),(2,1),...,(2,6),...,(6,1),...,(6,6) \}| = 36</mrow></md>
	and so the expected relative frequency would be |A|/|S| = 7/36. Compare this theoretical value
	with the sum of the two outcomes from your experiment above.
</p>
        <p>We are ready to now formally give a name to the theoretical measure of expectation for
	outcomes from an experiment. Taking our cue from our examples, let's 
	make our definition agree with the following relative frequency properties:
<ol><li>Relative frequency cannot be negative, since cardinality cannot be negative</li><li>Relative frequencies for disjoint events should sum to one</li><li>Relative frequencies for collections of disjoint outcomes should equal the sum of the
	individual relative frequencies</li></ol>
</p>
        <p>which leads us to the following formal definition...</p>
        <p>
<definition xml:id="DefnProb"><title>Probability</title><statement><p>
	The probability P(A) of a given outcome A is a set function that satisfies:
	</p><p>
		<ol><li>(Nonnegativity) P(A) <m>\ge 0</m></li><li>(Totality) P(S) = 1</li><li>(Subadditivity) If A <m>\cap</m> B = <m>\emptyset</m>, then P(A <m>\cup</m> B) = P(A) + P(B).  
			In general, if {<m>A_k</m>} are pairwise disjoint then <m>P( \cup_k A_k) = \sum_k P(A_k)</m>.</li></ol>
		</p></statement></definition>	
</p>
        <p>
	<exercise><introduction><p>
		Using the definition above, determine the following probabilities.
		</p></introduction><webwork-reps xml:id="extracted-webwork-14" ww-id="webwork-14">
    <pg source="Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability01.pg"/>

      
    <static source="Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability01.pg" seed="14">
      <statement><p>Suppose you select a letter at random from the word MISSISSIPPI.</p><p>The probability of selecting the letter S is <fillin name="AnSwEr0001" characters="4"/></p><p>The probability of selecting the letter M is <fillin name="AnSwEr0002" characters="4"/></p><p>The probability of selecting the letters P or I is <fillin name="AnSwEr0003" characters="4"/></p><p>The probability of not selecting the letter I is <fillin name="AnSwEr0004" characters="4"/></p></statement>
      
      <hint><p>Count the number of letters in the word.  When computing each probability, this is the number that goes on the bottom.</p></hint>
      
      <solution><p>The probability of 'M's is 1/11.</p><p>The probability of 'I's is 4/11.</p><p>The probability of 'S's is 4/11.</p><p>The probability of 'P's is 2/11.</p></solution>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=14&amp;sourceFilePath=Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability01.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=14&amp;sourceFilePath=Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability01.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=14&amp;sourceFilePath=Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability01.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=14&amp;sourceFilePath=Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability01.pg</server-url>

  </webwork-reps><conclusion><p>
		Notice when you are given complete information regarding the entire data set then determining
		probabilities for events can be relatively easy to compute.
		</p></conclusion></exercise>
</p>
        <p>
Based upon this definition we can immediately establish a number of results.
</p>
        <p>
	<theorem xml:id="ProbabilityComplements"><title>Probability of Complements</title><statement> For any event A, <m>P(A) + P(A^c) = 1</m></statement><proof><p>Let A be any event and note that 
			<me>A \cap A^c = \emptyset.</me>  
			But <m>A \cup A^c = S</m>.
			So, by subadditivity 
			<me>1 = P(S) = P(A \cup A^c) = P(A) + P(A^c)</me> 
			as desired.</p></proof></theorem>
</p>
        <p>
	<theorem xml:id="ProbabilityEmptySet"><statement><p>
		<m>P(\emptyset) = 0</m>
		</p></statement><proof><p>Note that <m>\emptyset^c = S</m>. So, by the theorem above, 
			<me>1 = P(S) + P(\emptyset) \Rightarrow 1 = 1 + P(\emptyset).</me>
			Cancelling the 1 on both sides gives <m>P(\emptyset) = 0</m>. </p></proof></theorem>
</p>
        <p>
	<theorem xml:id="ProbabilityContainment"><statement>For events A and B with <m> A \subset B, P(A) \le P(B)</m>.
		</statement><proof><p>Assume sets A and B satisfy <m> A \subset B</m>. Then, notice that
			<me>A \cap (B-A) = \emptyset</me> 
			and  
			<me>B = A \cup (B-A).</me> 
			Therefore, by subadditivity and nonnegativity
			<md><mrow>0 \le P(B-A)</mrow><mrow>P(A) \le P(A) + P(B-A) </mrow><mrow>P(A) \le P(B)</mrow></md>
			</p></proof></theorem>
</p>
        <p>
	<theorem xml:id="ProbabilityLessThanOne"><statement>For any event A, <m>P(A) \le 1</m></statement><proof><p>Notice <m>A \subset S</m>. By the theorem above <m> P(A) \le P(S) = 1</m></p></proof></theorem>
</p>
        <p>
	<theorem xml:id="ProbabilityTwoUnions"><statement>For any sets A and B, <m>P(A \cup B) = P(A) + P(B) - P(A \cap B)</m></statement><proof><p>Notice that we can write <m>A \cup B</m> as the disjoint union
			<me>A \cup B = (A-B) \cup (A \cap B) \cup (B-A).</me>
			We can also write disjointly
			<md><mrow>A = (A-B) \cup (A \cap B)</mrow><mrow>B = (A \cap B) \cup (B-A)</mrow></md>
			Hence,
			<md><mrow>P(A) &amp; + P(B) - P(A \cap B) </mrow><mrow>&amp; = [P(A-B) + P(A \cap B)] </mrow><mrow>&amp; + [P(A \cap B) + P(B-A)] - P(A \cap B)</mrow><mrow>&amp; = P(A-B) + P(A \cap B) + P(B-A)</mrow><mrow>&amp; = P(A \cup B)</mrow></md>
			</p></proof></theorem>
</p>
        <p>
This result can be extended to more that two sets using a property known as inclusion-exclusion. The following two theorems illustrate this property and are presented without proof.
</p>
        <p>
<corollary xml:id="ProbabilityThreeUnions"><statement><p>
			For any sets A, B and C, 
			<md><mrow>P(A \cup B \cup C) &amp; = P(A) + P(B) + P(C)</mrow><mrow>&amp; - P(A \cap B) - P(A \cap C) - P(B \cap C) </mrow><mrow>&amp; + P(A \cap B \cap C)</mrow></md>
		</p></statement></corollary>
</p>
        <p>
	<corollary xml:id="ProbabilityFourUnions"><statement><p>
			For any sets A, B, C and D, 
			<md><mrow>P(A \cup B \cup C \cup D) &amp; = P(A) + P(B) + P(C) + P(D)</mrow><mrow>&amp; - P(A \cap B) - P(A \cap C) - P(A \cap D) </mrow><mrow>&amp; - P(B \cap C) - P(B \cap D) - P(C \cap D)</mrow><mrow>&amp; + P(A \cap B \cap C) + P(A \cap B \cap D) </mrow><mrow>&amp; + P(A \cap C \cap D) + P(B \cap C \cap D)</mrow><mrow>&amp; - P(A \cap B \cap C \cap D)</mrow></md>
		</p></statement></corollary>
</p>
        <p>
Many times, you will be dealing with making selections from a sample space where each item in the space has an equal chance of being selected. This may happen (for example) when items in the sample space are of equal size or when selecting a card from a completely shuffled deck or when coins are flipped or when a normal fair die is rolled. 
</p>
        <p>
It is important to notice that not all outcomes are equally likely--even in times when there are only two of them. Indeed, it is generally not an equally likely situation when picking the winner of a football game which pits, say, the New Orleans Saints professional football team with the New Orleans Home School Saints. Even though there are only two options the probability of the professional team winning in most years ought to be much greater than the chances that the high school will prevail. 
</p>
        <p>
When items are equally likely (sometimes also called "randomly selected") then each individual event has the same chance of being selected as any other. In this instance, determining the probability of a collection of outcomes is relatively simple.
</p>
        <p>
<theorem><title>Probability of Equally Likely Events</title><statement><p>
	If outcomes in S are equally likely, then for <m>A \subset S,</m> 
	<me>P(A) = \frac{|A|}{|S|}.</me> 
	</p></statement><proof><p>
	Enumerate S = {<m>x_1, x_2, ..., x_{|S|}</m>} and note <m>P( \{ x_k \} ) = c</m> for some constant c since each item is equally likely. However, using each outcome as a disjoint event and the definition of probability, 
	<md><mrow>1 = P(S) &amp; = P( \{ x_1 \} \cup \{x_2 \} \cup ... \cup \{x_{|S|} \} )</mrow><mrow> &amp; = P(\{ x_1 \}) + P(\{ x_2 \} ) + ... + P(\{ x_{|S|} \} )</mrow><mrow> &amp; = c + c + ... + c = {|S|} \times c</mrow></md>
	and so <m>c = \frac{1}{{|S|}}</m>. Therefore, <m>P( \{ x_k \} ) = \frac{1}{|S|}</m> .
	</p><p>
	Hence, with A = {<m>a_1, a_2, ..., a_{|A|}</m>}, breaking up the disjoint probabilities as above gives
	<md><mrow>P(A) &amp; = P( \{ a_1 \} \cup \{ a_2 \} \cup ... \cup \{ a_{|A|} \} )</mrow><mrow> &amp; = P(\{ a_1 \}) + P(\{ a_2 \} ) + ... + P(\{ a_{|A|} \} )</mrow><mrow> &amp; = \frac{1}{{|S|}} + \frac{1}{{|S|}} + ... + \frac{1}{{|S|}}</mrow><mrow> &amp; = \frac{|A|}{{|S|}}</mrow></md>
	as desired.
	</p></proof></theorem>
</p>
        <p>
<sage><title>Let's play around with cards</title><input>
var('A C D H J K Q S') 

def L(str):
    n = len(str)
    m = int(n/5)
    top = m+1
    if m == n/5:
        top = m
    for k in range(top):
        print str[5*k:5*k+5]
        
suits = [S, D, C, H] 
values = [2, 3, 4, 5, 6, 7, 8, 9, 10, J, Q, K, A] 

deck = [(value, suit) for suit in suits for value in values]
full_deck = copy(deck)  # to save a copy of the original deck for later use.

L(deck)
shuffle(deck)
L(deck)
deck1 = copy(full_deck)
shuffle(deck1)

@interact
def _(auto_update=False):
    global deck1    
    shuffle(deck1)            
    if (Set(deck1).cardinality()&lt;5):
        print 'Deck is too small...getting a new deck'
        deck1 = copy(full_deck)
    else:
        hand = [deck1.pop() for card in range(5)] 
        print "The cards dealt:"
        L(hand)
        print
        print " The remaining cards in the deck:"
        L(deck1)
        print
        print(html("\n The number of remaining cards in the deck = %s"%str(Set(deck1).cardinality())))</input></sage>
</p>
        <p>	
	<exercise><title>WebWork</title><introduction><p>
		Let's see if you understand the relationship between frequency and relative frequency. In this exercise, presume "Probabiity" to be the expected fraction of outcomes you might logically expect.
		</p></introduction><webwork-reps xml:id="extracted-webwork-15" ww-id="webwork-15">
    <pg source="Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability03.pg"/>

      
    <static source="Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability03.pg" seed="15">
      <statement><p>A fun size bag of M<m>\\amp </m>Ms has about 18 candies.  You open one of the bags and discover:</p><p>3 Blues, 4 Yellows, 5 Browns, 2 Reds and 4 Greens.</p><p>The probability of choosing a brown is <fillin name="AnSwEr0001" characters="4"/>.</p><p>The odds in favor of choosing a yellow is <fillin name="AnSwEr0002" characters="4"/></p><p>The probability of choosing either a blue or a red is <fillin name="AnSwEr0003" characters="4"/></p><p>The odds against a green being chosen is <fillin name="AnSwEr0004" characters="4"/></p></statement>
      
      <hint><p>Odds in favor of an event = number of favorable outcomes / number of unfavorable outcomes.</p><p>Odds against an event = number of unfavorable outcomes / number of favorable outcomes.</p></hint>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=15&amp;sourceFilePath=Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability03.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=15&amp;sourceFilePath=Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability03.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=15&amp;sourceFilePath=Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability03.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=15&amp;sourceFilePath=Library/MC/PreAlgebra/setPreAlgebraC06S04/BasicProbability03.pg</server-url>

  </webwork-reps><conclusion><p>
		So, these are simple calculations.
		</p></conclusion></exercise>
</p>
        <p>
	<exercise><title>WebWork</title><introduction><p>This one is a little harder and uses the binomial coefficients from Combinatorics.
		</p></introduction><webwork-reps xml:id="extracted-webwork-16" ww-id="webwork-16">
    <pg source="Library/Rochester/setProbability5RandomSample/ur_pb_5_1a.pg"/>

      
    <static source="Library/Rochester/setProbability5RandomSample/ur_pb_5_1a.pg" seed="16">
      <statement><p>(a) <m/> Count the number of ways to arrange a sample of <m>5</m> elements from a population of
      <m>10</m> elements. NOTE: Order is not important.</p><p>answer: <fillin name="AnSwEr0001" characters="10"/></p><p>(b) <m/> If random sampling is to be employed, the probability that any particular sample will
      be selected is <fillin name="AnSwEr0002" characters="10"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=16&amp;sourceFilePath=Library/Rochester/setProbability5RandomSample/ur_pb_5_1a.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=16&amp;sourceFilePath=Library/Rochester/setProbability5RandomSample/ur_pb_5_1a.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=16&amp;sourceFilePath=Library/Rochester/setProbability5RandomSample/ur_pb_5_1a.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=16&amp;sourceFilePath=Library/Rochester/setProbability5RandomSample/ur_pb_5_1a.pg</server-url>

  </webwork-reps><conclusion><p>
		Notice how the probabilities look similar to relative frequencies. It's just the case 
		that you are counting ALL of the individual simple possibilities that lead to a success.
		</p></conclusion></exercise>
</p>
      </section>
      <section>
        <title>Exercises</title>
        <p>
<exercise><title>Poker</title><statement><p>
	Determine the probabilities associated with the various 5-card hands. That is
	<ol><li>P(one pair)</li><li>P(two pair)</li><li>P(three of a kind)</li><li>P(full house)</li><li>P(four of a kind</li><li>P(straight)</li><li>P(flush)</li><li>P(royal flush)</li></ol>
	</p></statement></exercise>
</p>
        <p>
<exercise><title>Dice</title><statement><p>
	Determine the 36 possible outcomes related to the rolling a pair of fair dice. Justify why each of these outcomes is equally likely. Determine the probabilities associated with each possible sum.
	</p></statement><solution><p>
	Remember, when using equally likely outcomes |A|/|S| assumes that the items counted for A are also in the sample space S.  In this case, for example, to determine the Probability of getting a sum of (say) 4 includes the rolls (1,3), (2,2), and (3,1). These three "successes" from the 36 possible ordered pairs gives P(4) = 3/36.  Similarly, P(5) = |dice rolls with a sum of 5|/36 = |(1,4), (2,3), (3,2), (4,1)| / 36 = 4/36.  Continue in this manner to determine the other possibilities and then compare to the experimental sage cell seen earlier for <xref ref="TwoDiceSage"> the sum of two dice </xref>.
	</p></solution></exercise>
</p>
        <p>
<exercise><title>Skew Dice</title><statement><p>
	Suppose you have one die which only has three possible sides labeled 1, 2, or 3. Suppose a second die has twelve equally likely sides with labels 1,2,3,4,4,5,5,6,6,7,8,9.  Justify that the probabilities associate with each possible sum is the same as the probabilities when using two normal 6-sided dice.
	</p></statement><solution><p>
	Consider the outcome space 
	<me>S = {(1,1), (1,2), (1,3), (1,4), (1,4), (1,5), (1, 5), \\
     (1,6), (1,6), (1,7), (1,8), (1,9), (2,1) ... (3,9)}</me>
	Then P(5) = |(1,4), (1,4), (2,3), (3,2) |/36 = 4/36. Compare this to the exercise with regular dice performed above.  Similarly, compute the remaining probabilities.
	</p></solution></exercise>
</p>
        <p>
<exercise><title>Craps</title><statement><p>
	Analyze the dice game known as "craps": Roll a pair of dice and consider the sum. If that sum is 7 or 11, the one who rolls wins and can roll again. If the sum is 2, 3, or 12 -- known as craps -- the one who rolls loses but keeps the dice. For any other outcome (called the "point"), the one who rolls continues hoping to roll the point value again before rolling a 7. If successful, then the roller wins and starts the game anew. If a 7 appears first, the roller loses and the next person gets to be the roller.
</p><p>
So, a win can be obtained in two ways: 7 or 11 on first roll or getting the point before the 7 thereafter. Therefore, determine the probability of a win and the probability of a loss.
</p></statement><solution><p>
	<url href="http://mathworld.wolfram.com/Craps.html">"craps"</url>.
	</p></solution></exercise>
</p>
      </section>
      <section>
        <title>Conditional Probability</title>
        <introduction>
          <p>When finding the probability of an event, sometimes you may need to consider past history and how it might affect things. Indeed, you might think that when the local station forecasts rain then the probability of it actually raining should be greater than if they forecast fair skies. At least that is the hope. :)  In this section, you will develop a way to deal with the probability of some event that might change dependent upon the occurence or not of some other event.
	</p>
        </introduction>
        <p>Indeed, consider what happens when you keep on dealing a hand of five cards from a shuffled deck but without replacement.  Notice how the probability of the same thing (such as P(getting a Heart on the next card)) oscillates based upon what cards came out of the deck on previous hands.
</p>
        <p>
<sage><input>
print "Conditional Events - successively deal 5 cards w/o replacement" 

var('Ace Clubs Diamonds Hearts Jack King Queen Spades') 

suits = [Spades, Diamonds, Clubs, Hearts] 
values = [2, 3, 4, 5, 6, 7, 8, 9, 10, Jack, Queen, King, Ace] 

deck = [(value, suit) for suit in suits for value in values]
full_deck = copy(deck)  # to save a copy of the original deck for later use.

deck1 = copy(full_deck)
history1=[]
@interact
def _(choice=['Hearts','Spades','Diamonds','Clubs','New Deck'],again=['Repeat Same Suit']):
    global deck1, history1
    shuffle(deck1)
    if choice=='Hearts':
        suit = Hearts
    elif choice=='Spades':
        suit = Spades
    elif choice=='Diamonds':
        suit = Diamonds
    elif choice=='Clubs':
        suit = Clubs
    else:
        deck1 = copy(full_deck)
        shuffle(deck1)
        history1=[]
    if (Set(deck1).cardinality()&lt;5):
        print "Deck is too small...get a new deck"
    elif choice&lt;&gt;'New Deck':
        hand = [deck1.pop() for card in range(5)] 
        print "Click on a desired suit above to deal out another 5 card hand.  The cards dealt:"
        print hand
        print "The remaining cards in the deck:"
        print deck1
        num = Set(deck1).cardinality()
        print "\nThe number of remaining cards in the deck = %s"%str(num)
        looking = []
        for card in deck1:
            if card[1]==suit:
                looking.append(card)
        prob = float(Set(looking).cardinality())/num
        history1.append(prob)
        
        print 'So, the remaining probability of getting a card from '+choice+' from the remaining cards is %s'%str(prob)
    list_plot(history1).show(xmin=0,xmax=9,ymin=0,ymax=1,figsize=(5,2))

</input></sage>
</p>
        <p>Now, consider the case when you put the cards back in, reshuffle, and then get 5 new cards...</p>
        <p>
<sage><input>
print "Independent Events - Successively deal 5 cards but WITH replacement"

var('Ace Clubs Diamonds Hearts Jack King Queen Spades') 

suits = [Spades, Diamonds, Clubs, Hearts] 
values = [2, 3, 4, 5, 6, 7, 8, 9, 10, Jack, Queen, King, Ace] 

deck = [(value, suit) for suit in suits for value in values]
full_deck = copy(deck)  # to save a copy of the original deck for later use.
deck1 = copy(full_deck)

h2=[]
@interact
def _(choice=['Heart','Spade','Diamond','Club'],again=['Repeat Same Suit']):

    if choice=='Hearts':
        suit = Hearts
    elif choice=='Spades':
        suit = Spades
    elif choice=='Diamonds':
        suit = Diamonds
    else:
        suit = Clubs

    deck1 = copy(full_deck)
    shuffle(deck1) 
    hand = [deck1.pop() for card in range(5)] 
    print "The cards dealt:"
    print hand
    print "Replacing this hand and reshuffling gives the remaining cards in the deck:"
    deck1 = copy(full_deck)
    shuffle(deck1)
    print(deck1)
    
    num = Set(deck1).cardinality()
    print "\nThe number of remaining cards in the deck = %s"%str(num)
    looking = []
    for card in deck1:
        if card[1]==suit:
            looking.append(card)
    prob = float(Set(looking).cardinality())/num
    h2.append(prob)
    
    print 'So, the remaining probability of getting a '+choice+' from the remaining cards is %s'%str(prob)
    list_plot(h2).show(xmin=0,xmax=15,ymin=0,ymax=1,figsize=(5,2))
    
    print 'Independent Events - Successively deal 5 cards but WITH replacement' 


</input></sage>
</p>
        <p><em>Changing Sample Space - Balls:</em>  
Consider a box with three balls: one Red, one White, and one Blue.  Using an equally likely assumption, the probability of randomly pulling out a Red ball should be 1/3.  That is P(Red) = 1/3.  However, suppose that for a first trial you pull out the White ball and set it aside. Attempting to pull out another ball leaves you with only two options and so the probability of randomly pulling out a Red ball is 1/2. Notice that the probability changed for the second trial dependent on the outcome of the first trial.
</p>
        <p><em>Changing Sample Space - Cards: </em>
Consider a deck of 52 standard playing cards and a success occurs when a Heart is selected from the deck. When extracting one card randomly, the probability	of that card being a Heart is P(Heart) = 13/52. Now, assume that one card has already been extracted and setaside.  Now, prepare to extract another. If the first card drawn was a Heart, then there are only 12 Hearts left for the second draw. However, if the first card drawn was not a Heart, then there are 13 Hearts available for the second draw. To compute this probability correctly, one need to formulate the question so that subadditivity can be utilized.
</p>
        <p>
Let <m>H_1</m> be the outcome Heart on 1st draw and <m>H_2</m> be the outcome Heart on 2nd draw. Then,
<md><mrow>P(\text{Heart on 2nd draw}) &amp; = P( [ H_1 \cap H_2 ] \cup [ H_1^c \cap H_2 ] )</mrow><mrow> &amp; = P( H_1 \cap H_2 ) + P( H_1^c \cap H_2 )</mrow><mrow> &amp; = \frac{ | H_1 \cap H_2 |}{| P( \text{Number of ways to get two cards} | }</mrow><mrow> &amp; + \frac{ | H_1^c \cap H_2 | }{ | \text{Number of ways to get two cards} | }</mrow><mrow> &amp; = \frac{13}{52} \cdot \frac{12}{51} + \frac{39}{52} \cdot \frac{13}{51} = \frac{12}{4 \cdot 51} + \frac{3 \cdot 13}{4 \cdot 51}	</mrow></md>
</p>
        <p>
<definition><title>Conditional Probability</title><statement><p>For sets A and B,
			<me>P(B | A) = \frac{P(A \cap B)}{ P(A) },</me>
			 provided P(A)<m>\gt 0</m>.
		 </p></statement></definition>
</p>
        <p>
You can read P(B|A) as "the probability of B given A".
</p>
        <p>
<theorem><statement><p>
	Conditional Probability satisfies all of the requirements of regular probability.
	</p></statement><proof><p>
		By definition, for any event probability must be nonnegative. Therefore
		<me>P(A \cap B) \ge 0.</me> 
		So,
		<me>P(B | A) = \frac{\text{positive or zero}}{\text{positive}}\ge 0.</me>
		</p><p>
		Further, 
		<me>P (S | A) = P(A \cap S)/P(A) = P(A)/P(A) = 1.</me>
		For the third part, we will only consider the case when there are two disjoint sets B and C.  Then,
		<md><mrow>P(B \cup C | A) &amp; = \frac{P(A \cap (B \cup C)}{P(A)} </mrow><mrow> &amp; = \frac{P( (A \cap B) \cup (A \cap C) )}{P(A)}</mrow><mrow> &amp; = \frac{P(A \cap B)}{P(A)} + \frac{P(A \cap C)}{P(A)}</mrow><mrow> &amp; = P(B | A) + P(C | A).</mrow></md>
		</p></proof></theorem>
</p>
        <p>	
<theorem><title>Multiplication Rule</title><statement><p> For any sets A and B,
		<me>P(A \cap B) = P(A) P(B | A) = P(B) P(A | B)</me>
	</p></statement><proof><p>
		If P(A)=0 or P(B)=0, then the result is trivial. Otherwise, unravel the definition of conditional probably by taking the denominator to the other side. Also note that you can write <m>A \cap B = B \cap A</m>.
		</p></proof></theorem>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>Conditional Probability sometimes makes you have to think carefully about the ways to get 
		the desired outcome.
		</p></introduction><webwork-reps xml:id="extracted-webwork-17" ww-id="webwork-17">
    <pg source="Library/UMN/algebraKaufmannSchwitters/ks_15_5_42.pg"/>

      
    <static source="Library/UMN/algebraKaufmannSchwitters/ks_15_5_42.pg" seed="17">
      <statement><p>A bag contains <m>6</m> red marbles and <m>7</m> white marbles.  Two marbles are drawn in succession without replacement.  Find the probabilities of the following events:</p><p><em> 1. </em> The first marble drawn is red and the second is white.</p><p>Answer: <fillin name="AnSwEr0001" characters="20"/></p><p><em> 2. </em> Both marbles drawn are red.</p><p>Answer: <fillin name="AnSwEr0002" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=17&amp;sourceFilePath=Library/UMN/algebraKaufmannSchwitters/ks_15_5_42.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=17&amp;sourceFilePath=Library/UMN/algebraKaufmannSchwitters/ks_15_5_42.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=17&amp;sourceFilePath=Library/UMN/algebraKaufmannSchwitters/ks_15_5_42.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=17&amp;sourceFilePath=Library/UMN/algebraKaufmannSchwitters/ks_15_5_42.pg</server-url>

  </webwork-reps><conclusion><p>
		See how you had to break the given question up into two disjoint pieces.
		</p></conclusion></exercise>	
</p>
      </section>
      <section>
        <title>Bayes Theorem</title>
        <introduction>
          <p>Conditional probabilities can be computed using the methods developed above if the appropriate information is available. Some times you will however have some information available, such as <m>P(A | B)</m> but need <m>P(B | A)</m>. The ability to "play around with history" by switching what has been presumed to occur leads to an important result known as Baye's Theorem.
	</p>
        </introduction>
        <theorem>
          <title>Bayes Theorem</title>
          <statement>
            <p>
	Let <m>S = \{ S_1, S_2, ... , S_m \}</m> where the <m>S_k</m> are pairwise disjoint and <m>S_1 \cup S_2 \cup ... \cup S_m = S</m> (i.e. a partition of the space S).  Then for any <m>A \subset S</m>
	
	<me>P(S_j | A) = \frac{P(S_j)P(A | S_j)}{\sum_{k=1}^m P(S_k)P(A | S_k)}.</me>
	
	The conditional probability <m>P(S_j | A)</m> is called the posterior probability of <m>S_k</m>.
	</p>
          </statement>
          <proof>
            <p>
	Notice, by the definition of conditional probability and the multiplication rule
	<me>P(S_j | A) = \frac{P(S_j \cap A)}{P(A)} = \frac{P(S_j)P( A | S_j)}{P(A)}.</me>
	But using the disjointness of the partition 
	<md><mrow>P(A) &amp; = P( (A \cap S_1) \cup (A \cup S_2) \cup ... \cup (A \cup S_m) )</mrow><mrow>    &amp; = P(A \cap S_1) + P(A \cup S_2) + ... + P(A \cup S_m)</mrow><mrow>    &amp; = P(S_1 \cap A) + P(S_2 \cup A) + ... + P(S_m \cup A)</mrow><mrow>    &amp; = P(S_1) P(A | S_1) + P(S_2)P(A | S_2) + ... + P(S_m)P(A | S_m)</mrow><mrow>    &amp; = \sum_{k=1}^m P(S_k)P(A | S_k)</mrow></md>
	Put these two expansions together to obtain the desired result.
	</p>
          </proof>
        </theorem>
        <p>
	To illustrate this result, from the web site <url href="http://stattrek.com/probability/bayes-theorem.aspx"/> consider the following problem:
	</p>
        <p>
	Marie is getting married tomorrow, at an outdoor ceremony in the desert. In recent years, it has rained only 5 days each year. Unfortunately, the weatherman has predicted rain for tomorrow. When it actually rains, the weatherman correctly forecasts rain 90% of the time. When it doesn't rain, he incorrectly forecasts rain 10% of the time. What is the probability that it will rain on the day of Marie's wedding?
	</p>
        <p>
	Notice, all days can be classified into one of two disjoint options:
	<ul><li>Rainy, in which case we can deduce from the given info that P(Rain) = 5/365</li><li>Not Rainy, and since this is the complement of above, P(Not Rain) = 360/365</li></ul>
	In the notation of Bayes Theorem, let A represent a forecast of Rain and note you have 
	<me>P(\text{Rain}) = P(S_1) = \frac{5}{365}</me>
	 and 
	<me>P(\text{Not Rain}) = P(S_2) = \frac{360}{365}.</me> 
	Further, you are given the conditional probabilities
    <me>P(\text{ Forecast Rain | Rain}) = P( A | S_1) = 0.9</me>
    <me>P(\text{ Forecast Rain | Not Rain}) = P( A | S_2) = 0.1</me>
    
    Notice that the question provided requests that you find the probability of Rain given that the weatherman has forecasted rain. What is given on the other hand is the reverse of that conditional probability. Using Bayes Theorem allows you to turn this around...
	<md><mrow>P(\text{Rain}) &amp;  = P(S_1) P( A | S_1) + P(S_2) P(A | S_2)</mrow><mrow> &amp; = \frac{5}{365} \cdot 0.9 + \frac{360}{365} \cdot 0.1</mrow></md>
	Hence, putting these together gives
	<md><mrow>P(\text{Rain | Forecast Rain}) &amp; = \frac{\frac{5}{365} \cdot 0.9}{\frac{5}{365} \cdot 0.9 + \frac{360}{365} \cdot 0.1}</mrow><mrow> &amp; = \frac{5 \cdot 0.9}{5 \cdot 0.9 + 360 \cdot 0.1}</mrow><mrow> &amp; = \frac{45}{45+360} \approx 0.111</mrow></md>
	So, normally there is only a 5 percent chance of rain on a given day but given that the weatherman has forecast rain, the chance of rain has risen to a little more than 11 percent.
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
	Let's try a Bayes Theorem example...
	</p></introduction><webwork-reps xml:id="extracted-webwork-18" ww-id="webwork-18">
    <pg source="Library/Mizzou/Finite_Math/Probability_Bayes_Theorem/Bayes1.pg"/>

      
    <static source="Library/Mizzou/Finite_Math/Probability_Bayes_Theorem/Bayes1.pg" seed="18">
      <statement><p>A biomedical research company produces <m>50 \lt percent /&gt;</m> of its insulin at a plant in Kansas City, and the remainder is produced at a plant in Jefferson City.  Quality control has shown that <m>1.25 \lt percent /&gt;</m> of the insulin produced at the plant in Kansas City is defective, while <m>0.7 \lt percent /&gt;</m> of the insulin produced at the plant in Jefferson City is defective.  What is the probability that a randomly chosen unit of insulin came from the plant in Jefferson City given that it is defective?</p><p><fillin name="AnSwEr0001" characters="20"/></p><p>(<em>Hint:</em> Draw a tree diagram first)</p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=18&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Bayes_Theorem/Bayes1.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=18&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Bayes_Theorem/Bayes1.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=18&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Bayes_Theorem/Bayes1.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=18&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Bayes_Theorem/Bayes1.pg</server-url>

  </webwork-reps><conclusion><p>
	You have to be careful to extract the conditional probabilities from the problem.
	</p></conclusion></exercise>

<exercise><title>WebWork</title><introduction><p>
	Here is a more extensive Bayes Theorem example...
	</p></introduction><webwork-reps xml:id="extracted-webwork-19" ww-id="webwork-19">
    <pg source="Library/UVA-Stat/setStat212-Homework04/stat212-HW04-16.pg"/>

      
    <static source="Library/UVA-Stat/setStat212-Homework04/stat212-HW04-16.pg" seed="19">
      <statement><p>Data from Office on Smoking and Health, Centers for 
      Disease Control and Prevention, indicate that 
      36<percent/> of adults who did not finish high school, 
      33<percent/> of high school graduates, 26<percent/> of 
      adults who completed some college, and 15<percent/> of 
      college graduates smoke.  Suppose that one individual 
      is selected at random and it is discovered that the 
      individual smokes.  Use the probabilities in the 
      following table to calculate the probability that 
      the individual is a college graduate.</p><sidebyside><tabular top="medium" bottom="medium" left="medium" right="medium"><row><cell>Education</cell><cell>Employed</cell><cell>Unemployed</cell></row><row><cell>Not a high school graduate</cell><cell>0.0975</cell><cell>0.0080</cell></row><row><cell>High school graduate</cell><cell>0.3108</cell><cell>0.0128</cell></row><row><cell>Some college, no degree</cell><cell>0.1785</cell><cell>0.0062</cell></row><row><cell>Associate Degree</cell><cell>0.0849</cell><cell>0.0023</cell></row><row><cell>Bachelor Degree</cell><cell>0.1959</cell><cell>0.0041</cell></row><row><cell>Advanced Degree</cell><cell>0.0975</cell><cell>0.0015</cell></row></tabular></sidebyside><p>Probability =  <fillin name="AnSwEr0001" characters="15"/></p><p>Hints: This problem has all the information you need, but not in
      the typical ready-to-use form.  The table above can tell you the 
      proportion of people with various levels of education in the population.
      Keep in mind that any degree (Associate, Bachelor, or Advanced) counts 
      as graduating from college.</p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=19&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework04/stat212-HW04-16.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=19&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework04/stat212-HW04-16.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=19&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework04/stat212-HW04-16.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=19&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework04/stat212-HW04-16.pg</server-url>

  </webwork-reps><conclusion><p>
	Notice that having the data expressed in tabular form sometimes makes it easier to deal with.
	</p></conclusion></exercise>
</p>
        <p>The interactive cell below can be used to easily compute all of the conditional probabilities associated with Bayes's Theorem. Notice how the relative size of the pie-shaped partition changes when you presume that an event in the space has already occurred.</p>
        <p xml:id="BayesSage">
<sage><input>

#  This function is used to convert an input string into separate entries
def g(s): return str(s).replace(',',' ').replace('(',' ').replace(')',' ').split()

@interact
def _(Partition_Probabilities=input_box('0.35,0.25,0.40',label="$ P(S_1),P(S_2),... $"),
        Conditional_Probabilities=input_box('0.02,0.01,0.03',label='$ P(A|S_1),P(A|S_2),... $'),
        print_numbers=checkbox(True,label='Numerical Results on Graphs?'),
        auto_update=False):
            
    Partition_Probabilities = g(Partition_Probabilities)
    Conditional_Probabilities = g(Conditional_Probabilities)
    n = len(Partition_Probabilities)
    n0 = len(Conditional_Probabilities)
    
    # below needs to be n not equal to n0 but mathbook xml will not let me get the other
    if (n &gt; n0):
        pretty_print("You must have the same number of partition probabilities and conditional probabilities.")
        
    else:                               # input data streams now are the same size!
        colors = rainbow(n)
        accum = float(0)                # to test whether partition probs sum to one
        ends = [0]                      # where the graphed partition sectors change in pie chart 
        mid = []                        # middle of each pie chart sector used for placement of text
        p_Sk_given_A = []               # P( S_k | A )
        pA = 0                          # P(A)
        PP=[]                           # array to hold the numerical Partition Probabilities 
        CP=[]                           # array to hold the numerical Conditional Probabilities     
        for k in range(n):
            PP.append(float(Partition_Probabilities[k]))
            CP.append(float(Conditional_Probabilities[k]))    
            p_Sk_given_A.append(PP[k]*CP[k] )
            pA += p_Sk_given_A[k]
            accum = accum + PP[k]
            ends.append(accum)
            mid.append((ends[k]+accum)/2)
#
#  Marching along from 0 to 1, saving angles for each partition sector boundary.
#  Later, we will multiple these by 2*pi to get actual sector boundary angles.
#
        if abs(accum-float(1))&gt;0.0000001:     #  Due to roundoff issues, this should be close enough.                     
            pretty_print("Sum of probabilities should equal 1.")
        
        else:                           # probability data is sensible
 
#        
#  Draw the Venn diagram by drawing sectors from the angles determined above
#  First, create a circle of radius 1 to illustrate the the sample space S
#  Then draw each sector with varying colors and print out their names on the edge
#
            G = circle((0,0), 1, rgbcolor='black',fill=False, alpha=0.4,aspect_ratio=True,axes=False,thickness=5)
            for k in range(n):
                G += disk((0,0), 1, (ends[k]*2*pi, ends[k+1]*2*pi), color=colors[mod(k,10)],alpha = 0.2)
                G += text('$S_'+str(k+1)+'$',(1.1*cos(mid[k]*2*pi), 1.1*sin(mid[k]*2*pi)), rgbcolor='black')
                
            G += circle((0,0), 0.6, facecolor='yellow', fill = True, alpha = 0.1, thickness=5,edgecolor='black') 
    
#  Print the probabilities corresponding to each particular region as a list and on the graphs
            if print_numbers:               

                html("$P(A) = %s$"%(str(pA),))
                for k in range(n):
                    html("$P(S_{%s} | A)$"%(str(k+1))+"$ = %s$"%str(p_Sk_given_A[k]/pA))
                                        
                    G += text(str(p_Sk_given_A[k]),(0.4*cos(mid[k]*2*pi), 0.4*sin(mid[k]*2*pi)), rgbcolor='black')
                    G += text(str(PP[k] - p_Sk_given_A[k]),(0.8*cos(mid[k]*2*pi), 0.8*sin(mid[k]*2*pi)), rgbcolor='black')
        
#  This is essentially a repeat of some of the above code but focused only on creating the smaller inner circle dealing
#  with the set A so that the sectors now correspond in area to the Bayes Theorem probabilities


            accum = float(0)                        
            ends = [0]                     # where the graphed partition sectors change in pie chart 
            mid = []                       # middle of each pie chart sector used for placement of text
            for k in range(n): 
                accum += float(p_Sk_given_A[k]/pA) 
                ends.append(accum)
                mid.append((ends[k]+accum)/2)
            H = circle((0,0), 1, rgbcolor='black',fill=False, alpha=0,aspect_ratio=True,axes=False,thickness=0)
            H += circle((0,0), 0.6, facecolor='yellow',fill=True, alpha=0.1,aspect_ratio=True,axes=False,thickness=5,edgecolor='black')
            
            for k in range(n):
                H += disk((0,0), 0.6, (ends[k]*2*pi, ends[k+1]*2*pi), color=colors[mod(k,10)],alpha = 0.2)
                H += text('$S_'+str(k+1)+'|A$',(0.7*cos(mid[k]*2*pi), 0.7*sin(mid[k]*2*pi)), rgbcolor='black')
                    
        #  Now, print out the bayesian probabilities using the smaller set A only
    
            if print_numbers:
                for k in range(n):
                    H += text(str( N(p_Sk_given_A[k]/pA,digits=4) ),(0.4*cos(mid[k]*2*pi), 0.4*sin(mid[k]*2*pi)), rgbcolor='black')
                    
            G.show(title='Venn diagram of partition with A in middle')
            print
            H.show(title='Venn diagram presuming A has occured')
</input></sage>
</p>
        <p>
<exercise><title>Insured vs Accident</title><statement><p>
	Your automobile insurance company uses past history to determine how to set rates by measuring the number of accidents caused by clients in various age ranges. The following table summarizes the proportion of those insured and the corresponding probabilities by age range:

	<table halign="left"><caption>Age vs Accident Likelihood</caption><tabular halign="right"><row><cell bottom="medium" right="medium">Age</cell><cell bottom="medium" right="medium">Proportion of Insured</cell><cell bottom="medium">Probability of Accident</cell></row><row><cell right="medium">16-20</cell><cell right="medium">0.05</cell><cell>0.08</cell></row><row><cell right="medium">21-25</cell><cell right="medium">0.06</cell><cell>0.07</cell></row><row><cell right="medium">26-55</cell><cell right="medium">0.49</cell><cell>0.02</cell></row><row><cell right="medium">55-65</cell><cell right="medium">0.25</cell><cell>0.03</cell></row><row><cell right="medium">over 65</cell><cell right="medium">0.15</cell><cell>0.04</cell></row></tabular></table>
	
	One of your family friends insured by this company has an accident. 
	<ol><li>Determine the conditional probability that the driver was in the 16-20 age range.</li><li>Compare this to the probability that the driver was in the 18-20 age range. Discuss the difference.</li><li>Determine how much more the company should charge for someone in the 16-20 age range compared to someone in the 26-55 age range.</li></ol>
	</p></statement><solution><p>
	  Plug the middle column into the first input box and the right column into the second input box of the  <xref ref="BayesSage"> Bayes Sage Cell </xref>
	</p></solution></exercise>
</p>
        <p>	
<exercise><title>Spinal bifida odds</title><statement><p>
	Congratulations...your family is having a baby! As part of the prenatal care, some testing is part of the normal procedure including one for spinal bifida (which is a condition in which part of the spinal cord may be exposed.) Indeed, measurement of maternal serum AFP values is a standard tool used in obstetrical care to identify pregnancies that may have an increased risk for this disorder. You want to make plans for the new child's care and want to know how serious to take the test results. However, some times the test indicates that the child has the disorder when in actuality it does not (a false positive) and likewise may indicate that the child does not have the disorder when in fact it does (a false negative.) 
	</p><p>The combined accuracy rate for the screen to detect the chromosomal abnormalities mentioned above is approximately 85% with a false positive rate of 5%. This means that (from <url href="http://americanpregnancy.org/prenatal-testing/first-trimester-screen/">americanpregnancy.org</url>)
	<ul><li>Approximately 85 out of every 100 babies affected by the abnormalities addressed by the screen will be identified. (Positive Positive)</li><li>Approximately 5% of all normal pregnancies will receive a positive result or an abnormal level. (False Positive)</li></ul>
	<ol><li>Given that your test came back negative, determine the likelihood that the child will actually have spinal bifida.</li><li>Given that your test came back negative, determine the likelihood that the child will not have spina bifida</li><li>Given that a positive test means you have a 1/100 to 1/300 chance of experiencing one of the abnormalities, determine the likelihood of spinal bifida in a randomly selected child.</li></ol>
	</p></statement></exercise>
</p>
      </section>
      <section>
        <title>Independence</title>
        <introduction>
          <p>You have seen when repeatedly sampling without replacement leads to a change the the likelihood of some event in successive trials. Indeed, this is what conditional probabilities above illustrate. However, when sampling with replacement you may find a different situation arises. Indeed, you easily notice that when flipping a coin, P(Heads) = 1/2 regardless of the outcome of any previous flip.  In situations such as this where the probability of an event is not affected by the occurrence (or lack of occurrence) of some other event determining the probability of compound events can be greatly simplified.
	</p>
        </introduction>
        <p>	
<definition xml:id="DefnIndependentEvents"><title>Independent Events</title><statement><p>Events A and B are independent provided 
		<me>P(A \cap B) = P(A) P(B)</me>
		</p></statement></definition>
</p>
        <p>	
<corollary><title>Independence and Conditional Probability</title><statement><p>Given <xref ref="DefnIndependentEvents">independent events</xref> A and B, 
			<me>P(B | A) = P(B)</me> and <me>P(A | B) = P(A).</me>
	</p></statement><proof><p>By the multiplication rule and the definition of independence, for any events A and B
			<me>P(A) \cdot P(B) = P(A \cap B) = P(A) \cdot P(B | A) .</me>
			Therefore, if P(A) is non-zero, canceling yields the first result. Switching around notation provides the second.
			</p></proof></corollary>
</p>
        <!--
<p>
<exercise><title>WebWork</title>
	<introduction>
		<p>
		Independence makes combined probabilities VERY easy to compute.
		</p>
	</introduction>
	<webwork source="Library/Rochester/setProbability4Conditional/ur_pb_4_8.pg"></webwork>
	<conclusion>
		<p>
		Basically you just multiply individual probabilities together.  Independence is often
		assumed since it makes computations easier. That said, you should remember to consider
		each time whether independence should or should not be assumed.
		</p>
	</conclusion>
</exercise>
</p>
-->
        <p>
<corollary><title>Independence and Mutual Exclusivity</title><statement><p>If events A and B are both <xref ref="DefnIndependentEvents">independent</xref> and <xref ref="DefnMutuallyExclusive">mutually exclusive</xref>, then at least one of them has zero probability.
	</p></statement><proof><p>
			By independence, <m>P(A \cap B) = P(A) \cdot P(B)</m>. However, by mutually exclusivity, <m>A \cap B = \emptyset \Rightarrow P(A \cap B) = 0</m> gives
			<me>P(A) \cdot P(B) = 0.</me>
			Hence, one or the other (or both) must be zero.
			</p></proof></corollary>
</p>
        <p>
<corollary><title>Successive Independent Events</title><statement><p>Given a sequence of mutually independent events <m>A_1, A_2, A_3, ...</m>,
		<me>P(\cap_{k \in R} A_k) = \prod_{k \in R} P(A_k)</me>	
	</p></statement></corollary>
</p>
      </section>
      <section>
        <title>Summary</title>
        <p>
TBA
</p>
      </section>
      <section>
        <title>More Exercises</title>
        <introduction/>
        <p>
<exercise><title>Conditional Basic computation</title><statement><p>
	Given P(A) = 0.43, P(B) = 0.72, and <m>P(A \cap B) = 0.29</m>, determine
	<ol><li><m>P(A \cup B)</m></li><li><m>P(B | A)</m></li><li><m>P(A | B)</m></li><li><m>P(A^c \cap B^c)</m></li></ol>
	</p></statement></exercise>
</p>
        <p>
<exercise><title>Gender vs University Major</title><statement><p>
	The table below classifies students at your university according to gender and according to major.

	<table halign="left"><caption>Gender vs Major</caption><tabular halign="right"><row><cell bottom="medium" right="medium">Enrollment</cell><cell bottom="medium">Male</cell><cell bottom="medium" right="medium">Female</cell><cell bottom="medium">Totals</cell></row><row><cell right="medium">STEM</cell><cell>420</cell><cell right="medium">510</cell><cell>930</cell></row><row><cell right="medium">Business</cell><cell>320</cell><cell right="medium">270</cell><cell>590</cell></row><row><cell bottom="medium" right="medium">Other</cell><cell bottom="medium">610</cell><cell bottom="medium" right="medium">710</cell><cell bottom="medium">1320</cell></row><row><cell right="medium">Totals</cell><cell>1350</cell><cell right="medium">1490</cell><cell>2840</cell></row></tabular></table>

	Determine the following:
	<ol><li>P( STEM major )</li><li>P( STEM | Female )</li><li>P( Female | STEM )</li><li>P( Female | Not STEM)</li></ol>
	</p></statement></exercise>
</p>
        <p>	
<exercise><title>Mean Tough Teacher</title><statement><p>
	You are in a probability and statistics class with a teacher who has predetermined that only one student can make an A for the course. To be "fair", he places a number of slips of paper in a bowl equal to the number of students in the course with one of the slips having an A designation. Students in the course each can pick once randomly from the bowl and without replacement to see if they can get the lucky slip.  Determine the following:
	<ol><li>If there are 15 students in your course, determine the probabilities of getting an A in the course if you pick first and if you pick last.</li><li>Since the teacher likes you the most, she will give you the option of deciding whether to pick at any position. If so, determine the position that would give you the best likelihood of getting the A slop.</li><li>Suppose again that the teacher was feeling more generous and decided instead to allow for two A's. Determine how that changes your likelihood of winning and on what position you would like to choose.</li><li>Continue as above except that only one slip does not have an A on it.</li><li>Discuss how your choice is affected by the number of students in the course or the number of A slips included.</li></ol>
	</p></statement><solution><p>
	Using the normal equally-likely definition, <m>P(\text{first}) = \frac{1}{15}</m>.
	</p><p>
	To get the A on the last pick requires that all of the previous picks to be something else. You don't get the opportunity to pick the A if it has already been selected. So, if L stands for losing (not getting the A), then 
	<md><mrow> P(\text{last}) = P(\text{LLLLLLLLLLLLLLA}) = \frac{14 \cdot 13 \cdot 12 \cdot 11 \cdot 10 \cdot 9  \cdot 8  \cdot 7  \cdot 6  \cdot 5  \cdot 4  \cdot 3 \cdot 2  \cdot 1}{15 \cdot 14 \cdot 13 \cdot 12 \cdot 11 \cdot 10 \cdot 9 \cdot 8 \cdot 7 \cdot 6 \cdot 5 \cdot 4 \cdot 3 \cdot 2} = \frac{1}{15}.</mrow></md>
	Therefore, it is the same probability of getting the A whether you pick first or last.  In general, to win on the kth pick gives
	<md><mrow> P(\text{kth}) = P(\text{LL...LA}) = \frac{14 \cdot 13 \cdot ... \cdot (15-k) \cdot 1}{15 \cdot 14 ... \cdot (16-k) \cdot (15-k)} = \frac{1}{15}</mrow></md>
	Hence, it is the same probability regardless of when you get to pick.
	</p><p>
	If there are two A's possible, then the options for person k in include either receiving the first of the two slips or the second. The probability for determining the first of the two is computed in a manner similar to above except that there is one more A and one less other.
	<md><mrow> P(\text{kth as first}) = P(\text{LL...LA}) = \frac{13 \cdot 12 \cdot ... \cdot (15-k)  \cdot 2}{15 \cdot 14 ... \cdot (16-(k+1)) \cdot (16-k)} = \frac{2 \cdot (15-k)}{15 \cdot 14}</mrow></md>

	The probability of getting the second A means exactly one of the previous k-1 selections also picked the other A. There are k-1 ways that this could happen. Computing for one of the options and multiplying by k-1 gives
	<md><mrow> P(\text{kth as second}) = P(\text{LL...LAA}) = (k-1) \cdot \frac{13 \cdot 12 \cdot ... \cdot (15-k) \cdot 2 \cdot 1}{15 \cdot 14 ... \cdot (16-k) \cdot (15-k)} = \frac{2 \cdot (k-1)}{15 \cdot 14}.</mrow></md>	
	Adding these two together gives
	<md><mrow>P(\text{getting an A when there are two}) = \frac{2 \cdot (15-k) + 2 \cdot (k-1)}{15 \cdot 14}</mrow><mrow> = \frac{28}{15 \cdot 14} = \frac{2}{15}.</mrow></md>

	For example, if k = 5,
	<md><mrow> P(\text{5th as first}) = P(\text{LLLLA}) </mrow><mrow> = \frac{13 \cdot 12 \cdot 11 \cdot 10  \cdot 2}{15 \cdot 14 \cdot 13 \cdot 12 \cdot 11} = \frac{20}{15 \cdot 14}</mrow></md>
	<md><mrow> P(\text{5th as second}) = P(\text{LL...LAA}) </mrow><mrow> = 4 \cdot \frac{13 \cdot 12 \cdot \cdot 11 \cdot 2 \cdot 1}{15 \cdot 14 \cdot 13 \cdot 12 \cdot 11} = \frac{8}{15 \cdot 14}.</mrow></md>	
	Adding these together yields the general result. So, once again, it doesn't matter which pick you use since the likelihood of getting an A is the same for all positions.
	</p></solution></exercise>
</p>
        <p>
<exercise><title>Shared Birthdays</title><statement><p>
	In this problem, you want to consider how many people are necessary in order to have an even chance of finding two or more who share a common birthday. Toward that end, assuming a year has exactly 365 equally likely days let r be the number of people in a sample and consider the following:
	<ol><li>Determine the number of different outcomes of birthdays when order matters and birthdays are allowed to be repeated.</li><li>Determine the number of different outcomes when birthdays are not allowed to be repeated.</li><li>Determine the probability that two or more of your r students have the same birthday.</li><li>Prepare a spreadsheet with the probabilities found above from r=2 to r=50. Determine the value of r for which this probability is closest to 0.5.</li><li>As best as you can, sample two groups of the size found above and gather birthday information. For each group, determine if there is a shared birthday or not.  Compare your results with others in the class to check whether the sampling validates that about half of the samples should have a shared birthday group.</li></ol>
	</p></statement><solution><p>
	The correct sample size to get past a probability of 0.5 is 23 people. You should justify this numerically by justifying the following probabilities:
<pre>
#	P(Match)	
1	0
2	0.0027
3	0.0082
4	0.0164
5	0.0271
6	0.0405
7	0.0562
8	0.0743
9	0.0946
10	0.1169
11	0.1411
12	0.1670
13	0.1944
14	0.2231
15	0.2529
16	0.2836
17	0.3150
18	0.3469
19	0.3791
20	0.4114
21	0.4437
22	0.4757
23	0.5073
24	0.5383
25	0.5687
26	0.5982
27	0.6269
28	0.6545
29	0.6810
30	0.7063
</pre>
	</p></solution></exercise>
</p>
        <p>
<exercise><title>Internet meme solution</title><statement><p>
	This one is from an internet meme:  Two fair 6-sided dice are rolled together and you are told that at least one of the dice is a 6. Given that a 6 will be removed, determine the probability that the other die is a 6.
	</p></statement><solution><p>
	In this case, you are presented with an outcome where the possible choices consist of (1,6), (2,6), (3,6), (4,6), (5,6), (6,6), (6,5), (6,4), (6,3), (6,2), (6,1).  Each of these would satisfy the condition that at least one of the dice is a 6. From this group, the only success that satisfies being a 6, given that another 6 has already been removed, is the (6,6) outcome. Therefore, the conditional probability is 1/11.
	</p><p>
	It is interesting to note that if the question instead was posed so that one of the dice was a 6 and it was removed, then the probability of the other dice showing a 6 would be 1/6.
	</p></solution></exercise>
</p>
        <p>
<exercise><title>100 people on an airplane with boarding pass issues</title><statement><p>
	This is a famous problem.  100 people are in line, boarding an airplane with 100 seats, one at a time. They are in no particular order. The first person has lost his boarding pass, so he sits in a random seat. The second person does the following:

	<ul><li>Goes to his seat (the one it says to go to on the boarding pass). If unoccupied, sit in it.</li><li>If occupied, find a random seat to sit in.</li></ul>
	Everyone else behind him does the same. What is the probability that the last person sits in his correct seat?
	</p></statement><solution><p>
	To get the idea, consider what happens with only 2 people, then only 3. Generalize. 
	</p><p>
	The answer is 1/2. To obtain this, you can define recursively the probability that the kth person sits in their own set as f(k).  Consider the first traveler's and your seats. Then you get the following cases:
	<ul><li>P(first guy sits in his own seat and you sit in yours) = <m>\frac{1}{k} \cdot 1</m> </li><li>P(first guy sits in your seat and you do not sit in yours) = <m>\frac{1}{k} \cdot 0</m> </li><li>P(other k-2 travelers make their choices) = <m>(k-2) \frac{1}{k} f(k-1)</m> </li></ul>
	<me>f(k) = 1/k + 0 + (k-2)/k f(k-1)</me>
	with f(2) = 1/2.
	</p><p>
	For example,
	<ul><li>f(3) = 1/3 + f(2)/3 = 1/3 + 1/6 = 1/2. </li><li>f(4) = 1/4 + 2/4 f(3) = 1/4 + 1/2 1/2 = 1/2. </li><li>f(5) = 1/5 + 3/5 1/2 = 1/2. </li><li>f(6) = 1/6 + 4/6 1/2 = 1/2. </li></ul>
	Etc.
	</p></solution></exercise>
</p>
        <p>
<exercise><title>Basic Independence Calculations</title><statement><p>
	Given P(A) = 0.43, P(B) = 0.72, and <m>P(A \cap B) = 0.31</m>, verify that A and B are not independent.
	</p></statement><solution><p>
	A and B are <xref ref="DefnIndependentEvents">independent by definition</xref> provided 
	<me>P(A \cap B) = P(A) P(B).</me>
	Using the provided values, notice that
	<me>P(A \cap B) = 0.31</me>
	but
	<me>P(A)P(B) = 0.43 \cdot 0.72 = 0.3096.</me>
	Since these are not equal (regardless how close) then A and B are not independent.
	</p></solution></exercise>
</p>
        <p>
<exercise><title>Compound events and Independence</title><statement><p>
	Given A, B, and C are independent events, with P(A) = 2/5, P(B) = 3/4, and P(C) = 1/6, determine:
	<ol><li><m>P(A \cap B \cap C)</m></li><li><m>P(A^c \cap B^c \cap C)</m></li><li><m>P(A \cup B \cup C)</m></li></ol>
	</p></statement><solution><p>
	Extending the <xref ref="DefnIndependentEvents">definition of independent events</xref> gives
	<me>P(A \cap B \cap C) = \frac{2}{5} \frac{3}{4} \frac{1}{6}.</me>
	By the corollary for independent events, complements also maintain a similar independence. So
	<me>P(A^c \cap B^c \cap C) \frac{3}{5} \frac{1}{4} \frac{1}{6} .</me>
	To complete the third part, use the <xref ref="ProbabilityThreeUnions">inclusion/exclusion result</xref> for dealing with three sets.
	</p></solution></exercise>
</p>
        <p>	
<exercise><title>Rolling multiple dice</title><statement><p>
For a pair of dice you want to consider the events A = {rolling a 7 or 11} and B = {otherwise}...as in the first roll in the game of craps.  Further, for notation purposes let's take ABA (for example) to mean event A occurs on the first roll, event B occurs on the second roll, and event A occurs again on the third roll...in that order only. If you roll the dice 5 times, determine
	<ol><li>P(AABBB)</li><li>P(BBBAA)</li><li>The probability of getting A on exactly two rolls of the dice.</li></ol>
	</p></statement><solution><p>
	Successive rollings of a pair of dice are <xref ref="DefnIndependentEvents">independent events</xref>. Therefore, 
	<me>P(AABBB) = P(A)P(A)P(B)P(B)P(B) = \frac{8}{36} \frac{8}{36} \frac{28}{36} \frac{28}{36} \frac{28}{36}</me>
	Similarly for the second part.
	</p><p>
	For the third part, notice that there will be <m>\binom{5}{2}</m> ways to rearrange 2 A's and 3 B's but that each of these will have two 8/36's and three 28/36's but just in a different order. Therefore, you will get
	<me>10 \cdot \frac{8}{36} \frac{8}{36} \frac{28}{36} \frac{28}{36} \frac{28}{36}</me>
	</p></solution></exercise>
</p>
        <p>
<exercise><title>Redundancy</title><statement><p>
	To help "insure" the success of a mission, you propose several redundant components so that the mission is a success if one or more succeed. Supposing that these separate components act independently of each other and that each component has a 75% chance of success, determine:
	<ol><li>The probability of failure if you utilize 2 components.</li><li>The probability of failure if you utilize 5 components.</li><li>The number of components needed to insure that the probability of success is at least 99%.</li></ol>
	</p></statement></exercise>
</p>
        <p>
<exercise><title>Internet Meme redux</title><statement><p>
	Again, from an internet meme:  Two fair 6-sided dice are rolled together and you are told that at least one of the dice is a 6. A 6 is removed and you are presented with the other die.  Determine the probability that it is a 6.
	</p></statement><solution><p>
	For this setting, notice that the outcomes from each of the two dice are independent of each other. Removing one of the dice, regardless of it's value, does not affect the other. The question in this case does not ask for a conditional probability.
	</p></solution></exercise>
</p>
        <p>
<exercise><title>Single Elimination Tournament</title><statement><p>
	Consider a n=4 team single-elimination tournament where the teams are "seeded" from 1 (the best team) to 4 (the worst team).  For this tournament, team 1 plays team 4 and team 2 plays team 3. The winner of each play each other to determine the final winner. When teams j and k play, set P(j wins) = <m>\frac{k}{j+k}</m> and similarly for team k.  Assuming separate games are independent of each other, determine the probability that team 4 wins the tournament. What about with 8 teams? What about 64 teams?
	</p></statement><solution><p>
	P(4 wins) = P(4 beats 1) P(4 beats the winner of the other bracket)
	</p><p>
	P(4 wins) = (1/5) * P(4 beats 2 | 2 beats 3) + P(4 beats 3 | 3 beats 2)
	</p><p>
	P(4 wins) = 1/5 [(3/5)(2/6) + (2/5)(3/7)] = 78/1050 = 0.0742
	</p><p>
	For the other teams:
	</p><p>
	P(1 wins) = 4/5 [(3/5)(2/3) + (2/5)(3/4) ] = 0.56
	</p><p>
	P(2 wins) = 3/5 [(4/5)(1/3) + (1/5)(4/6) ] = 0.24
	</p><p>
	P(3 wins) = 2/5 [(4/5)(1/4) + (1/5)(4/7) ] = 0.1257
	</p></solution></exercise>
</p>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="ProbabilityFunctions">
      <title>Probability Functions</title>
      <section>
        <title>Introduction</title>
        <p>Each of the probability exercises thus far required you to utilize basic definitions and theorems to determine the answer. Starting a new problem meant starting over from scratch. This is burdensome.  However, you may have noticed that some of the ways you might have created solutions for some problems ending up looking very similar to the solutions for others. In this chapter, you will consider the framework needed for creating general solution techniques. These techniques will give a number of "distributions" which are general ways to solve a particular type of problem.
</p>
        <p>Toward that end, in this chapter you will see how to create a random variable which takes items in the sample space and assigns corresponding numerical values. From that, you will see how to create "Probability Functions" on that variable that provide the desired probability by simple function evaluation. General properties these functions possess will also be developed.
</p>
      </section>
      <section>
        <title>Random Variables</title>
        <p>For a given set of events, we might have difficulty doing mathematics since the outcomes
are not numerical. In order to accomodate our desire to convert to numerical measures we want
to assign numerical values to all outcomes. The process of doing this creates what is known as a random
variable.
</p>
        <p>
<definition><title>Random Variable</title><statement><p>Given a random experiment with sample space S, a function X mapping each 
		element of S to a unique real number is called a random variable. 
		For each element s from the sample space S, denote this function by
		<me>X(s) = x</me>
		and let R  be the range of X. R will be called "the space of X" and in notation
		<me> R = { x : X(s)=x, \text{for some} s \in S } .</me>
		</p></statement></definition>
</p>
        <image source="images/randomvariable.png"/>
        <p>We will make various restrictions on the range of the random variable to fit different 
generalized problems. Then, we will be able to work on a problem (which may be 
inherently non-numerical) by using the random variable in subsequent calculations.
</p>
        <p>
<example><title>Success vs Failure</title><p>When dealing with only two outcomes, one might use 
	<me>S = \text{{ success, failure }}.</me>
	Choose 
	<md><mrow>X(success)=1</mrow><mrow>X(failure)=0.</mrow></md>
	Then, R={0,1}.
	</p></example>
</p>
        <p>
<example><title>Standard Dice Pairs</title><p>When gambling with a pair of dice, one might use
	S=ordered pairs of all possible rolls.  Then 
	<me>S = \text{ {(a,b): a=die 1 outcome, b=die 2 outcome}}.</me>
	Choose 
	<me>X( (a,b) ) = a+b.</me> 
	Then, R={2, 3, 4, 5, ..., 12}.
	</p></example>
</p>
        <p>
<example><title>Other Dice Options</title><p>When rolling dice in a board game (like RISK), one might use
	<me>S= \text{{(a,b): a=die 1 outcome, b=die 2 outcome}}</me>
	Choose 
	<me>X( (a,b) ) = \text{max{a,b}}.</me> 
	Then, R={1, 2, 3, 4, 5, 6}.
	</p></example>
</p>
        <p>
<definition><title>Countable and Uncountable Sets</title><statement><p>
		R contains a countable number of points if either R is finite or there 
		is a one to one correspondence between R and the positive integers. 
		Such a set will be called discrete. We will see that often the set R is not countable. 
		If R consists of an interval of points (or a union of intervals), 
		then we call X a continuous random variable. 
		</p></statement></definition>
</p>
      </section>
      <section>
        <title>Probability Functions</title>
        <p>In the formulas below, we will presume that we have a random variable X which maps the sample space S onto some range of real numbers R.  From this set, we then can define a probability function f(x) which acts on the numerical values in R and returns another real number.  We attempt to do so to obtain (for discrete values) P(sample space value s)<m> = f(X(s))</m>.  That is, the probability of a given outcome s is equal to the composition which takes s to a numerical value x which is then plugged into f to get the same final values.
</p>
        <p>For example, consider a random variable which assigns a 1 when you roll a 1 on a six-sided die and 0 otherwise. Presuming each side is equally likely, <m>f(1) = \frac{1}{6}</m> and <m>f(0) = \frac{5}{6}</m>.
</p>
        <p>
<definition><title>Probability "Mass" Function</title><statement><p>Given a discrete random variable X on a space R, a probability mass function on X is given by a function <m>f:R \rightarrow \mathbb{R}</m> such that:
		<md><mrow>&amp; \forall x \in R , f(x) \gt 0</mrow><mrow>&amp; \sum_{x \in R} f(x) = 1</mrow><mrow>&amp; A \subset R \Rightarrow P(X \in A) = \sum_{x \in A}f(x)</mrow></md>
		For <m>x \not\in R</m>, you can use the convention f(x)=0.
		</p></statement></definition>
</p>
        <p>	
<definition><title>Probability "Density" Function</title><statement><p>Given a continuous random variable X on a space R, a probability density function on X is given by a function <m>f:R \rightarrow \mathbb{R}</m> such that:
		<md><mrow>&amp; \forall x \in R , f(x) \gt 0</mrow><mrow>&amp; \int_{R} f(x) dx = 1</mrow><mrow>&amp; A \subset R \Rightarrow P(X \in A) = \int_{A} f(x) dx</mrow></md>
		For <m>x \not\in R</m>, you can use the convention f(x)=0.
	</p></statement></definition>
</p>
        <p>
For the purposes of this book, we will use the term "Probability Function" to refer to either of these options.
</p>
        <p>
<example><title>Discrete Probability Function</title><p>
Consider <m>f(x) = x/10</m> over R = {1,2,3,4}.  Then, f(x) is obviously positive for each of the values in R and certainly <me>\sum_{x \in R} f(x) = f(1) + f(2) + f(3) + f(4) = 1/10 + 2/10 + 3/10 + 4/10 = 1.</me> Therefore, f(x) is a probability mass function over the space R.
</p></example>
</p>
        <p>
<sage><title>Sampling Discrete Probability Function</title><input>
# Combining all of the above into one interactive cell
@interact
def _(D = input_box([1,2,3,5,6,8,9,11,12,14],label="Enter domain R (in brackets):"), 
       Probs = input_box([1/20,1/20,1/20,3/20,1/20,4/20,4/20,1/20,1/20,3/20],label="Enter corresponding f(x) (in brackets):"),
       n_samples=slider(100,10000,100,100,label="Number of times to sample from this distribution:")):
    n = len(D)
    R = range(n)
    one_huh = sum(Probs)
    pretty_print('\n\nJust to be certain, we should check to make certain the probabilities sum to 1\n')
    pretty_print(html('$\sum_{x\epsilon R} f(x) = %s$'%str(one_huh)))
    
    G = Graphics()
    if len(D)==len(Probs):
        f = zip(D,Probs)
        meanf = 0
        variancef = 0
        for k in R:
            meanf += D[k]*Probs[k]
            variancef += D[k]^2*Probs[k]
            G += line([(D[k],0),(D[k],Probs[k])],color='green')
        variancef = variancef - meanf^2
        sd = sqrt(variancef)
        G += points(f,color='blue',size=50)
        G += point((meanf,0),color='yellow',size=60,zorder=3)
        G += line([(meanf-sd,0),(meanf+sd,0)],color='red',thickness=5)
    
        g = DiscreteProbabilitySpace(D,Probs)
        pretty_print('     mean = %s'%str(meanf))
        pretty_print(' variance = %s'%str(variancef))
    
        #  perhaps to add mean and variance for pmf here
    else:
        print 'Domain D and Probabilities Probs must be lists of the same size'
    
    #  Now, let's sample from the distribution given above and see how a random sampling matches up

    counts = [0] * len(Probs)
    X = GeneralDiscreteDistribution(Probs)
    sample = []

    for _ in range(n_samples):
        elem = X.get_random_element()
        sample.append(D[elem])
        counts[elem] += 1
    Empirical = [1.0*x/n_samples for x in counts] # random
    
    samplemean = mean(sample)
    samplevariance = variance(sample)
    sampdev = sqrt(samplevariance)
    
    E = points(zip(D,Empirical),color='orange',size=40)
    E += point((samplemean,0.005),color='brown',size=60,zorder=3)
    E += line([(samplemean-sampdev,0.005),(samplemean+sampdev,0.005)],color='orange',thickness=5)    
    (G+E).show(ymin=0,figsize=(8,5))	
</input></sage>
</p>
        <p>
<example><title>Continuous Probability Function</title><p>
	Consider <m>f(x) = x^2/c</m> for some positive real number c and presume R = [-1,2]. Then f(x) is nonnegative (and only equals zero at one point). To make f(x) a probability density function, we must have
	<me>\int_{x \in R} f(x) = 1.</me>
	In this instance you get
	<me>1 = \int_{-1}^2 x^2/c = x^3/(3c) |_{-1}^2 = \frac{8}{3c} - \frac{-1}{3c} = \frac{3}{c}</me>
	Therefore, f(x) is a probability density function over R provided   = 3.
</p></example>
</p>
        <p>	
<definition><title>Distribution Function</title><statement><p>Given a random variable X on a space R, a probability distribution function on X is given by a function 
		<me>F:\mathbb{R} \rightarrow \mathbb{R} \ni \displaystyle F(x)=P(X \le x).</me>
		</p></statement></definition>
</p>
        <p>
<example><title>Discrete Distribution Function</title><p>Using <m>f(x) = x/10</m> over R = {1,2,3,4} again, note that F(x) will only change at these four domain values. We get
	
	<table halign="left"><caption>Discrete Distribution Function Example</caption><tabular halign="right"><row><cell bottom="medium" right="medium">X</cell><cell bottom="medium">F(x)</cell></row><row><cell right="medium"><m>x \lt 1</m></cell><cell>0</cell></row><row><cell right="medium"><m>1 \le x \lt 2</m></cell><cell>1/10</cell></row><row><cell right="medium"><m>2 \le x \lt 3</m></cell><cell>3/10</cell></row><row><cell right="medium"><m>3 \le x \lt 4</m></cell><cell>6/10</cell></row><row><cell right="medium"><m>4 \le x </m></cell><cell>1</cell></row></tabular></table>
	</p></example>
</p>
        <p>	
<example><title>Continuous Distribution Function</title><p>
	Consider <m>f(x) = x^2/3</m> over R = [-1,2].  Then, for <m>-1 \le x \le 2</m>,
	<me>F(x) = \int_{-1}^x u^2/3 du = x^3/9 + 1/9.</me>
	Notice, F(-1) = 0 since nothing has yet been accumulated over values smaller than -1 and F(2)=1 since by that time everything has been accumulated. In summary:
	
	<table halign="left"><caption>Continuous Distribution Function Example</caption><tabular halign="right"><row><cell bottom="medium" right="medium">X</cell><cell bottom="medium">F(x)</cell></row><row><cell right="medium"><m>x \lt -1</m></cell><cell>0</cell></row><row><cell right="medium"><m>-1 \le x \lt 2</m></cell><cell><m>x^3/9 + 1/9</m></cell></row><row><cell right="medium"><m>2 \le x</m></cell><cell>1</cell></row></tabular></table>
		
	</p></example>
</p>
        <!--
<p>
<exercise><title>WebWork</title>
		<introduction>
		<p>
		</p>
		</introduction>
<webwork source="Library/UBC/STAT/STAT241_251/setAssignment-02/HW02-01/HW02-01a.pg">
		</webwork>
</exercise>
</p>
-->
        <p>		
<theorem xml:id="theorem-Fmin"><statement><p><m>F(x)=0, \forall x \lt \inf(R)</m>
		</p></statement><proof><p>
		Let a = inf(R). Then, for <m>x \lt a,</m>
		<me>F(x) = P(X \le x) \le P(X \lt a) = 0</me> 
		since none of the x-values in this range are in R.
		</p></proof></theorem>
</p>
        <p>	
<theorem xml:id="theorem-Fmax"><statement><p>
	<m>F(x)=1, \forall x \ge \sup(R)</m>
	</p></statement><proof><p>
		Let b = sup(R). Then, for 
		<me>x \ge b, F(x) = P(X \le x)  = P(X \le b) + P( b \lt X \le x) = P(X \le b) = 1</me> 
		since all of the x-values in this range are in R and therefore will either sum over or integrate over all of R.
		</p></proof></theorem>
</p>
        <p>	
<theorem><statement xml:id="theorem-F-non-decreasing"><p>
	F is non-decreasing
	</p></statement><proof><p>Case 1: R discrete
			<md><mrow>\forall x_1,x_2 \in \mathbb{Z} \ni x_1 \lt x_2</mrow><mrow>F(x_2) &amp; = \sum_{x \le x_2} f(x) </mrow><mrow>&amp; = \sum_{x \le x_1} f(x) + \sum_{x_1 \lt x \le x_2} f(x)</mrow><mrow>&amp; \ge \sum_{x \le x_1} f(x) = F(x_1)</mrow></md>
		</p><p>Case 2: R continuous
			<md><mrow>\forall x_1,x_2 \in \mathbb{R} \ni x_1 \lt x_2</mrow><mrow>F(x_2) &amp; = \int_{-\infty}^{x_2} f(x) dx </mrow><mrow> &amp; = \int_{-\infty}^{x_1} f(x) dx + \int_{x_1}^{x_2} f(x) dx</mrow><mrow> &amp; \ge \int_{-\infty}^{x_1} f(x) dx</mrow><mrow> &amp; = F(x_1)</mrow></md>
		</p></proof></theorem>
</p>
        <p>
<theorem xml:id="theorem-Fvsf-discrete"><title>Using Discrete Distribution Function to compute probabilities</title><statement><p>For <m>x \in R, f(x) = F(x) - F(x-1)</m>
	</p></statement><proof><p>Assume <m>x \in R</m> for some discrete R. Then,
		<me>F(x) - F(x-1) = \sum_{u \le x} f(u) - \sum_{u \lt x} f(u) = f(x)</me>
		</p></proof></theorem>
</p>
        <p>	
<theorem xml:id="theorem-Fvsf-continuyous"><title>Using Continuous Distribution function to compute probabilities</title><statement><p>For <m>a \lt b, (a,b) \in R, P(a \lt X \le b) = F(b) - F(a)</m>
	</p></statement><proof><p>
		For a and b as noted, consider 
		<md><mrow>F(b) - F(a) &amp; = \int_{-\infty}^b f(x) dx - \int_{-\infty}^a f(x) dx</mrow><mrow> &amp; = \int_a^b f(x) dx </mrow><mrow> &amp; = P(a \lt x \le b)</mrow></md>
		</p></proof></theorem>
</p>
        <p>
<corollary xml:id="corollary-ProbPointZero-continuous"><statement><p>For continuous distributions, P(X = a) = 0
	</p></statement><proof><p>
		We will assume that F(x) is a continuous function. With that assumption, note
		<me>P(a-\epsilon \lt  x \le a)  = \int_{a-\epsilon}^a f(x) dx = F(a) - F(a-\epsilon)</me>
		Take the limit as <m> \epsilon \rightarrow 0^+</m> to get the result noting that
		</p></proof></corollary>
</p>
        <p>
<theorem><title>F(x) vs f(x), for continuous distributions</title><statement><p>If X is a continuous random variable, f the corresponding probability function, and F the associated distribution function, then
		<me>f(x) = F'(x)</me>
		</p></statement><proof><p>Assume X is continuous and f and F as above. Notice, by the definition of f, <m>\lim_{x \rightarrow \pm \infty} f(x) = 0</m> since otherwise the integral over the entire space could not be finite.
	</p><p>
	Now, let A(x) be any antiderivative of f(x). Then, by the Fundamental Theorem of Calculus,
	<md><mrow>F(x) &amp; = \int_{-\infty}^x f(u) du</mrow><mrow> &amp; = A(x) - \lim_{u \rightarrow -\infty} A(u)</mrow></md>
	Hence, <m>F'(x) = A'(x) - \lim_{u \rightarrow -\infty} A'(u) = f(x)</m> as desired.
	</p></proof></theorem>
</p>
        <p>
<definition><title>Percentiles for Random Variables</title><statement><p>
For <m>0 \lt p \lt 1</m>, the <m>100p^{th}</m> percentile is the largest random variable value c that satisfies
<me>F(c) = p.</me>
For continuous random variables over an interval R = [a,b], you will solve for c in the equation
<me>\int_a^c f(x) dx.</me>
For discrete random variables, it is unlikely that a particular percentile will land exactly on one of the elements of R but you will want to take the smallest value in R so that <m>F(c) \ge p</m>.
</p><p>
The 50th percentile (as before) is also known as the median.
</p></statement></definition>
</p>
        <p>
<example><title>Continuous Percentile</title><p>
For our earlier example with <m>f(x) = x^2/3</m> on R = [-1,2], the 50th percentile (i.e. the median) is found by starting with p = 0.5 and then solving 
<me>F(c) = 0.5</me>
or
<me>c^3/9 + 1/9 = 1/2</me>
or 
<me>c^3 + 1 = 9/2.</me>
After solving for c, you find
<me>\text{median} = \sqrt[3]{7/2} \approx 1.518.</me> 
</p></example>
</p>
        <p>
<example><title>Discrete Percentile</title><p>
TBA, using one of the table examples from above.
</p></example>
</p>
      </section>
      <section>
        <title>Expected Value</title>
        <p>Blaise Pascal was a 	17th century mathematician and philosopher who was accomplished in many areas but may likely be best known to you for his creation of what is now known as Pascal's Triangle. As part of his philosophical pursuits, he proposed what is known as "Pascal's wager". It suggests two  mutually exclusive outcomes: that God exists or that he does not. His argument is that a rational person should live as though God exists and seek to believe in God. If God does not actually exist, such a person will have only a finite loss (some pleasures, luxury, etc.), whereas they stand to receive infinite gains as represented by eternity in Heaven and avoid an infinite losses of eternity in Hell. This type of reasoning is part of what is known as "decision theory".
	</p>
        <p>You may not confront such dire payouts when making your daily decisions but we need a formal method for making these determinations precise. The procedure for doing so is what we call expected value.
	</p>
        <p>
	<definition><title>Expected Value</title><p>Given a random variable X over space R, corresponding probability function f(x) and "value function" v(x), the expected value of v(x) is given by
	<me>E = E[v(X)] = \sum_{x \in R} v(x) f(x)</me>
	provided X is discrete, or
	<me>E = E[v(X)] = \int_R v(x)f(x) dx</me>
	provided X is continuous.
	</p></definition>
	</p>
        <p>
<theorem><title>Expected Value is a Linear Operator</title><statement><p>
	<ol><li>E[c] = c</li><li>E[c v(X)] = c E[v(X)]</li><li>E[v(X) + w(X)] = E[v(X)] + E[w(X)]</li></ol>
	</p></statement><proof><p>Each of these follows by utilizing the corresponding linearity properties of the summation and integration operations. For example, to verify part three in the continuous case:
	<md><mrow>E[v(X) + w(X)] &amp; = \int_{x \in R} [v(x)+w(x)]f(x) dx</mrow><mrow> &amp; = \int_{x \in R} v(x)f(x) dx + \int_{x \in R} w(x)f(x) dx</mrow><mrow> &amp; = E[v(X)] + E[w(X)].</mrow></md>
	</p></proof></theorem>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		Use algebra and the theorem above.
		</p></introduction><webwork-reps xml:id="extracted-webwork-20" ww-id="webwork-20">
    <pg source="Library/Rochester/setProbability17Expectation/ur_pb_17_4.pg"/>

      
    <static source="Library/Rochester/setProbability17Expectation/ur_pb_17_4.pg" seed="20">
      <statement><p>If <m>E[X]=-3</m> and <m>\mbox{Var}(X) = 1</m>, then</p><p><m>E[(1 + 4 X)^2] =</m><fillin name="AnSwEr0001" characters="40"/></p><p>and</p><p><m>\mbox{Var}(4 + 5 X) =</m><fillin name="AnSwEr0002" characters="40"/>.</p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=20&amp;sourceFilePath=Library/Rochester/setProbability17Expectation/ur_pb_17_4.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=20&amp;sourceFilePath=Library/Rochester/setProbability17Expectation/ur_pb_17_4.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=20&amp;sourceFilePath=Library/Rochester/setProbability17Expectation/ur_pb_17_4.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=20&amp;sourceFilePath=Library/Rochester/setProbability17Expectation/ur_pb_17_4.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
	<example><title>Discrete Expected Value</title><p>Consider <m>f(x) = x/10</m> over R = {1,2,3,4} where the payout is 10 euros if x=1, 5 euros if x=2, 2 euros if x=3 and -7 euros if x = 4.  Then your value function would be 
	<me>v(1)=10, v(2) = 5, v(3)=2, v(4) = -7.</me> 
	Computing the expect payout gives
	<me>E = 10 \times 1/10 + 5 \times 2/10 + 2 \times 3/10 - 7 \times 4/10 = -2/10</me>
	Therefore, the expected payout is actually negative due to a relatively large negative payout associated with the largest likelihood outcome and the larger positive payout only associated with the least likely outcome.
	</p></example>
	</p>
        <p>
	<example xml:id="ContinuousEV-example"><title>Continuous Expected Value</title><p>
	Consider <m>f(x) = x^2/3</m> over R = [-1,2] with value function given by <m>v(x) = e^x - 1</m>. Then, the expected value for v(x) is given by
	<me>E = \int_{-1}^2 (e^x-1) \cdot x^2/3 = -1/9 \cdot (e + 15) \cdot e^{-1} + 2/3 \cdot e^2 - 8/9 \approx 3.3129</me>
	</p></example>
	</p>
        <p>
	<definition xml:id="TheoreticalMeasures"><title>Theoretical Measures</title><statement><p>
	Given a random variable with probability function f(x) over space R
	<ol><li>The mean of X = <m>\mu = E[x]</m></li><li>The variance of X = <m>\sigma^2 = E[(x-\mu)^2]</m></li><li>The skewness of X = <m>\gamma_1 = \frac{E[(x-\mu)^3]}{\sigma^3}</m></li><li>The kurtosis of X = <m>\gamma_2 = \frac{E[(x-\mu)^4]}{\sigma^4}</m></li></ol>
	</p></statement></definition>
	</p>
        <p>
	<theorem xml:id="TheoreticalMeasuresAlternates"><title>Alternate Formulas for Theoretical Measures</title><statement><p>
	<ol><li><m>\sigma^2 = E[x^2] - \mu^2 = E[X(x-1)] + \mu - \mu^2</m></li><li><m>\gamma_1 = \frac{1}{\sigma^3} \cdot \left [ E[X^3] - 3 \mu E[X^2] + 2\mu^3 \right ]</m></li><li><m>\gamma_2 = \frac{1}{\sigma^4} \cdot \left [ E[X^4] - 4 \mu E[X^3] + 6\mu^2 E[X^2] - 3 \mu^4 \right ]</m></li></ol>
	</p></statement><proof><p>
		In each case, expand the binomial inside and use the linearity of expected value.
		</p></proof></theorem>
	</p>
        <p>
	Consider the following example when computing these statistics for a discrete variable. In this case, we will utilize a variable with a relatively small space so that the summations can be easily done by hand. Indeed, consider
	
	<table halign="left"><caption>Discrete Probability Function Example</caption><tabular halign="right"><row><cell bottom="medium" right="medium">X</cell><cell bottom="medium">f(x)</cell></row><row><cell right="medium">0</cell><cell>0.10</cell></row><row><cell right="medium">1</cell><cell>0.25</cell></row><row><cell right="medium">2</cell><cell>0.40</cell></row><row><cell right="medium">4</cell><cell>0.15</cell></row><row><cell right="medium">7</cell><cell>0.10</cell></row></tabular></table>
	
	<image source="images/DiscreteHistogramExample.png"/>
	</p>
        <p>
	Using the definition of mean as a sum,
	<md><mrow>\mu &amp; = 0 \cdot 0.10 + 1 \cdot 0.25 + 2 \cdot 0.40 + 4 \cdot 0.15 + 7 \cdot 0.10</mrow><mrow> &amp; = 0 + 0.25 + 0.80 + 0.60 + 0.70</mrow><mrow> &amp; = 2.35</mrow></md>
	Notice where this lies on the probability histogram for this distribution.
	</p>
        <p>For the variance
	<md><mrow>\sigma^2 &amp; = E[X^2] - \mu^2</mrow><mrow> &amp; = \left [ 0^2 \cdot 0.10 + 1^2 \cdot 0.25 + 2^2 \cdot 0.40 + 4^2 \cdot 0.15 + 7^2 \cdot 0.10 \right ] - 2.35^2</mrow><mrow> &amp; = 0 + 0.25 + 1.60 + 2.40 + 4.90 - 5.5225</mrow><mrow> &amp; = 9.15 - 5.225</mrow><mrow> &amp; = 3.6275 </mrow></md>	
	and so the standard deviation <m>\sigma = \sqrt{3.6275} \approx 1.90</m>. Notice that 4 times this value encompasses almost all of the range of the distribution.
	</p>
        <p>For the skewness
	<md><mrow> \text{Numerator = } &amp; E[X^3] - 3 \mu E[X^2] + 2\mu^3</mrow><mrow> &amp; = \left [ 0^3 \cdot 0.10 + 1^3 \cdot 0.25 + 2^3 \cdot 0.40 + 4^3 \cdot 0.15 + 7^3 \cdot 0.10 \right ] - 3 \cdot 2.35 \cdot 9.15 + 2 \cdot 2.35^3</mrow><mrow> &amp; \approx 0 + 0.25 + 3.20 + 9.60 + 34.3 - 64.5075 + 25.96</mrow><mrow> &amp; = 47.35 - 64.5075 + 25.96</mrow><mrow> &amp; \approx 8.80</mrow></md>
	which yields a skewness of <m>\gamma_1 = 8.80 / \sigma^3 \approx 1.27 </m>. This indicates a slight skewness to the right of the mean. You can notice the 4 and 7 entries on the histogram illustrate a slight trailing off to the right.
	</p>
        <p>Finally, for kurtosis
	<md><mrow> \text{Numerator = } &amp; E[X^4] - 4 \mu E[X^3] + 6 \mu^2 E[X^2] - 3\mu^4</mrow><mrow> &amp; = \left [ 0^4 \cdot 0.10 + 1^4 \cdot 0.25 + 2^4 \cdot 0.40 + 4^4 \cdot 0.15 + 7^4 \cdot 0.10 \right ] - 4 \cdot 2.35 \cdot 47.35 + 6 \cdot 2.35^2 \cdot 9.15^2 - 3 \cdot 2.35^4</mrow><mrow> &amp; \approx 0 + 0.25 + 6.40 + 38.4 + 240.1 - 445.09 + 303.19 - 91.49</mrow><mrow> &amp; \approx 285.15 - 445.09 + 303.19 - 91.49</mrow><mrow> &amp; \approx 51.75</mrow></md>
	which yields a kurtosis of <m>\gamma_2 = 51.75 / \sigma^4 \approx 3.93</m> which also notes that the data appears to have a modestly bell-shaped distribution.
	</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		.
		</p></introduction><webwork-reps xml:id="extracted-webwork-21" ww-id="webwork-21">
    <pg source="Library/Mizzou/Finite_Math/Probability_Random_Variables/EV1.pg"/>

      
    <static source="Library/Mizzou/Finite_Math/Probability_Random_Variables/EV1.pg" seed="21">
      <statement><p>Find the expected value for the random variable:</p><sidebyside><tabular top="medium" bottom="medium" left="medium" right="medium"><row><cell>  <m>X</m>   </cell><cell>    1   </cell><cell>    3   </cell><cell>    5  </cell><cell>    6  </cell></row><row><cell><m>P(X)</m></cell><cell>  0.22  </cell><cell>  0.16  </cell><cell> 0.15  </cell><cell>  0.47  </cell></row></tabular></sidebyside><p><m>E(X) =</m> <fillin name="AnSwEr0001" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=21&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Random_Variables/EV1.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=21&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Random_Variables/EV1.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=21&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Random_Variables/EV1.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=21&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Random_Variables/EV1.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		.
		</p></introduction><webwork-reps xml:id="extracted-webwork-22" ww-id="webwork-22">
    <pg source="Library/Rochester/setProbability7RandomVariables/ur_pb_7_6.pg"/>

      
    <static source="Library/Rochester/setProbability7RandomVariables/ur_pb_7_6.pg" seed="22">
      <statement><p>Prizes and the chances of winning in a sweepstakes are given in the table below.</p><sidebyside><tabular top="medium" bottom="medium" left="medium" right="medium"><row><cell>Prize</cell><cell>Chances</cell></row><row><cell><dollar/>15,000,000 </cell><cell>1 chance in 300,000,000 </cell></row><row><cell><dollar/>550,000 </cell><cell>1 chance in 100,000,000 </cell></row><row><cell><dollar/>50,000 </cell><cell>1 chance in 80,000,000 </cell></row><row><cell><dollar/>10,000 </cell><cell>1 chance in 3,000,000 </cell></row><row><cell><dollar/>600 </cell><cell>1 chance in 200,000 </cell></row><row><cell>A watch valued at <dollar/>70 </cell><cell>1 chance in 8,000 </cell></row></tabular></sidebyside><p>(a) <m/> Find the expected value (in dollars) of the amount won by one entry.</p><p><fillin name="AnSwEr0001" characters="20"/></p><p>(b) <m/> Find the expected value (in dollars) if the cost of entering this sweepstakes is the cost of a postage stamp (34 cents)</p><p><fillin name="AnSwEr0002" characters="20"/></p></statement>
      
      <solution>
      
      
       SOLUTION 
      
      
      (a)  Let <m>W</m> be the amount of money (in dollars) won by an entry.  Then 
      <me>\begin{aligned}
      E[W]  = \amp 15000000\cdot P(W = 15000000) + 550000 \cdot P(W = 550000) +  50000 \cdot P(W = 50000)\\
      \amp  + \, 10000 \cdot P(W = 10000) +600 \cdot P( W = 600) + 70 \cdot P( W = 70)\\
       \amp  = \frac{15000000}{300000000} + \frac{550000}{100000000} + \frac{50000}{80000000} + \frac{10000}{3000000} + \frac{600}{200000} + \frac{70}{8000} \\
      \amp = 0.0712083333333333
      \end{aligned}</me>
      So the expected value of the amount won by one entry in the sweepstakes is about 7 cents.
      
      
      
      (b) Let <m>X</m> be the net earnings from one entry into the sweepstakes.  Then <m>X = W - 0.34</m>, so 
      <me>E[X] = E[W- 0.34] = E[W] - 0.34 = -0.268791666666667.</me>
      Hence, taking into account the cost of postage, there is an expected loss of about 27 cents from one entry into the sweepstakes. 
      
      
      </solution>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=22&amp;sourceFilePath=Library/Rochester/setProbability7RandomVariables/ur_pb_7_6.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=22&amp;sourceFilePath=Library/Rochester/setProbability7RandomVariables/ur_pb_7_6.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=22&amp;sourceFilePath=Library/Rochester/setProbability7RandomVariables/ur_pb_7_6.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=22&amp;sourceFilePath=Library/Rochester/setProbability7RandomVariables/ur_pb_7_6.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		.
		</p></introduction><webwork-reps xml:id="extracted-webwork-23" ww-id="webwork-23">
    <pg source="Library/UBC/STAT/STAT241_251/setAssignment-01/HW01-01.pg"/>

      
    <static source="Library/UBC/STAT/STAT241_251/setAssignment-01/HW01-01.pg" seed="23">
      <statement><p>The table below summarizes the number of surface flaws
      found on the paintwork of new cars following their inspection after primer
      paint was applied by a new method:</p><sidebyside><tabular top="medium" bottom="medium" left="medium" right="medium"><row><cell>No. of flaws</cell><cell>No. of cars</cell></row><row><cell>0</cell><cell>5</cell></row><row><cell>1</cell><cell>9</cell></row><row><cell>2</cell><cell>14</cell></row><row><cell>3</cell><cell>12</cell></row><row><cell>4</cell><cell>6</cell></row><row><cell>5</cell><cell>3</cell></row><row><cell>6</cell><cell>1</cell></row></tabular></sidebyside><p><em> Part a) </em>
      Find the mean number of flaws per car. Please give your answer to two decimal places.</p><p>The mean number of flaws per car is: <fillin name="AnSwEr0001" characters="6"/></p><p><em> Part b) </em></p><p>Find the variance of the number of flaws per car. Please give your answer to two decimal places.</p><p>The variance of the number of flaws per car is: <fillin name="AnSwEr0002" characters="6"/></p></statement>
      
      <solution><p>Here <m>n = 50</m> and the sample mean is 
      <me>\bar{x} = 
      \frac{5\times 0 +
            9\times 1 +
            14\times 2 +
            12\times 3 +
            6\times 4 +
            3\times 5 +
            1\times 6}
      {50} \\
       = 2.36.</me></p><p>The sample variance is</p><p><me>\frac{5\left( 0 - 2.36 \right) ^{2} +
            9\left( 1 - 2.36 \right) ^{2} +
            14\left( 2 - 2.36 \right) ^{2} +
            12\left( 3 - 2.36 \right) ^{2} +
            6\left( 4 - 2.36 \right) ^{2} + 
            3\left( 5 - 2.36 \right) ^{2} +
            1\left( 6 - 2.36 \right) ^{2}}
      {49}</me>
      which is 2.072.</p></solution>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=23&amp;sourceFilePath=Library/UBC/STAT/STAT241_251/setAssignment-01/HW01-01.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=23&amp;sourceFilePath=Library/UBC/STAT/STAT241_251/setAssignment-01/HW01-01.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=23&amp;sourceFilePath=Library/UBC/STAT/STAT241_251/setAssignment-01/HW01-01.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=23&amp;sourceFilePath=Library/UBC/STAT/STAT241_251/setAssignment-01/HW01-01.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
	Consider the following example when computing these statistics for a continuous variable. 
	Let <m>f(x) = \frac{3}{4} \cdot (1-x^2)</m> over R = [-1,1].  
		<image source="images/ContinuousDistributionExample.png"/>
	</p>
        <p>
	Then for the mean
	<md><mrow>\mu &amp; = \int_{-1}^1 x \cdot \frac{3}{4} \cdot (1-x^2) dx</mrow><mrow> &amp; = \int_{-1}^1 \frac{3}{4} \cdot (x-x^3) dx</mrow><mrow> &amp; = \frac{3}{4} \cdot (x^2/2-x^4/4) \big |_{-1}^1</mrow><mrow> &amp; = \frac{3}{4} \cdot [(1/2)-(1/4)] - [(1/2) - (1/4)]</mrow><mrow> &amp; = 0</mrow></md>
	as expected since the probability function is symmetric about x=0.
	</p>
        <p>For the variance
	<md><mrow>\sigma^2 &amp; = \int_{-1}^1 x^2 \cdot \frac{3}{4} \cdot (1-x^2) dx - \mu^2</mrow><mrow> &amp; = \int_{-1}^1 \cdot \frac{3}{4} \cdot (x^2-x^4) dx - 0</mrow><mrow> &amp; = \frac{3}{4} \cdot (x^3 /3 -x^5 / 5) \big |_{-1}^1</mrow><mrow> &amp; = \frac{3}{4} \cdot 2 \cdot (1/3-1/5)</mrow><mrow> &amp; = \frac{3}{4} \cdot \frac{4}{15}</mrow><mrow> &amp; = \frac{1}{5}</mrow></md>
	and taking the square root gives a standard deviation slightly less than 1/2. Notice that four times this value encompasses almost all of the range of the distribution.
	</p>
        <p>For the skewness, notice that the graph is symmetrical about the mean and so we would expect a skewness of 0.  Just to check it out
	<md><mrow> \text{Numerator = } &amp; E[X^3] - 3 \mu E[X^2] + 2\mu^3</mrow><mrow> &amp; = \int_{-1}^1 x^3 \cdot \frac{3}{4} \cdot (1-x^2) dx - 3 E[X^2] \cdot 0 + 0^3 </mrow><mrow> &amp; = \int_{-1}^1 \cdot \frac{3}{4} \cdot (x^3-x^5) dx</mrow><mrow> &amp; = \frac{3}{4} \cdot (x^4/4-x^6/6) \big |_{-1}^1</mrow><mrow> &amp; = 0</mrow></md>
	as expected without having to actually complete the calculation by dividing by the cube of the standard deviation.
	</p>
        <p>Finally, note that the probability function in this case is modestly close to a bell shaped curve so we would expect a kurtosis in the vicinity of 3. Indeed, noting that (conveniently) <m>\mu = 0</m> gives
	<md><mrow> \text{Numerator = } &amp; E[X^4] - 4 \mu E[X^3] + 6 \mu^2 E[X^2] - 3 \mu^4</mrow><mrow> &amp; = \int_{-1}^1 x^4 \cdot \frac{3}{4} \cdot (1-x^2) dx</mrow><mrow> &amp; = \frac{3}{4} \cdot (x^5 /5-x^7 /7) \big |_{-1}^1</mrow><mrow> &amp; = \frac{3}{4} \cdot 2(1/5-1/7)</mrow><mrow> &amp; = \frac{3}{35}</mrow></md>
	and so by dividing by <m>\sigma^4 = \sqrt{\frac{1}{5}}^4 = \frac{1}{25}</m> gives a kurtosis of
	<me>\gamma_2 = \frac{3}{35} / \frac{1}{25} = \frac{75}{35} \approx 2.14.</me>
	</p>
        <p>
<example><p>
Consider <xref ref="ContinuousEV-example">our previous example</xref>. To compute the mean and standard deviation for this distribution,
<me>\mu = \int_{-1}^2 x \cdot x^2/3 dx = \int_{-1}^2 x^3/3 dx = \frac{2^4}{12} - \frac{(-1)^4}{12} = \frac{15}{12} = \frac{5}{4}</me>
and by using <xref ref="TheoreticalMeasuresAlternates">the alternate forumulas</xref>
<md><mrow>\sigma^2 &amp; = E[X^2] - \mu^2</mrow><mrow> &amp; = \int_{-1}^2 x^2 \cdot x^2/3 dx - \mu^2</mrow><mrow> &amp; = \int_{-1}^2 x^4/3 dx - \left ( \frac{5}{4} \right</mrow><mrow> &amp; = \frac{2^5}{15} - \frac{(-1)^5}{15} - \frac{25}{16}</mrow><mrow> &amp; = \frac{33}{15} - \frac{25}{16} = \frac{51}{80}</mrow></md>
which gives 
<me>\sigma = \sqrt{\frac{51}{80}} \approx 0.7984.</me>
</p><p>
For skewness, note that in computing the variance above you also found that
<me>E[X^2] = \frac{11}{5}.</me>
So, once again by using <xref ref="TheoreticalMeasuresAlternates">the alternate forumulas</xref>
<me>E[X^3] = \int_{-1}^2 x^3 \cdot x^2/3 dx = \frac{x^6}{18} |_{-1}^2 = \frac{7}{2}</me>
and so
<me>\gamma_1 = \frac{\frac{7}{2} - 3 \cdot \frac{5}{4} \cdot \frac{11}{5} + 2 \cdot (\frac{5}{4})^3}{\sqrt{\frac{51}{80}}^3}</me>
</p><p>
For kurtosis, you can reuse <m>E[X^3] = \frac{7}{2}</m> and <m>E[X^2] = \frac{11}{5}</m> and 
<xref ref="TheoreticalMeasuresAlternates">the alternate forumulas</xref> to determine
<me>E[(X-\mu)^4] = E[X^4] - 4 \mu \cdot E[X^3] + 6 \mu^2 \cdot E[X^2] - 3 \mu^4</me>
which is the numerator for the kurtosis.  
</p></example>
</p>
        <p>
<example><title>Roulette</title><p>
Roulette is a gambling game popular in may casinos in which a player attempts to win money from the casino by predicting the location that a ball lands on in a spinning wheel.  There are two variations of this game...the American version and the European version. The difference being that the American version has one additional numbered slot on the wheel. The American version of the game will be used for the purposes of this example.
</p><p>
A Roulette wheel consists of 38 equally-sized sectors identified with the numbers 1 through 36 plus 0 and 00. The 0 and 00 sectors are colored green and half of the remaining numbers are in sectors colored red with the remainder colored black.  A steel ball is dropped onto a spinning wheel and as the wheel comes to rest the sector in which it comes to rest is noted.  It is easy to determine that the probability of landing on any one of the 38 sectors is 1/38. A picture of a typical American-style wheel and betting board is given by
<image source="images/6-1-American-Roulette-1024x463.png"/>. (Found at BigFishGames.com.)
</p><p>
Since this is a game in a casino, there must be the opportunity to bet (and likely lose) money. For the remainder of this example we will assume that you are betting 1 dollar each time. If you were to bet more then the values would scale correspondingly. However, if you place your bet on any single number and the ball ends up on the sector corresponding to that number, you win a net of 35 dollars.  If the ball lands elsewhere you lose your dollar. Therefore the expected value of winning if you bet on one number is
<me>E[\text{win on one}] = 35 \cdot \frac{1}{38} - 1 \cdot \frac{37}{38} = - \frac{2}{38}</me>
which is a little more than a nickel loss on average.
</p><p>
You can bet on two numbers as well and if the ball lands on either of the two then you win a payout in this case of 17 dollars.  Therefore the expected value of winning if you bet on two numbers is
<me>E[\text{win on two numbers}] = 17 \cdot \frac{2}{38} - 1 \cdot \frac{36}{38} = - \frac{2}{38}.</me>
</p><p>
Continuing, you can bet on three numbers and if the ball lands on any of the three then you win a payout of 11 dollars.  Therefore the expected value of winning if you bet on three numbers is
<me>E[\text{win on three numbers}] = 11 \cdot \frac{3}{38} - 1 \cdot \frac{35}{38} = - \frac{2}{38}.</me>
</p><p>
You can bet on all reds, all blacks, all evens (ignoring 0 and 00), or all odds and get your dollar back. The expected value for any of these options is
<me>E[\text{win on eighteen numbers}] = 1 \cdot \frac{18}{38} - 1 \cdot \frac{20}{38} = - \frac{2}{38}.</me>
</p><p>There is one special way to bet which uses the the 5 numbers {0, 00, 1, 2, 3} and pays 6 dollars. This is called the "top line of basket".  Notice that the use of five numbers will make getting the same expected value as the other cases impossible using regular dollars and cents. The expected value of winning in this case us
<me>E[\text{win on top line of basket}] = 6 \cdot \frac{5}{38} - 1 \cdot \frac{33}{38} = - \frac{3}{38}</me>
which is of course worse and is the only normal way to bet on roulette which has a different expected value. 
</p><p>
There are other possible ways to bet on roulette but none provide a better expected value of winning.  The moral of this story is that you should never bet on the 5 number option and if you ever get ahead by winning on roulette using any of the possible options then you should probably stop quickly since over a long period of time it is expected that you will lose an average of <m>\frac{1}{19}</m> dollars per game.
</p></example>
</p>
        <p>
Going back to Pascal's wager, let 
<ul><li>X = 0 represent disbelief when God doesn't exist</li><li>X = 1 represent disbelief when God does exist</li><li>X = 2 represent belief when God does exist</li><li>X = 3 represent belief when God does not exist</li></ul>
Presume that p is the likelihood that God exists. Then you can compute the expected value of disbelief and the expect value of belief by first creating a value function. Below, for argument sake we are somewhat randomly assign a value of one million to disbelief if God doesn't exist. The conclusions are the same if you choose any other finite number...
	<md><mrow>v(0) = 1,000,000, f(0) = 1-p</mrow><mrow>v(1) = -\infty, f(1) = p</mrow><mrow>v(2) = \infty, f(2) = p</mrow><mrow>v(3) = 0, f(3) = 1-p</mrow></md>
	Then, 
	<md><mrow>E[\text{disbelief}] &amp; = v(0)f(0) + v(1)f(1)</mrow><mrow>&amp; = 1000000 \times (1-p) - \infty \times p</mrow><mrow>&amp; = -\infty</mrow></md>
	if p&gt;0. On the other hand, 
	<md><mrow>E[\text{belief}] &amp; = v(2)f(2) + v(3)f(3)</mrow><mrow>&amp; = \infty \times p + 0 \times (1-p)</mrow><mrow>&amp; = \infty</mrow></md>
	if p&gt;0. So Pascal's conclusion is that if there is even the slightest chance that God exists then belief is the smart and scientific choice.
	</p>
      </section>
      <section>
        <title>Standard Units</title>
        <p>Any distribution variable can be converted to “standard units” using the linear translation 
	<me>\displaystyle z = \frac{x-\mu}{\sigma}.</me> 
	In doing so, values of z will always represent the number of
	standard deviations x is from the mean and will provide “dimensionless” comparisons.
	</p>
        <p>
	<example><p>
	Consider our earlier 
	<xref ref="ContinuousEV-example">continuous example</xref> 
	in which we found 
	<m>\mu = \frac{5}{4}</m> and 
	<m>\sigma = \sqrt{\frac{51}{80}}</m>.  Then, 
	<me>P(0 &lt; X &lt; 1) = P \left ( \frac{0-\frac{5}{4}}{\sqrt{\frac{51}{80}}} &lt; \frac{X - \frac{5}{4}}{\sqrt{\frac{51}{80}}} &lt; \frac{1-\frac{5}{4}}{\sqrt{\frac{51}{80}}} \right )</me>
	gives the middle term is Z and the other endpoints are now in standard units that indicate the number of standard deviations from the mean rather than actual problem units.
	</p></example>
	</p>
      </section>
      <section>
        <title>Summary</title>
        <p>
TBA
</p>
      </section>
      <section>
        <title>Exercises</title>
        <introduction>
Here are some exercises to consider related to Probability Functions.
</introduction>
        <exercise>
          <title>Flipping A Fixed Number of Coins</title>
          <p>
	Consider the random variable from the previous section where you flip three coins and measure the number of heads obtained. Determine f(0), f(1), f(2), and f(3) and the corresponding distribution function F(x). These can be expressed in a table format. Generalize your answer to the case when you flip a n coins where n is a fixed natural number.
	</p>
        </exercise>
        <exercise>
          <title>Later</title>
          <p>
	B.  
	</p>
        </exercise>
        <exercise>
          <title>Flipping Fixed Number of Coins</title>
          <p>
	You flip three coins and measure the number of heads obtained. Determine the space R for the corresponding random variable X. From the eight possible outcomes, determine all outcomes corresponding to X=2. Identify the random variable as discrete or continuous.
	</p>
        </exercise>
        <exercise>
          <title>Flipping Coins till success</title>
          <p>
	You flip one coin repeatedly until you get a second head. Determine the space R for the corresponding random variable X. From the possibilities, determine all outcomes corresponding to X=4. Identify the random variable as discrete or continuous.
	</p>
        </exercise>
        <exercise>
          <title>Time between Accidents</title>
          <p>
	Now you want to measure the time between accidents at a particular intersection in town. Determine the space R for the corresponding random variable X. Describe all outcomes corresponding to <m>X \lt 1</m>. Be purposeful in the problem to describe the units you are using to measure time. Identify the random variable as discrete or continuous.
	</p>
        </exercise>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="UniformHypergeometric">
      <title>Distributions based upon Equally likely Outcomes</title>
      <section>
        <title>Introduction</title>
        <p>
When motivating our definition of probability you may have noticed that we modeled our definition on the relative frequency of equally-likely outcomes. In this chapter you will develop the theoretical formulas which can be used to model equally-likely outcomes.
</p>
        <p>
In this chapter, you will investigate the following distributions:
<ol><li>Discrete Uniform - each of a finite collection of outcomes is equally likely and prescribed a "position" and X measures the position of an item selected randomly from the outcomes.</li><li>Continuous Uniform - an interval of values is possible with sub-intervals of equal length having equal probabilities and X measures a location inside that interval.</li><li>Hypergeometric - each of a finite collection of values are equally likely and grouped into two classes (successes vs failures) and a subset of that collection is extracted with X measuring the number of successes in the sample.</li></ol>
</p>
      </section>
      <section>
        <title>Discrete Uniform Distribution</title>
        <p>
In this section, you will investigate distributions that begin with individual outcomes that are equally likely and expand into more general settings.
</p>
        <p>
<theorem><title>Discrete Uniform Distribution</title><statement><p xml:id="DiscreteUniformFunction">
Assume outcomes in R = {1, 2, 3, ..., n} are equally likely.  Then, the probability function for the discrete uniform variable X is
<me>f(x) = \frac{1}{n}</me>
for <m>x \in R</m>.
</p></statement><proof><p>
	Assume that you have a variable with space R = {1, 2, 3, ..., n} so that the likelihood of each value is equally likely. Then, the probability function satisfies <m>f(x) = c</m> for any <m>x \in R</m>.  As before, since <m>\sum_{x \in R} f(x) = 1</m>, then 
	<me>f(x) = \frac{1}{n}.</me> 
	</p></proof></theorem>
</p>
        <p>	
<sage><input>
# Uniform distribution over 1 .. n
pretty_print("Discrete Uniform Distribution over the set 1, 2, ..., n")
var('x')
@interact
def _(n=slider(2,10,1,2)):
    np1 = n+1
    R = range(1,np1)
    f(x) = 1/n
    pretty_print(html('Density Function: $f(x) =%s$'%str(latex(f(x)))+' over the space $R = %s$'%str(R)))
    points((k,f(x=k)) for k in R).show()
    for k in R:
        pretty_print(html('$f(%s'%k+') = %s'%f(x=k)+' \\approx %s$'%f(x=k).n(digits=5)))

</input></sage>
</p>
        <p>
<theorem><title>Properties of the Discrete Uniform Probability Function</title><statement><p xml:id="DiscreteUniformProperties">
	<m>f(x) = \frac{1}{n}</m> over R = {1, 2, 3, ..., n} satisfies the properties of a discrete probability function and
	<ol><li><m>\mu = \frac{1+n}{2}</m></li><li><m>\sigma^2 = \frac{n^2-1}{12}</m></li><li><m>\gamma_1 = 0</m></li><li><m>\gamma_2 = \frac{6}{5}\frac{1+n^2}{1-n^2}</m></li><li>Distribution function F(x) = frac{x}{n} for <m>x \in R</m>.</li></ol>
	</p></statement><proof><p>
	Trivially, by construction you get by summing over <m>R = \{1, 2, ... , n \}</m>
	<me>\sum_{x=1}^n \frac{1}{n} = 1</me>
	Also, 1/n is positive for all x values.
	</p><p>To determine the mean,
		<md><mrow>\mu &amp; = \sum_{x=1}^n x \cdot \frac{1}{n}</mrow><mrow> &amp; = \frac{1}{n}\sum_{x=1}^n x </mrow><mrow> &amp; = \frac{1}{n} \frac{n(n+1)}{2}</mrow><mrow> &amp; = \frac{1+n}{2}</mrow></md>
	</p><p>To determine the variance,
		<md><mrow>\sigma^2 &amp; = \sum_{x=1}^n x^2 \cdot \frac{1}{n} - \mu^2</mrow><mrow> &amp; = \frac{1}{n}\sum_{x=1}^n x^2 - \left ( \frac{1+n}{2}\right )^2 </mrow><mrow> &amp; = \frac{1}{n} \frac{n(n+1)(2n+1)}{6} - \frac{1+2n+n^2}{4}</mrow><mrow> &amp; = \frac{(2n^2+3n+1)}{6} - \frac{1+2n+n^2}{4}</mrow><mrow> &amp; = \frac{(4n^2+6n+2)}{12} - \frac{3+6n+3n^2}{12}</mrow><mrow> &amp; = \frac{(n^2-1)}{12}</mrow></md>
	</p><p>For skewness,
		<md><mrow>\gamma_1 = &amp; \sum_{x=1}^n x^3 \cdot \frac{1}{n} - 3 \mu \sum_{x=1}^n x^2 \cdot \frac{1}{n}  + 2\mu^3</mrow><mrow> &amp; = \frac{n^2(n+1)^2}{4n} - 3\frac{(n(n+1)(2n+1))}{2n} \frac{1+n}{2} + 2 \left ( \frac{1+n}{2}\right )^3 </mrow><mrow> &amp; = \frac{n^2(n+1)^2}{4n} - \frac{(n+1)^2 (n(2n+1)}{4n} + \frac{(n+1)^3}{4}</mrow><mrow> &amp; = \frac{(n+1)^2}{4} \left [ n - 2n -1 + (n+1) \right ]</mrow><mrow> &amp; = 0</mrow></md>
	which should be obvious since the histogram for this distribution is constantly flat.
	</p><p>For Kurtosis, 
	use the fourth moment and simplify.  This this is tedious, the algebra is performed using Sage in the active cell below this proof. However, you might want to supply the remainder of this proof using the fact that
	<me>\sum_{x=1}^n x^4 = \frac{6n^5 + 15n^4 + 10n^3 - n}{30}.</me>
	</p></proof></theorem>
</p>
        <p>
Sage can also do the algebra for you to determine each of these measures. Notice, as n increases the Kurtosis approaches <m>\frac{6}{5}</m> which indicates that there is (obviously) no tend toward central tendency over time.
</p>
        <p>
<sage><input>
var('x,n')
f = 1/n
mu = sum(x*f,x,1,n).factor()
pretty_print('Mean = ',mu)
mu = (1+n)/2
v = sum((x-mu)^2*f, x, 1, n)
pretty_print('Variance = ',v.factor())
stand = sqrt(v)
pretty_print('Skewness =  ',(sum((x-mu)^3*f, x, 1, n)/stand^3))
kurt = sum((x-mu)^4*f, x, 1, n)/stand^4
pretty_print('Kurtosis = ',(kurt-3).factor(),' + 3')
</input></sage>
</p>
        <p>
<example><title>Rolling one die</title><p>When you consider rolling a regular, fair, single 6-sided die, each side is equally likely. The sample space consists of the 6 sides, each with a unique number of physical dots. Let the random variable X correspond each side with the number corresponding to the number of dots. Then, R = {1, 2, 3, 4, 5, 6}.  Since each side is equally likely then f(x) = 1/6.
</p><p>
Further, the probability of getting an outcome in A={2,3} would be f(2)+f(3) = 1/6 + 1/6 = 2/6.
</p></example>
</p>
      </section>
      <section>
        <title>Continuous Uniform Distribution</title>
        <p>
Modeling the idea of "equally-likely" in a continuous world requires a slightly different perspective since there are obviously infinitely many outcomes to consider. Instead, you should consider requiring that intervals in the domain which are of equal width should have the same probability regardless of where they are in that domain. This behaviour suggests <m>P(u \lt X \lt v) = P(u + \Delta \lt X \lt v + \Delta)</m> for reasonable values of <m>\Delta</m> so that the interval remains inside R.
</p>
        <p>
<theorem><title>Continuous Uniform Probability Function</title><statement><p xml:id="ContinuousUniformFunction">For R = [a,b], with a &lt; b, the continuous uniform probability function is given by
	<me>f(x) = \frac{1}{b-a}.</me>
</p></statement><proof><p>From before, for X a continuous uniform variable, we get
	<md><mrow>\int_u^v f(x) dx = \int_{u+\Delta}^{v+\Delta} f(x) dx</mrow><mrow>F(v)-F(u) = F(v+\Delta)-F(u+\Delta)</mrow><mrow>F(u+\Delta)-F(u) = F(v+\Delta)-F(v)</mrow><mrow>frac{F(u+\Delta)-F(u)}{\Delta} = \frac{F(v+\Delta)-F(v)}{\Delta}</mrow></md>
	which is true regardless of \Delta so long as you stay in the domain of interest. Letting <m>\Delta \rightarrow 0</m> gives
	<me>F'(u) = F'(v)</me>
but since F is an antiderivative of the probability function,
	<me>f(u) = f(v)</me>
for all u and v in R. This only happens if f is constant...say, f(x)=c. If the space of X is a single interval with <m>R = [a,b]</m> then
	<me>1 = \int_a^b c dx = c(b-a)</me>
	which yields <m>c = \frac{1}{b-a}</m> as desired. 
	</p></proof></theorem>
</p>
        <p>
<example><title>Basic Continuous Uniform</title><p>
On <m>R = [1,2 \pi]</m>,
<me>f(x) = \frac{1}{2 \pi - 1}.</me>
Then, if you want to compute something like <m>P(2 &lt; X &lt; 4.5)</m> integrate
<me>P(2 &lt; X &lt; 4.5) = \int_2^{4.5} \frac{1}{2 \pi -1} dx = \frac{2.5}{2 \pi - 1}</me>
</p></example>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		This one uses the continuous uniform distribution.
		</p></introduction><webwork-reps xml:id="extracted-webwork-24" ww-id="webwork-24">
    <pg source="Library/Rochester/setProbability16JointDist/ur_pb_16_3.pg"/>

      
    <static source="Library/Rochester/setProbability16JointDist/ur_pb_16_3.pg" seed="24">
      <statement><p>A man and a woman agree to meet at a cafe about noon. If the man arrives at a time uniformly distributed between <m>11:35</m>
      and <m>12:15</m> and if the woman independently arrives at a time uniformly distributed between <m>11:55</m> and <m>12:45</m>, what
      is the probability that the first to arrive waits no longer than <m>15</m> minutes?</p><p><fillin name="AnSwEr0001" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=24&amp;sourceFilePath=Library/Rochester/setProbability16JointDist/ur_pb_16_3.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=24&amp;sourceFilePath=Library/Rochester/setProbability16JointDist/ur_pb_16_3.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=24&amp;sourceFilePath=Library/Rochester/setProbability16JointDist/ur_pb_16_3.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=24&amp;sourceFilePath=Library/Rochester/setProbability16JointDist/ur_pb_16_3.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<example><title>Continuous Uniform over two disjoint intervals</title><p>
Suppose <m>R = [0,2] \cup [5,7]</m>.  Then, as in the theorem proof
<me>1 = \int_R c dx = \int_0^2 c dx + \int_5^7 c dx = 4c.</me>
Thus, <m> f(x) = \frac{1}{4}</m>.
For computing probabilities, you will want to break up any resulting integrals in a similar manner.
</p></example>
</p>
        <p>
<theorem><title>Properties of the Continuous Uniform Probability Function</title><statement><p xml:id="ContinuousUniformProperties">For the Continuous Uniform Distribution over <m>R = [a,b]</m>, with a &lt; b,
	<ol><li><m>f(x) = \frac{1}{b-a}</m> satisfies the properties of a probability function over R = [a,b].</li><li><m>\mu = \frac{a+b}{2}</m></li><li><m>\sigma^2 = \frac{b^2-a^2}{12}</m></li><li><m>\gamma_1 = 0</m></li><li><m>\gamma_2 = \frac{9 \, {\left(a^{5} - 5 \, a^{4} b + 10 \, a^{3} b^{2} - 10 \, a^{2} b^{3} + 5 \, a b^{4} - b^{5}\right)} {\left(a - b\right)}}{5 \, {\left(a^{3} - 3 \, a^{2} b + 3 \, a b^{2} - b^{3}\right)}^{2}}</m>
		</li></ol>
	</p></statement></theorem>
</p>
        <p>
<sage><input>
# Continous uniform distribution statistics derivation
reset()
var('x,a,b')
f = 1/(b-a)
mu = integrate(x*f,x,a,b).factor()
pretty_print('Mean = ',mu)

v = integrate((x-mu)^2*f, x, a, b)
pretty_print('Variance = ',v.factor())
stand = sqrt(v)

sk = (integrate((x-mu)^3*f, x, a, b)/stand^3)
pretty_print('Skewness =  ',sk)

kurt = (integrate((x-mu)^4*f, x, a, b)/stand^4)
pretty_print('Kurtosis = ',kurt)

pretty_print('Several Examples')
a1=0
for b1 in range(2,7):
    pretty_print('Using [',a1,',',b1,']:')
    pretty_print('    mean = ',mu(a=a1,b=b1))
    pretty_print('variance = ',v(a=a1,b=b1))
    pretty_print('skewness = ',sk(a=a1,b=b1))
    pretty_print('kurtosis = ',kurt(a=a1,b=b1))
</input></sage>
</p>
        <p>
<example><title>Occurence of exactly one event randomly in a given interval</title><p>
Suppose you know that only one person showed up at the counter of a local business in a given 30 minute interval of time. Then, R=[0,30] given f(x) = 1/30.
</p><p>
Further, the probability that the person arrived within the first 6 minutes would be <m>\int_0^6 \frac{1}{30} dx = 0.2</m>.
</p></example>
</p>
        <p>
<theorem><title>Distribution Function for Continuous Uniform</title><statement><p>
For <m>x \in [a,b], F(x) = \frac{x-a}{b-a}</m>
</p></statement><proof><p>
For x in this range, 
<me>F(x) = \int_a^x \frac{1}{b-a} du = \frac{u}{b-a} \big |_a^x = \frac{x-a}{b-a}.</me>
</p></proof></theorem>
</p>
      </section>
      <section>
        <title>Hypergeometric Distribution</title>
        <p>
For the discrete uniform distribution, the presumption is that you will be making a selection one time from the collection of items. However, if you want to take a larger sample without replacement from a distribution in which originally all are equally likely then you will end up with something which will not be uniform.
</p>
        <p>
Indeed, consider a collection of n items from which you want to take a sample of size r without replacement. If <m>n_1</m> of the items are "desired" and the remaining <m>n_2 = n - n_1</m> are not, let the random variable X measure the number of items from the first group in your sample with <m>R = \{0, 1, ..., min {r,n_1} \}</m>. The resulting collection of probabilities is called a Hypergeometric Distribution.
</p>
        <p>
<image source="images/HypergeometricBucket.png" width="60%"/>
</p>
        <p>
<theorem><title>Hypergeometric Probability Function</title><statement><p xml:id="HypergeometricFunction">For a Hypergeometric random variable with R = {0, 1, ..., r} and assuming <m>n_1 \ge r</m> and <m>n-n_1 \ge r</m>,
	<me>f(x) = \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}}</me>	
</p></statement><proof><p>
For the following, we will presume thatSince you are sampling without replacement and trying only measure the number of items from your desired group in the sample, then the space of X will include R = {0, 1, ..., r} assuming <m>n_1 \ge r</m> and <m>n-n_1 \ge r</m>. In the case when r is too large for either of these, the formulas below will follow noting that binomial coefficients are zero if the top is smaller than the bottom or if the bottom is negative.
</p><p>
So f(x) = P(X = x) = P(x from the sample are from the target group and the remainder are not). Breaking these up gives
	<me>f(x) = \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}}</me>
</p></proof></theorem>
</p>
        <p>
For example, suppose that you have a bag of assorted candies but you really prefer the little dark chocolate bars. Because you are obsessive, you first empty the whole bag onto your desk and discover that the bag contains 33 equally-sized candy bars of which 6 of them are your delightful dark chocolate bars. Putting the bars randomly back into the bag, you find that a friend's friend's friend walks into the room and grabs a handful of 5 candy bars from your bag. You are shocked and would like to know the probability that this person got 2 or more of your dark chocolate candy bars. 
</p>
        <p>
As a good prob/stats student you recognize that this situation fits the requirements of the hypergeometric distribution with <m>n_1 = 6, n_2 = 27, r=5</m> and you want <m>P(X \ge 2)</m>.  You determine that it would be easier to compute the complement 
<me>1 - P(X \le 1) = 1 - f(0) - f(1).</me>  
Therefore, 
<me> P (X \ge 2) = 1 - \frac{\binom{6}{0} \binom{27}{5}}{\binom{33}{5}} - \frac{\binom{6}{1} \binom{27}{4}}{\binom{33}{5}}</me>
or after some simplification
<me>P (X \ge 2) = 1 - \frac{13455}{39556} - \frac{8775}{19778} \approx 0.21617</me>
Therefore, you have about 1 chance out of 5 that the friend got 2 or more of your bars. You can be somewhat confident that plenty of dark chocolate bars remain hoarded for yourself.
</p>
        <p>	
	<theorem><title>Properties of the Hypergeometric Distribution</title><statement><p xml:id="HypergeometricProperties">
	<ol><li><m>f(x) = \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}}</m> satisfies the properties of a probability function.</li><li><m>\mu = r \frac{n_1}{n}</m></li><li><m>\sigma^2 = r \frac{n_1}{n} \frac{n_2}{n} \frac{n-r}{n-1}</m></li><li><m>\gamma_1 = \frac{(n - 2 n_1)\sqrt{n-1}(n - 2r)}{r n_1 (n - n_1) \sqrt{n-r}(n-2)}</m></li><li><m>\gamma_2 = \frac{n(n+1)-6n(n-r)}{n_1(n-n_1)} + \frac{3r(n-r)(n+6)}{n^2} - 6</m></li></ol>
	</p></statement><proof><p>
	<ol><li>
			<p>		
			<md><mrow>\sum_{x=0}^n \binom{n}{x} y^x &amp; = (1+y)^n, \text{ by the Binomial Theorem}</mrow><mrow>&amp; = (1+y)^{n_1} \cdot (1+y)^{n_2} </mrow><mrow>&amp; = \sum_{x=0}^{n_1} \binom{n_1}{x} y^x \cdot \sum_{x=0}^{n_2} \binom{n_2}{x} y^x </mrow><mrow>&amp; = \sum_{x=0}^n \sum_{t=0}^r \binom{n_1}{r} \binom{n_2}{r-t} y^x</mrow></md>		
			Equating like coefficients for the various powers of y gives
			<me>\binom{n}{r} = \sum_{t=0}^r \binom{n_1}{r} \binom{n_2}{r-t}.</me>
			Dividing gives
			<me>1 = \sum_{x=0}^r f(x).</me>
			</p>
		</li><li>
		<p>For the mean
			<md><mrow>\sum_{x=0}^n x \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}} &amp; = 
\frac{1}{\binom{n}{r}} \sum_{x=1}^n  \frac{n_1(n_1-1)!}{(x-1)!(n_1-x)!}  \binom{n-n_1}{r-x}				
				</mrow><mrow> &amp; = \frac{n_1}{\binom{n}{r}} \sum_{x=1}^n  \frac{(n_1-1)!}{(x-1)!((n_1-1)-(x-1))!}  \binom{n-n_1}{r-x} </mrow><mrow> &amp; = \frac{n_1}{\frac{n(n-1)!}{r!(n-r)!}} \sum_{x=1}^n  \binom{n_1-1}{x-1}  \binom{n-n_1}{r-x} </mrow></md>
			Consider the following change of variables for the summation: 
			<md><mrow>y = x-1</mrow><mrow>n_3 = n_1-1</mrow><mrow>s = r-1</mrow><mrow>m = n-1</mrow></md>
			Then, this becomes
			<md><mrow> \mu = \sum_{x=0}^n x \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}} &amp; = r \frac{n_1}{n} \sum_{y=0}^m  \frac{\binom{n_3}{y} \binom{m-n_3}{s-y}}{\binom{m}{s}}
				</mrow><mrow>&amp; = r \frac{n_1}{n} \cdot 1</mrow></md>
			noting that the summation is in the same form as was show yields 1 above.

		</p>
		</li><li>
		<p>
For variance, we will use an alternate form of the definition that is useful when looking for cancellation options with the numerous factorials in the hypergeometric probability function. Indeed, you can easily notice that
<me>\sigma^2 = E[X^2] - \mu^2 = E[X^2-X]+E[X] -\mu^2 = E[X(X-1)] + \mu - \mu^2.</me>
Since we have <m>\mu = r \frac{n_1}{n}</m> from above then let's focus on the first term only and use the substitutions
			<md><mrow>y = x-2</mrow><mrow>n_3 = n_1-2</mrow><mrow>s = r-2</mrow><mrow>m = n-2</mrow></md>
to get
<md><mrow>E[X(X-1)] &amp; = \sum_{x=0}^n x(x-1) \frac{\binom{n_1}{x} \binom{n-n_1}{r-x}}{\binom{n}{r}}</mrow><mrow> &amp; = \sum_{x=2}^n x(x-1) \frac{\frac{n_1!}{x(x-1)(x-2)!(n_1-x)! } \binom{n-n_1}{r-x}}{\binom{n}{r}}</mrow><mrow> &amp; = \sum_{x=2}^n \frac{\frac{n_1!}{(x-2)!(n_1-x)! } \frac{n_2!}{(r-x)!(n_2-r+x)!}}{\binom{n}{r}}</mrow><mrow> &amp; = n_1 \cdot (n_1-1) \sum_{x=2}^n \frac{\frac{(n_3)!}{(x-2)!(n_3 -(x-2))! } \frac{n_2!}{((r-2)-(x-2))!(n_2-(r-2)+(x-2))!}}{\binom{n}{r}}</mrow><mrow> &amp; = n_1 \cdot (n_1-1) \sum_{y=0}^{m} \frac{\frac{(n_3)!}{y!(n_3 -y)! } \frac{n_2!}{(s-y)!(n_2-s+y)!}}{\binom{n}{r}}</mrow><mrow> &amp; = \frac{n_1 \cdot (n_1-1) \cdot r \cdot (r-1)}{n (n-1)} \sum_{y=0}^{m} \frac{\binom{(n_3)}{y} \binom{n_2}{s-y}}{\binom{m}{s}}</mrow><mrow> &amp; = \frac{n_1 \cdot (n_1-1) \cdot r \cdot (r-1)}{n (n-1)} </mrow></md>
where we have used the summation formula above that showed that f(x) was a probability function.  
</p>
<p>
Putting this together with the earlier formula gives
<me>\sigma^2 = \frac{n_1 \cdot (n_1-1) \cdot r \cdot (r-1)}{n (n-1)} + r \frac{n_1}{n} - \left ( r \frac{n_1}{n} \right )^2.</me> 
		</p>
		</li><li>
		<p>The proof of kurtosis is even more messy and we won’t bother with proving it for this distribution!
		</p>
		</li></ol>
	</p></proof></theorem>
</p>
        <p>
	Note, if r=1 then you are back at a regular discrete uniform model. Indeed, <me>P(\text{desired item}) = 1 \cdot \frac{n_1}{n} = \mu .</me>
	which is indeed what you might expect when selecting once.
	</p>
        <p>
<sage language="r"><input>
N1 = 10
N2 = 16
n = N1+N2
r = 5

X = 0:r        # the space R of the random variable 
mu = r*N1/n      # the formula for mean of the Binomial Distributions
sdev = sqrt(mu*(N2/n)*(n-r)/(n-1))  # the formula for the standard deviation
dhyper( X, N1, N2, r )   # let's print out a bunch of actual probs

Phyper = dhyper(X, N1, N2, r )  # create the probability function over X

Psample = rhyper(10^6, N1, N2, r)  # to create a histogram, sample a lot
Xtop=max(Psample)          # for scaling the x-axis. Shift by 1/2 below.
hist(Psample, prob=TRUE, br=(-1:Xtop)+0.5, col="skyblue2", xlab="X", 
  main="Hypergeometric Probability Function vs Approximating 'Bell Curve'")

points(X, Phyper, pch=19, col="darkgreen")  # to create actual (x,f(x))

Pnormal &lt;- function(X){dnorm(X, mean=mu, sd=sdev)}   # to overlap a bell curve
curve(Pnormal, col="red", lwd=2, add=TRUE) 
</input></sage>
</p>
        <!--
<p>
<exercise><title>WebWork</title>
		<introduction>
		<p>
		This one uses the hypergeometric distribution.
		</p>
		</introduction>
<webwork source="Library/Misc/hypergeometric.pg"></webwork>
</exercise>
</p>
-->
        <p>Consider the Hypergeometric distribution for various values of <m>n_1, n_2,</m> and r using the interactive cell above. Notice what happens when you start with relatively small values of <m>n_1, n_2,</m> and r (say, start with <m>n_1 = 5, n_2 = 8,</m> and r = 4 and then doubling then all again and again. Consider the likely skewness and kurtosis of the graph as the values get larger.
</p>
        <p>
In the interactive cell below, notice how many items are in each portion of the "Venn Bucket" when you change the size of the number extracted--denoted by what is inside the circle.
</p>
        <sage>
          <input>
# Hypergeometric distribution over 0 .. N
# Size of classes N1 and N2 must be given as well as subset size r
var('x')
@interact(layout=dict(top=[['N1','N2','r']]))
def _(N1=input_box(10,width=5,label='\( N_1 \)'),
    N2=input_box(10,width=5,label='\( N_2 \)'),
    r=input_box(5,width=5,label='\( r \)')):
    N = N1 + N2
    f = binomial(N1,x)*binomial(N2,r-x)/binomial(N,r)
    @interact
    def __(X = slider(0,min(r,N1),1)):
        Px = f(x=X)
        Pxapprox = Px.n(digits=8)
        formula = "\\frac{\\binom{%s}"%str(N1)+"{%s}"%str(X)+" \\binom{%s}"%str(N2)+"{%s}}"%str(r-X)+"{ \\binom{%s}"%str(N)+"{%s}}"%str(r)
        pretty_print(html("P(X = %s"%str(X)+") = \( %s \)"%str(formula)+" = \( %s \)"%str(latex(Px))+"\( \\approx %s \)"%str(Pxapprox)))
        G = polygon([(0,0), (1,0), (1.2,1), (-.2,1)],color='lightblue')
        G += line([(0.5,0),(0.5,1)],thickness=2)
        G += circle((0.5,0.3),0.25,fill=True,facecolor='yellow',alpha=0.5,zorder=2)
        G += text("Things I want",(0.2,0.9))+text("Everything else",(0.8,0.9))
        G += text("%s"%X,(0.4,0.3),fontsize=30) + text("%s"%(r-X),(0.6,0.3),fontsize=30)
        G += text("%s"%(N1-X),(0.1,0.5),fontsize=30) + text("%s"%(N2-(r-X)),(0.9,0.5),fontsize=30)
        show(G, axes=0, figsize=(4,4) )
	</input>
        </sage>
      </section>
      <section>
        <title>Summary</title>
        <p>
<introduction><p>
Here is a summary of the major formulas from this chapter:
</p></introduction>
</p>
        <p>
<xref ref="DiscreteUniformFunction">Discrete Uniform f(x)</xref>
</p>
        <p>
<xref ref="DiscreteUniformProperties">Discrete Uniform statistics</xref>
</p>
        <p>
<xref ref="ContinuousUniformFunction">Continuous Uniform f(x)</xref>
</p>
        <p>
<xref ref="ContinuousUniformProperties">Continuous Uniform statistics</xref>
</p>
        <p>
<xref ref="HypergeometricFunction">Hypergeometric f(x)</xref>
</p>
        <p>
<xref ref="HypergeometricProperties">Hypergeometric statistics</xref>
</p>
      </section>
      <section>
        <title>Exercises</title>
        <p>
<exercise><title> - The Proverbial Urn Problem</title><statement><p>
You have an urn with 10 marbles of which <m>n_1 = 6</m> are red and <m>N_2 = 4</m> are blue. You select randomly r = 3 of the marbles without replacement and let X represent the number of red marbles in your sample. With R = {0, 1, 2, 3}, determine:
<ul><li>f(x)</li><li>P(2 of the 3 are red) = f(2)</li><li>P(at most 2 of the 3 are red) = f(0) + f(1) + f(2)</li></ul> 
</p></statement><hint><p>
This is hypergeometric using  
<me>f(x) = \frac{\binom{6}{x} \binom{4}{3-x}}{\binom{10}{3}}.</me>
</p></hint></exercise>
</p>
        <p>
<exercise><title> - Playing Cards</title><statement><p>
You randomly select a hand of five cards without replacement from an ordinary deck of playing cards.  
<ul><li>Determine the probability that four of the five are spades.</li><li>Determine the probability that three of the five are face cards (ie, Jacks, Queens, Kings, or Aces).</li></ul>
</p></statement><hint><p>
This exercise is actually two different hypergeometric distributions: the first is the 13 spades vs the 39 other cards and the second is the 12 face cards vs the 40 other cards.
</p></hint></exercise>
</p>
        <p>
<exercise><title> - Starting Seniors</title><statement><p>
You are picking an eleven member football starting team by picking randomly from a group with 15 seniors and 35 others. Determine:
<ul><li>P(all seniors)</li><li>P(exactly 6 seniors)</li><li>the expected number of seniors on the team</li><li>If your team has all seniors, explain whether someone could suggest that your decision on members was unfair</li></ul>
</p></statement><hint><p>
This is a hypergeometric distribution with <m>n_1 = 15, n_2 = 35, r = 11</m>.
</p></hint></exercise>
</p>
        <p>
<exercise><title> - Old Faithful</title><statement><p>
Ole Faithful geyser in Yellowstone National Park erupts every 91 minutes. You show up at some random time in the eruption cycle and your tour bus plans to stay for 25 minutes. Determine the likelihood that you will be able to see it erupt.  Express your answer by giving correct formulas for f(x) and F(x) and then determine the specific answer to this question.
</p></statement><hint><p>
This is the continuous uniform distribution over R = [0, 91].
</p></hint></exercise>
</p>
        <p>
<exercise><title> - Uniform Scenarios</title><statement><p>
Explain how the following situations can be modeled using a continuous uniform distribution by identifying the space R and the corresponding f(x) for each situation.
<ul><li>The location on a prize wheel where the spun wheel will stop.</li><li>Given a clock with only a minute hand, the current one second interval.</li><li>The location on a automobile tire where the next puncture will occur.</li></ul>
</p></statement></exercise>
</p>
        <p>
<exercise><title> - Continous Uniform on a different space</title><statement><p>
Determine an explicit formula for f(x) and the mean and variance for a continuous uniform distribution over <m>R = [-2,3] \cup [5,6] \cup [9,15]</m>.
</p></statement><solution><p>
Since you must have 
<me>\int_{x \in R} f(x) dx = 1</me>
and since f(x) must be constant than all you must do is measure the accumulated width of the intervals in R. This is 5 + 1 + 6 = 12 and so
<me>
f(x)=\left\{\begin{matrix}
 \frac{1}{12}, &amp; -2 \le x \le 3
\\ \frac{1}{12}, &amp; 5 \le x \le 6
\\ \frac{1}{12}, &amp; 9 \le x \le 15
\\ 0, &amp; \text{otherwise}
\end{matrix}\right.
</me>
For the mean, 
	<md><mrow>\int_{x \in R} x \frac{1}{12} dx &amp; = \int_{-2}^3 \frac{x}{12} dx + \int_5^6 \frac{x}{12} dx + \int_9^{15} \frac{x}{12} dx</mrow><mrow> &amp; = \frac{9-4}{24} + \frac{36-25}{24} + \frac{225-81}{24}</mrow><mrow> &amp; = \frac{5+11+144}{24} = \frac{160}{24} = \frac{20}{3}.</mrow></md>
For the variance,
	<md><mrow>\int_{x \in R} x^2 \frac{1}{12} dx - \mu^2 &amp; = \int_{-2}^3 \frac{x^2}{12} dx + \int_5^6 \frac{x^2}{12} dx + \int_9^{15} \frac{x^2}{12} dx - \mu^2</mrow><mrow> &amp; = \frac{81+8}{36} + \frac{216-125}{36} + \frac{3375-729}{36} - \big ( \frac{20}{3} \big )^2</mrow><mrow> &amp; = \frac{89+91+2646}{36} - \frac{400}{9} = \frac{2826-1600}{36} </mrow><mrow> &amp; = \frac{1226}{36} \approx	34.055.</mrow></md>
</p></solution></exercise>
</p>
        <p>
<exercise><title> - Louisiana Mega Millions Lottery</title><statement><p>
To play the Mega Millions Louisiana Lottery consists of picking five numbers from 1 to 75 and one yellow Mega Ball number from 1 through 15. (You can play up to five different sets of numbers on each playslip but we will just assume one play per ticket to keep things straight.) Each play costs $1 and you can pay an additional $1 to apply a "multiplier" which multiplies any non-Jackpot prize by the Multiplier number (2, 3, 4, or 5) randomly selected at the time of the drawing.</p><p> On October 10, 2016 the jackpots listed were
<ul><li>Match 5 plus Mega ball = Jackpot of $49,000,000 with cash value of $32,600,000</li><li>Match only 5 = $1,000,000</li><li>Match 4 plus Mega ball = $5,000</li><li>Match only 4 =$500</li><li>Match 3 plus Mega ball = $50</li><li>Match only 3 = $5</li><li>Match 2 plus Mega ball = $5</li><li>Match 1 plus Mega ball = $2</li><li>Match only the Mega ball = $1</li></ul>
</p><p>
Verify the posted odds
<ul><li>Match 5 plus Mega ball = 1 in 258,890,850</li><li>Match only 5 = 1 in 18,492,204</li><li>Match 4 plus Mega ball = 1 in 739,688</li><li>Match only 4 = 1 in 52,835</li><li>Match 3 plus Mega ball = 1 in 10,720</li><li>Match only 3 = 1 in 766</li><li>Match 2 plus Mega ball = 1 in 473</li><li>Match 1 plus Mega ball = 1 in 56</li><li>Match only the Mega ball = 1 in 21</li></ul>
</p><p>
Determine the expected payout for each ticket purchased. Also, determine what the Jackpot would need to be in order for the game to be considered "fair" with an expected value of zero.
</p></statement><solution><p>
Throughout these calculations, you can presume that the first five numbers are selected independently from the Mega Ball number. However, the first five numbers are selected without replacement so computing probabilities with those does not allow for independence. This part is hypergeometric with the <m>n_1 = 5</m> numbers you selected being the "desired" numbers and the Lottery Commission picking a subset of size r = 5 from the 75 possible numbers.  So, your likelihood of matching all five would be
<me>\frac{\binom{5}{5} \cdot \binom{70}{0}}{\binom{75}{5}} = \frac{1}{17259390}.</me>
Multiplying this by the 1 chance in 15 that you also match the Mega Ball gives
<me>P(\text{Match 5 plus Mega Ball}) = \frac{1}{17259390} \cdot \frac{1}{15} = \frac{1}{258,890,850}.</me>
To match only 5 means you also MUST miss the Mega Ball which has probability 14/15 to give
<me>\frac{1}{17259390} \cdot \frac{14}{15} = \frac{1}{17259390 \cdot \frac{15}{14}} \approx \frac{1}{18492204}.</me>
Continue in this manner to determine the other odds.
</p><p>
For the expected earnings, first determine a value function corresponding to each outcome and apply the discrete expected value process. This gives
<md><mrow> &amp; \$32600000 \cdot \frac{1}{258,890,850} + \$1000000 \cdot \frac{1}{18,492,204} </mrow><mrow> &amp; + \$5000 \cdot \frac{1}{739,688} + \$500 \cdot \frac{1}{52,835}</mrow><mrow> &amp; + \$50 \cdot \frac{1}{10,720} + \$5 \cdot \frac{1}{766} </mrow><mrow> &amp; + \$5 \cdot \frac{1}{473} + \$2 \cdot \frac{1}{56} + \$1 \cdot \frac{1}{21}</mrow><mrow> &amp; \approx \$0.3013.</mrow></md>
So, the expected payout is approximately 30 cents. Subtracting the cost of playing ($1) indicates that the average winnings per play of the Louisiana Lottery would be -70 cents. So, you would be better off to take, say, 50 cents and just give it to the local school system every time you consider playing this game rather than actually playing.
</p><p>
To determine the Jackpot A needed to make this a fair game means to solve the equation
<md><mrow> &amp; A \cdot \frac{1}{258,890,850} + \$1000000 \cdot \frac{1}{18,492,204} </mrow><mrow> &amp; + \$5000 \cdot \frac{1}{739,688} + \$500 \cdot \frac{1}{52,835}</mrow><mrow> &amp; + \$50 \cdot \frac{1}{10,720} + \$5 \cdot \frac{1}{766} </mrow><mrow> &amp; + \$5 \cdot \frac{1}{473} + \$2 \cdot \frac{1}{56} + \$1 \cdot \frac{1}{21}</mrow><mrow> &amp; = 1</mrow></md>
for A.
</p><p>
Finally, to deal with the multiplier, note that all but the Jackpot payouts would be increased by the multiplier m where <m>m \in \{1,2,3,4,5\}</m>.  For the cost of an extra $1 (total cost of $2 per bet) the expected payout increases as the multiplier increases but each of these decreases likelihood of winning that payout by a factor of 1/5.  In general, let x = 1, 2, ..., 9 indicate the various winning options in order listed above, f(x) the corresponding probabilities listed for each option, and  u(x) the listed payouts. Then the expected payout is given by
<me> \$32600000 \cdot \frac{1}{258,890,850} + \sum_{m=1}^5
\sum_{x=2}^9 m \cdot u(x) f(x)/5 </me>
or
	<md><mrow> \$32600000 \cdot \frac{1}{258,890,850} &amp; + \sum_{m=1}^5 \frac{m}{5} \sum_{x=2}^9 u(x) f(x) </mrow><mrow> &amp; = \frac{\$32600000}{258890850} + \sum_{m=1}^5 \frac{m}{5} 0.17539</mrow><mrow> &amp; = 0.12592 + 3 \cdot 0.17539</mrow><mrow> &amp; = 0.65209</mrow></md>
Therefore, the expect value of spending another dollar to get the multiplier effect is about -$1.35.  Since this is slightly less than doubling the expected loss of 70 cents for playing without the multiplier with $1, it make more sense to bet $2 once rather than betting $1 twice.  Or, you can send the extra nickel to this author of this text and call it quits.
</p></solution></exercise>
</p>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="BinomialGeometricNegBinomial">
      <title>Distributions based upon Bernoulli Trials</title>
      <section>
        <title>Introduction</title>
        <p>
	Many practical problems involve measuring simply whether something was a success or a failure. In these situations, "success" should not be interpreted as having any moral or subjective meaning but only construed to mean that something you are looking for actually occurs.
	</p>
        <p>
	In situation where a single trial is performed and the result is determined only to be a success or failure is called a Bernoulli event. Indeed, one could create a corresponding probability function using a random variable X over the space <m>R = \{0, 1 \}</m> mapping X(success) = 1 and X(failure)=0. If p = P(success) then 
	<me>f(x) = p^x \cdot (1-p)^{1-x}</me>
	would be a formula but which only related to two values P(failure) = f(0) = (1-p) and P(Success) = f(1) = p.  
	</p>
        <p>
	Notice that p=0 means that you will always get a failure and that p=1 means that you will always get a success. In these cases, X would no longer be a random variable since the outcome for X could be predicted with certainty. Therefore, we will always assume that <m>0 &lt; p &lt; 1</m>.
	</p>
        <p>
	The Bernoulli distribution on its own is not extremely useful but serves as a starting point for several others that are useful.  Indeed, in this chapter you will investigate distributions that relate some number of successes in multiple trials to some number of independent trials. The difference between these distributions will be that one of these variables will be fixed and the other one will be variable.
</p>
        <p>
In this chapter, you will investigate the following distributions:
<ol><li>Binomial - the number of trials is fixed and X measures the variable number of successes</li><li>Geometric - the number of successes is fixed--at 1--and X measures the variable number of trials</li><li>Negative Binomial - the number of successes is fixed and X measures the variable number of trials</li></ol>
</p>
      </section>
      <section>
        <title>Binomial Distribution</title>
        <p>Consider a sequence  of n independent Bernoulli trials with the likelihood of a success p on each individual trial stays constant from trial to trial with <m> 0 \lt p \lt 1 </m>. If we let the variable <m>X</m> measure the number of successes obtained when doing a fixed number of trials n with <m>R = \{ 0, 1, ..., n \}</m>, then the resulting distribution of probabilities is called a Binomial Distribution.</p>
        <p>
Now, let's determine the actual probability function for this distribution.
</p>
        <p>
<theorem xml:id="BinomialProbabilityFunctionTheorem"><title>Derivation of Binomial Probability Function</title><statement><p xml:id="BinomialProbabilityFunction">
	For R = {0, 1, ..., n},
	<me>f(x) = \binom{n}{x}p^x(1-p)^{n-x}</me>
	</p></statement><proof><p> Since successive trials are independent, then the probability of X successes occurring within n trials is given by 
		<me>P(X=x) = \binom{n}{x}P(SS...SFF...F) = 		
						\binom{n}{x}p^x(1-p)^{n-x}</me>
		</p></proof></theorem>
</p>
        <p>
<theorem><title>Verification of Binomial Distribution Formula</title><statement><p>
	<me>\sum_{x \in R} f(x) = \sum_{x=0}^n \binom{n}{x}p^x(1-p)^{n-x} = 1.</me>
	</p></statement><proof><p>
		Using the Binomial Theorem with a = p and b = 1-p yields
		<me>\sum_{x=0}^n \binom{n}{x}p^x(1-p)^{n-x} = (p + (1-p))^n = 1</me>
	</p></proof></theorem>
</p>
        <p>
The following interactive cell illustrates the range of choices for a Binomial setup with fixed N and fixed p:
</p>
        <p>
<sage><input>
# Binomial distribution over 0 .. N
# N and p need to be given
var('x')
@interact(layout=dict(top=[['N','p']]))
def _(N=input_box(10,width=5,label='\( N \)'),
    p=input_box(3/10,width=5,label='\( p \)')):
    f = binomial(N,x)*p^x*(1-p)^(N-x)
    @interact
    def __(X = slider(0,N,1)):
        Px = f(x=X)
        Pxapprox = Px.n(digits=8)
        formula = "\\binom{%s}"%str(N)+"{%s}"%str(X)+"({%s})"%str(p)+"^{%s}"%str(X)+"(1-{%s})"%str(p)+"^{%s}"%str(N-X)
        pretty_print(html("P(X = %s"%str(X)+") = \( %s \)"%str(formula)+" = \( %s \)"%str(latex(Px))+"\( \\approx %s \)"%str(Pxapprox)))
        G = polygon([(0,0), (1,0), (1,1), (0,1)],thickness=10,color='blue',alpha=0.7,zorder=1)

        if X &gt; 0:
            R =[j for j in range(N)] 
            selected = sample(R, X)
            for k in selected:
                xk = sqrt(k)*cos(k)/N^(4/5)+0.5
                yk = sqrt(k)*sin(k)/N^(4/5)+0.5
                G += circle((xk,yk),0.05,fill=True,facecolor='red',zorder=3) 
                G += text('p',(xk,yk))

        for k in range(N):
            xk = sqrt(k)*cos(k)/N^(4/5)+0.5
            yk = sqrt(k)*sin(k)/N^(4/5)+0.5
            G += circle((xk,yk),0.05,zorder=2,fill=True, facecolor="white")
   
        show(G, axes=0, figsize=(4,4) )
</input></sage>
</p>
        <example>
          <title>Flipping a coin a fixed number of times</title>
          <p>Let's consider a simple example for flipping coins. Indeed, suppose you flip a coin exactly 20 times and need to determine the probability of getting exactly 10 heads.
</p>
          <p>
This is binomial with n = 20, p = 1/2 and you are looking for f(10). With these values
<me>f(10) = \binom{20}{10} \cdot \left ( \frac{1}{2} \right )^{10} \cdot \left ( \frac{1}{2} \right 	)^{20-10} = \frac{46189}{262144} \approx 0.176</me>

Note that the mean for this distribution is also 10 so one might expect 10 heads in general
</p>
          <p>
If you rather would prefer to determine the probability of getting 10 or fewer heads requires F(10) = f(0) + f(1) + ... + f(10). There is no "nice" formula for F but this calculation can be performed using a graphing calculator, such as the TI-84 with F(x) = binomcdf(n,p,x). In this case, F(10) = binomcdf(20,1/2,10) = 0.588.
</p>
        </example>
        <p>
<exercise><title>WebWork</title><introduction><p>
		This one uses the binomial distribution.
		</p></introduction><webwork-reps xml:id="extracted-webwork-25" ww-id="webwork-25">
    <pg source="Library/Mizzou/Finite_Math/Probability_Introduction/Coin.pg"/>

      
    <static source="Library/Mizzou/Finite_Math/Probability_Introduction/Coin.pg" seed="25">
      <statement><p>A coin is tossed 14 times.</p><p>a) How many different outcomes are possible?  <fillin name="AnSwEr0001" characters="20"/></p><p>b) What is the probability of getting exactly 6 heads? <fillin name="AnSwEr0002" characters="20"/></p><p>c) What is the probability of getting at least 2 heads? <fillin name="AnSwEr0003" characters="20"/></p><p>d) What is the probability of getting at most 10 heads? <fillin name="AnSwEr0004" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=25&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Introduction/Coin.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=25&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Introduction/Coin.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=25&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Introduction/Coin.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=25&amp;sourceFilePath=Library/Mizzou/Finite_Math/Probability_Introduction/Coin.pg</server-url>

  </webwork-reps></exercise>
</p>
        <example>
          <title>Testing critical components</title>
          <p>
Often one will test a critical system components for failure and toward that end collect a sample of 100 of these components from the manufacturer. Suppose the component is listed as having a p=0.01 probability of breaking and you want to know the likelihood that at most 1 of the tested components actually fails when tested. You find it reasonable to presume that different components succeed or fail independently of each other. So, you can model this situation with a binomial distribution. 
</p>
          <p>
If X measures the number of components that fail when tested, the specific probability function is given by
<me>f(x) = \binom{100}{x} 0.01^x 0.99^{100-x}.</me>
The probability that at most one component fails is then given by
<me>F(1) = f(0) + f(1) = \binom{100}{0} 0.01^0 0.99^{100} + \binom{100}{1} 0.01^1 0.99^99 \\ = 0.99^{100} + 100 \cdot 0.01 \cdot 0.99^{99} = 0.99^{99}(0.99 + 100 \cdot 0.01 \\ = 0.99^{99} \cdot 1.99 \approx 0.73576.</me>
</p>
        </example>
        <p>
Utilize the interactive cell below to compute f(x) and F(x) for the Binomial distribution
</p>
        <p>
<sage><input>
# Binomial calculator
@interact
def _(p=input_box(3/10,width=15),n=input_box(10,width=15)):
    R = range(n+1)
    f(x) = binomial(n,x)*p^x*(1-p)^(n-x)
    acc = 0
    pretty_print("Binomial Calculator")
    for k in R:
        prob = f(x=k)
        acc = acc+prob
        pretty_print('f(%s) = '%k,' %.8f'%prob,' and F(%s) = '%k,' %.8f'%acc)
	</input></sage>
</p>
        <p>
<theorem xml:id="BinomialStatisticsTheorem"><title>Binomial Distribution Statistics</title><statement><p xml:id="BinomialStatistics">For the Binomial Distribution
	<me>\mu = np</me>
	<me>\sigma^2 = np(1-p)</me>
	<me>\gamma_1 = \frac{1-2p}{\sqrt{np(1-p)}}</me>
	<me>\gamma_2 = \frac{1-6p(1-p)}{np(1-p)} + 3</me>
	</p></statement><proof><p>
		For the mean,
		<md><mrow> \mu &amp; = E[X] </mrow><mrow> &amp; = \sum_{x=0}^{n} {x \binom{n}{x} p^x (1-p)^{n-x}}</mrow><mrow> &amp; = \sum_{x=1}^{n} {x \frac{n(n-1)!}{x(x-1)!(n-x)!} p^x (1-p)^{n-x}}</mrow><mrow> &amp; = np \sum_{x=1}^{n} {\frac{(n-1)!}{(x-1)!((n-1)-(x-1))!} p^{x-1} (1-p)^{(n-1)-(x-1)}}</mrow></md>

		Using the change of variables <m>k=x-1</m> and <m>m = n-1</m> yields a binomial series
		<md><mrow> &amp; = np \sum_{k=0}^{m} {\frac{m!}{k!(m-k)!} p^k (1-p)^{m-k}}</mrow><mrow> &amp; = np (p + (1-p))^m = np</mrow></md>
	</p><p>For the variance,
		<md><mrow> \sigma^2 &amp; = E[X(X-1)] + \mu - \mu^2 </mrow><mrow> &amp; = \sum_{x=0}^{n} {x(x-1) \binom{n}{x} p^x (1-p)^{n-x}} + np - n^2p^2</mrow><mrow> &amp; = \sum_{x=2}^{n} {x(x-1) \frac{n(n-1)(n-2)!}{x(x-1)(x-2)!(n-x)!} p^x (1-p)^{n-x}}  + np - n^2p^2</mrow><mrow> &amp; = n(n-1)p^2 \sum_{x=2}^{n} {\frac{(n-2)!}{(x-2)!((n-2)-(x-2))!} p^{x-2} (1-p)^{(n-2)-(x-2)}} + np - n^2p^2</mrow></md>
	</p><p>Using the change of variables <m>k=x-2</m> and <m>m = n-2</m> yields a binomial series
	<md><mrow> &amp; = n(n-1)p^2  \sum_{k=0}^{m} {\frac{m!}{k!(m-k)!} p^k (1-p)^{m-k}} + np - n^2p^2</mrow><mrow> &amp; = n(n-1)p^2 + np - n^2p^2 = np - np^2 = np(1-p)</mrow></md>
	</p><p>The skewness and kurtosis can be found similarly using formulas involving E[X(X-1)(X-2)] and E[X(X-1)(X-2)(X-3)]. The complete determination is performed using Sage below.
	</p></proof></theorem>
</p>
        <p>The following uses Sage to symbolically confirm the general formulas for the Binomial distribution.
</p>
        <p>
<sage><input>
var('x,n,p')
assume(x,'integer')
f(x) = binomial(n,x)*p^x*(1-p)^(n-x)
mu = sum(x*f,x,0,n)
M2 = sum(x^2*f,x,0,n)
M3 = sum(x^3*f,x,0,n)
M4 = sum(x^4*f,x,0,n)

pretty_print('Mean = ',mu)

v = (M2-mu^2).factor()
pretty_print('Variance = ',v)
stand = sqrt(v)

sk = ((M3 - 3*M2*mu + 2*mu^3)).factor()/stand^3
pretty_print('Skewness = ',sk)

kurt = (M4 - 4*M3*mu + 6*M2*mu^2 -3*mu^4).factor()/stand^4
pretty_print('Kurtosis = ',(kurt-3).factor(),'+3')
</input></sage>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		This one uses the binomial distribution.
		</p></introduction><webwork-reps xml:id="extracted-webwork-26" ww-id="webwork-26">
    <pg source="Library/Rochester/setProbability8BinomialDist/ur_pb_8_6.pg"/>

      
    <static source="Library/Rochester/setProbability8BinomialDist/ur_pb_8_6.pg" seed="26">
      <statement><p>The Census Bureau reports that 82<percent/> of Americans over the age of 25 are high school graduates.
      A survey of randomly selected residents of certain county included 1370 who were over the age of 25, 
      and 1074 of them were high school graduates.</p><p>(a) <m/> Find the mean and standard deviation for the number of high school graduates in groups of 1370 Americans over the age of 25.</p><p>Mean = <fillin name="AnSwEr0001" characters="15"/></p><p>Standard deviation = <fillin name="AnSwEr0002" characters="15"/></p><p>(b) <m/> Is that county result of 1074 unusually high, or low, or neither?</p><p>(Enter HIGH or LOW or NEITHER) <fillin name="AnSwEr0003" characters="15"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=26&amp;sourceFilePath=Library/Rochester/setProbability8BinomialDist/ur_pb_8_6.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=26&amp;sourceFilePath=Library/Rochester/setProbability8BinomialDist/ur_pb_8_6.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=26&amp;sourceFilePath=Library/Rochester/setProbability8BinomialDist/ur_pb_8_6.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=26&amp;sourceFilePath=Library/Rochester/setProbability8BinomialDist/ur_pb_8_6.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<sage language="r"><input>
n = 10
p = 0.3
X = 0:n    # the space R of the random variable 
mu = n*p      # the formula for mean of the Binomial Distributions
sdev = sqrt(n*p*(1-p))  # the formula for the standard deviation
if(n &lt; 101){
dbinom( X, n, p )   # let's print out a bunch of actual probs if N reasonable
}

Pbinom = dbinom(X, n, p )  # create the probability function over X

Psample = rbinom(10^6, n, p)  # to create a histogram, sample a lot
Xtop=max(Psample)          # for scaling the x-axis. Shift by 1/2 below.
hist(Psample, prob=TRUE, br=(-1:Xtop)+0.5, col="skyblue2", xlab="X", 
  main="Binomial Probability Function vs Approximating 'Bell Curve'")

points(X, Pbinom, pch=19, col="darkgreen")  # to create actual (x,f(x))

Pnormal &lt;- function(X){dnorm(X, mean=mu, sd=sdev)}   # to overlap a bell curve
curve(Pnormal, col="red", lwd=2, add=TRUE) 
</input></sage>
</p>
        <p>
You can of course get specific values and graph the Binomial Distribution using R as well...
</p>
        <p>
<sage language="r"><input>
n &lt;- 10
p &lt;- 0.3

paste('Probability Function')
dbinom(0:n, n, p)   # gives the probability function
paste('Distribution function')
pbinom(0:n, n, p)   # gives the distribution function
paste('A random sample')
rbinom(15, n, p)    # gives a random sample of 15 items from b(n,p)

x &lt;- dbinom(0:n, size=n, prob=p)
barplot(x,names.arg=0:n, main=sprintf(paste('n=',n,' and p= ',p)))

</input></sage>
</p>
      </section>
      <section>
        <title>Geometric Distribution</title>
        <p>Consider the situation where one can observe a sequence  of independent
	trials where the likelihood of a success on each individual trial
	stays constant from trial to trial. Call this likelihood the probably of
	"success" and denote its value by <m>p</m> 
	where <m> 0 \lt p \lt 1 </m>.  
	If we let the variable <m>X</m> measure the number of trials needed in order
	to obtain the first success with <m>R = \{1, 2, 3, ... \}</m>, 
	then the resulting distribution of probabilities is called a 
	Geometric Distribution.</p>
        <p>
	<theorem xml:id="GeometricProbabilityFunctionTheorem"><statement><p xml:id="GeometricProbabilityFunction">For a Geometric variable X with <m>R = \{1, 2, 3, ... \}</m>,
	<me>f(x) = (1-p)^{x-1} \cdot p</me>
	</p></statement><proof><p> Since successive trials are independent, then the probability 
	of the first success occurring on the mth trial presumes that
	the previous m-1 trials were all failures.  Therefore the 
	desired probability is given by 
		<me>f(x) = P(X = x) = P(FF...FS) = (1-p)^{x-1}p</me>
	</p></proof></theorem>
	</p>
        <example>
          <title>Flipping a die until getting a success</title>
          <p>Let's consider a simple example for rolling a 24-sided die until you get a multiple of 9...that is, either a 9 or an 18. Successive rolls of a die would appear to be independent events and the probability of getting a 9 or 18 on any given roll is <m>p = \frac{1}{12}</m>. What is then the likelihood that it takes more than three rolls in order for you to get your first success?
</p>
          <p>
This is easily modeled by a geometric distribution and you are looking for 
<me>P(X &gt; 3) = 1 - P(X \le 3) = 1 - F(3) = 1 - f(1) - f(2) - f(3) \\
1 - \frac{1}{12} - \frac{11}{12} \cdot \frac{1}{12} - (\frac{11}{12})^2 \frac{1}{12} \approx 0.77025.</me> 
</p>
        </example>
        <example>
          <title>Testing a critical component until failure</title>
          <p>
Often one will test a critical system component until it fails to see how long the component works. Suppose you have a particular component that on any given trial has a p=0.01 probability of breaking. You also might find it reasonable to presume that succesive trials are independent which could be the case if the component shows no wear from trial to trial. So, you can model this situation with a geometric distribution and the probability that the component fails on the x-th trial is given by
<me>f(x) = 0.99^{x-1} \cdot 0.01.</me>
For some reason, you might be interested in whether the component fails on the 5th trial. The probability of this outcome is given by
<me>f(5) = 0.99^4 \cdot 0.01 \approx 0.0096</me>
so it is unlikely that the component will fail on exactly the 5th trial. However, what about failing on one of the first five trials? Then, you would need
<me>F(5) = f(1)+f(2)+f(3)+f(4)+f(5) \\ = 0.01 + 0.99 \cdot 0.01 + 0.99^2 \cdot 0.01 + 0.99^3 \cdot 0.01 + 0.99^4 \cdot 0.01 \approx 0.049</me>
which is still relatively small. Indeed, with such a small probability of failure, you might expect the component to last for some time. Indeed, we will uncover a formula below for the number of trials, on average, you might expect before failure.
</p>
        </example>
        <p>
Let's go ahead and verify this probability function and investigate some of the geometric distribution's properties.
</p>
        <p>
<theorem><title>Geometric Distribution sums to 1</title><statement><p>
		<me>f(x) = (1-p)^{x-1}p</me> 
		sums to 1 over <m>R = \{ 1, 2, ... \}</m>
		</p></statement><proof><p>
		<me>\sum_{x=1}^{\infty} {f(x)} = \sum_{x=1}^{\infty} {(1-p)^{x-1} p} \\ = p \sum_{j=0}^{\infty} {(1-p)^j} = p \frac{1}{1-(1-p)} = 1</me>
		using a change of variables j = x-1 and the known value for the sum of the geometric series.
		</p></proof></theorem>
</p>
        <p>	
<sage><input>
# Geometric distribution over 0 .. n
# Probability of success on one independent trial = p must also be given
var('x')
# n = 50 by default. actually should be infinite
@interact
def _(p=input_box(0.1,label='p = '),n=[25,50,75,100,200]):
    np1 = n+1
    R = range(1,np1)
    f(x) = (1-p)^(x-1)*p
    F(x) = 1 - (1-p)^x
    pretty_print(html('Density Function: $f(x) =%s$'%str(latex(f(x)))+' over the space $R = %s$'%str(R)))
    points((k,f(x=k)) for k in R).show(title="Probability Function")
    print
    points((k,F(x=k)) for k in R).show(title="Distribution Function")
    if (n == 25):
        for k in R:
            pretty_print(html('$f(%s'%k+') = %s'%latex(f(x=k))+' \\approx %s$'%f(x=k).n(digits=5)))
</input></sage>
</p>
        <p>	
	<theorem><title>Geometric Statistics Theorem</title><statement><p xml:id="GeometricStatistics">
		For the geometric distribution, 
			<me>\mu = 1/p</me>
			<me>\sigma^2  = \frac{1-p}{p^2}</me>
			<me>\gamma_1 = \frac{2-p}{\sqrt{1-p}}</me>
			<me>\gamma_2 = \frac{p^2-6p+6}{1-p} + 3</me>

		</p></statement><proof><p> For the mean,
			<md><mrow>\mu &amp; = E[X] = \sum_{x=1}^{\infty} {x(1-p)^{x-1}p}</mrow><mrow> &amp; = p \sum_{x=1}^{\infty} {x(1-p)^{x-1}}</mrow><mrow> &amp; = p \frac{1}{(1-(1-p))^2}</mrow><mrow> &amp; = p \frac{1}{p^2} = \frac{1}{p}</mrow></md>
			</p><p> For the variance,
			<md><mrow>\sigma^2 &amp; = E[X(X-1)] + \mu - \mu^2 </mrow><mrow> &amp; = \sum_{x=1}^{\infty} {x(x-1)(1-p)^{x-1}p} + \mu - \mu^2 </mrow><mrow> &amp; = (1-p)p \sum_{x=2}^{\infty} {x(x-1)(1-p)^{x-2}} + \frac{1}{p} - \frac{1}{p^2}</mrow><mrow> &amp; = (1-p)p \frac{2}{(1-(1-p))^3} + \frac{1}{p} - \frac{1}{p^2}</mrow><mrow> &amp; = \frac{1-p}{p^2}</mrow></md>
			</p></proof></theorem> 
</p>
        <p>
	<theorem><title>Geometric Distribution Function</title><statement><p>
			<me>F(x) =  1- (1-p)^{x}</me>
		</p></statement><proof><p> Consider the accumulated probabilities over a range of values...
		<md><mrow> P(X \le x) &amp; = 1 - P(X \gt x)</mrow><mrow> &amp; = 1- \sum_{k={x+1}}^{\infty} {(1-p)^{k-1}p}</mrow><mrow> &amp; = 1- p \frac{(1-p)^{x}}{1-(1-p)}</mrow><mrow> &amp; = 1- (1-p)^{x}</mrow></md>
		</p></proof></theorem> 
</p>
        <p>	
	<theorem><title>Statistics for Geometric Distribution</title><statement><p>Mean, Variance, Skewness, Kurtosis computed by Sage.
		</p></statement><proof><p>
See the interactive Sage cell below...
</p></proof></theorem>
<sage><input>
var('x,n,p')
assume(x,'integer')
f(x) = p*(1-p)^(x-1)
mu = sum(x*f,x,0,oo).full_simplify()
M2 = sum(x^2*f,x,0,oo).full_simplify()
M3 = sum(x^3*f,x,0,oo).full_simplify()
M4 = sum(x^4*f,x,0,oo).full_simplify()

pretty_print('Mean = ',mu)

v = (M2-mu^2).factor().full_simplify()
pretty_print('Variance = ',v)
stand = sqrt(v)

sk = (((M3 - 3*M2*mu + 2*mu^3))/stand^3).full_simplify()
pretty_print('Skewness = ',sk)

kurt = (M4 - 4*M3*mu + 6*M2*mu^2 -3*mu^4).factor()/stand^4
pretty_print('Kurtosis = ',(kurt-3).factor(),'+3')
	</input></sage>
</p>
        <p>
	<theorem><title>The Geometric Distribution yields a memoryless model.</title><statement><p>
	If X has a geometric distribution and a and b are nonnegative integers, then
	<me>P( X &gt; a + b | X &gt; b ) = P( X &gt; a)</me>
	</p></statement><proof><p>
	Using the definition of conditional probability,
	<md><mrow>P( X &gt; a + b | X &gt; b ) &amp; = \frac{P( X &gt; a + b \cap X &gt; b )}{P( X &gt; b)}</mrow><mrow> &amp; = \frac{P( X &gt; a + b )}{P( X &gt; b)}</mrow><mrow> &amp; = \frac{(1-p)^{a+b}}{(1-p)^b}</mrow><mrow> &amp; = (1-p)^a</mrow><mrow> &amp; = P(X &gt; a)</mrow></md>
	</p></proof></theorem>
</p>
      </section>
      <section>
        <title>Negative Binomial</title>
        <p>Consider the situation where one can observe a sequence  of independent
	trials where the likelihood of a success on each individual trial
	stays constant from trial to trial. Call this likelihood the probably of
	"success" and denote its value by <m>p</m> 
	where <m> 0 \lt p \lt 1 </m>.  
	If we let the variable <m>X</m> measure the number of trials needed in order
	to obtain the rth success, <m>r \ge 1</m>, with 
	<m>R = \{r, r+1, r+2, ... \}</m>
	then the resulting distribution of probabilities is called a 
	Geometric Distribution.</p>
        <p>Note that r=1 gives the Geometric Distribution.</p>
        <p>	
<theorem><title>Negative Binomial Series</title><statement><p>
			<me>\displaystyle \frac{1}{(a+b)^n} = \sum_{k=0}^{\infty} {(-1)^k \binom{n + k - 1}{k} a^k b^{-n-k}}</me> 
		</p></statement><proof><p>First, convert the problem to a slightly different form:		
		<m> \frac{1}{(a+b)^n} = \frac{1}{b^n} \frac{1}{(\frac{a}{b}+1)^n} 
					 = \frac{1}{b^n} \sum_{k=0}^{\infty} {(-1)^k \binom{n + k - 1}{k} \left ( \frac{a}{b} \right ) ^k}
		</m>
		</p><p>So, let's replace <m>\frac{a}{b} = x</m> and ignore for a while the term factored out. Then, we only need to show 
	<me>\sum_{k=0}^{\infty} {(-1)^k \binom{n + k - 1}{k} x^k} = \left ( \frac{1}{1+x} \right )^n </me>
However
	<md><mrow> \left ( \frac{1}{1+x} \right )^n &amp; = \left ( \frac{1}{1 - (-x)} \right )^n </mrow><mrow> &amp; = \left ( \sum_{k=0}^{\infty} {(-1)^k x^k} \right )^n</mrow></md>
</p><p>This infinite sum raised to a power can be expanded by distributing terms in the standard way. In doing so, the various powers of x multiplied together
will create a series in powers of x involving <m>x^0, x^1, x^2, ...</m>.  
To detemine the final coefficients notice that the number of time <m>m^k</m> will appear in this product depends upon the number of ways one can write k as a sum of nonnegative integers.
</p><p>For example, the coefficient of <m>x^3</m> will come from the n ways of multiplying the coefficients 
<m>x^3, x^0, ..., x^0</m> and <m>x^2, x^1, x^0, ..., x^0</m>
and <m>x^1, x^1, x^1, x^0,..., x^0</m>. This is equivalent to finding the number of ways to write the number k as a sum of nonnegative integers. The possible set of nonnegative integers is {0,1,2,...,k} and one way to count the combinations is to separate k *'s by n-1 |'s.  For example, if k = 3 then *||** means 
<m>x^1 x^0 x^2 = x^3</m>. Similarly for k = 5 and |**|*|**| implies <m> x^0 x^2 x^1 x^2 x^0 = x^5</m>.  The number of ways to interchange the identical *'s among the idential |'s is <m>\binom{n+k-1}{k}</m>. </p><p>Furthermore, to obtain an even power of x will require an even number of odd powers and an odd power of x will require an odd number of odd powers. So, the coefficient of the odd terms stays odd and the coefficient of the even terms remains even. Therefore,	
<me> \left ( \frac{1}{1+x} \right )^n = \sum_{k=0}^{\infty} {(-1)^k \binom{n + k - 1}{k} x^k}</me>	
Similarly,
<me> \left ( \frac{1}{1-x} \right )^n = \left ( \sum_{k=0}^{\infty} {x^k} \right )^n = \sum_{k=0}^{\infty} {\binom{n + k - 1}{k} x^k}</me>
</p></proof></theorem>	
</p>
        <p>Consider the situation where one can observe a sequence  of independent trials with the likelihood of a success on each individual trial <m>p</m> where 
	<m> 0 \lt p \lt 1 </m>.  
For a positive integer r, let the variable <m>X</m> measure the number of trials needed in order to obtain the rth success. Then the resulting distribution of probabilities is called a Negative Binomial Distribution.</p>
        <p>
<theorem><title>Negative Binomial Probability Function</title><statement><p xml:id="NegativeBinomialProbabilityFunction">
	<me>f(x) = \binom{x - 1}{r-1}(1-p)^{x-r}p^r,</me>
	for <m>x \in R = \{r, r+1, ... \}</m>.
	</p></statement><proof><p> Since successive trials are independent, then the probability of the rth success occurring on the x-th trial presumes that in the previous x-1 trials were r-1 successes and x-r failures. You can arrange these indistinguishable successes (and failures) in <m>\binom{x-1}{r-1}</m> unique ways. Therefore the desired probability is given by 
			<me>P(X=x) = \binom{x - 1}{r-1}(1-p)^{x-r}p^r</me>
	</p></proof></theorem>
</p>
        <example>
          <title>Flipping a die until getting a third success</title>
          <p>Once again, consider rolling our 24-sided die until you get a multiple of 9...that is, either a 9 or an 18...for the third time. Once again, the probability of getting a 9 or 18 on any given roll is <m>p = \frac{1}{12}</m> but since we will continue rolling until we get a success for the third time, this is modeled by a negative binomial distribution and you are looking for 
<me>f(x) = \binom{x-1}{2}(\frac{11}{12})^{x-3} (\frac{1}{12})^3  \\
= \frac{(x-1)(x-2)}{2}(\frac{11}{12})^{x-3} (\frac{1}{12})^3</me>  
</p>
          <p>
Computing f(x) for any given x is relatively painless but computing F(x) could take some effort. There is generally not a graphing calculator distribution option for negative binomial but the interactive cells below can be utilized to help with the tedious computations. For example, if you were interested in <m>P(X \lt 20) = P(X \le 19 ) = F(19)</m> then the interactive calculator below using r=3 and <m>p = \frac{1}{12}</m> gives <m>F(19) \approx 0.20737.</m> 
</p>
        </example>
        <example>
          <title>Testing a critical component until failure</title>
          <p>
Let's once again test a series of critical system components until you find two that fail. Again, suppose a particular component has a p=0.01 probability of breaking on any given trial. Since you will stop when you encounter the third failure, you can model this situation with a negative binomial distribution and the probability that the 2nd component fails on the x-th trial is given by
<me>f(x) = \binom{x-1}{2-1} 0.99^{x-2} \cdot 0.01^2 = (x-1) \cdot 0.99^{x-2} \cdot 0.01^2.</me>
Once again, let's compute the likelihood that you get the second failure on one of the first five trials. Then, 
<me>F(5) = f(2)+f(3)+f(4)+f(5) \\ = 0.01^2 + 2 \cdot 0.99 \cdot 0.01^2 + 3 \cdot 0.99^2 \cdot 0.01^2 + 4 \cdot 0.99^3 \cdot 0.01^2 \approx some nice number</me>
which is still relatively small. 
</p>
        </example>
        <p>
<theorem><title>Negative Binomial Distribution Sums to 1</title><statement><p>
		<me>\sum_{x=r}^{\infty} {\binom{x - 1}{r-1}(1-p)^{x-r}p^r} = 1</me>
	</p></statement><proof><p>
	<me>\sum_{x=r}^{\infty} {\binom{x - 1}{r-1}(1-p)^{x-r}p^r} = p^r \sum_{x=r}^{\infty} {\binom{x - 1}{r-1}(1-p)^{x-r}}</me>
		<p>and by using <m>k = x-r</m></p>
	<md><mrow> &amp; = p^r \sum_{k=0}^{\infty} {\binom{r + k - 1}{k}(1-p)^k}</mrow><mrow> &amp; = p^r \frac{1}{(1-(1-p))^r}</mrow><mrow> &amp; = 1</mrow></md>
	</p></proof></theorem>
</p>
        <p>Below, the interactive cell symbolically computes f(x) and F(x) for the negative binomial distribution.</p>
        <p>
<sage><input>
# Negative Binomial calculator
@interact
def _(p=input_box(1/12,width=15),r=slider(1,10,1,2)):
    n = 4*(floor(r/p)+1)
    np1 = n+1
    R = range(r,np1)
    f(x) = (factorial(x-1)/(factorial(r-1)*factorial(x-r)))*(1-p)^(x-r)*p^r
    acc = 0
    for k in R:
        prob = f(x=k)
        acc = acc+prob
        pretty_print('f(%s) = '%k,' %.8f'%prob,' and F(%s) = '%k,' %.8f'%acc)
</input></sage>
</p>
        <!-- Based upon
<webwork source="Library/UBC/STAT/STAT302/HW06/HW06-02.pg">
-->
        <exercise>
          <webwork-reps xml:id="extracted-webwork-27" ww-id="webwork-27">
    <authored>
      
        <setup><pg-code>
          </pg-code></setup>
        <statement><p>
      A telephone saleswoman arranges a sequence of interviews of potential customers in order to sell them an insurance policy. She believes that her success rate in completing a sale in any interview is 11 %. Provide answers to at least 3 decimal places.
      </p><p>Determine the probability that she fails to make a sale on the first five interviews:  <var name="0.558" width="10"/>
      </p><p>
      Determine the probability that she makes her first sale on the fourth interview: <var name="0.078" width="10"/>
      </p><p>
      Determine the probability that the second sale is made on the sixth interview: <var name="0.04209" width="10"/>
      </p></statement>
        <solution><p>Using geometric,
      <me>P(X \gt 5) = 1 - F(5) = (1-p)^5 = 0.89^5 \approx 0.558</me>
      </p><p>Using geometric,
      <me>P(X = 4) = f(4) = (1-p)^3 \cdot p = 0.89^3 \cdot 0.11 \approx 0.078</me>
      </p><p>Using negative binomial with r=2,
      <me>P(X = 6) = f(6) = 5 (1-p)^4 \cdot p^2 = 5 \cdot 0.89^4 \cdot 0.11^2 \approx 0.04209</me>
      </p></solution>
      
    </authored>

    <pg>
      #######################################
      ###    Generated from PreTeXt source   
      ###    on 2018-11-07T13:06:50-06:00    
      ###                                    
      ###   http://mathbook.pugetsound.edu   
      ###                                    
      #######################################
      ## DBsubject()
      ## DBchapter()
      ## DBsection()
      ## Level()
      ## KEYWORDS()
      ## TitleText1(Essentials of Mathematical Probability and Statistics)
      ## EditionText1()
      ## AuthorText1(John Travis)
      ## Section1(not reported)
      ## Problem1(7.4.6)
      ## Author()
      ## Institution()
      ## Language(en-US)
      
      DOCUMENT();
      
      ############################################################
      # Load Macros
      ############################################################
      loadMacros(
        "PGstandard.pl",
        "MathObjects.pl",
        "PGML.pl",
        "AnswerFormatHelp.pl",
        "PGcourse.pl",
      );
      
      ############################################################
      # Header
      ############################################################
      COMMENT('Authored in PreTeXt');
      TEXT(beginproblem());
      
      ############################################################
      # PG Setup
      ############################################################
      Context('Numeric');
      
      ############################################################
      # Body
      ############################################################
      
      BEGIN_PGML
      A telephone saleswoman arranges a sequence of interviews of potential customers in order to sell them an insurance policy. She believes that her success rate in completing a sale in any interview is 11 %. Provide answers to at least 3 decimal places.
      
      Determine the probability that she fails to make a sale on the first five interviews:  [__________]{0.558}
      
      Determine the probability that she makes her first sale on the fourth interview: [__________]{0.078}
      
      Determine the probability that the second sale is made on the sixth interview: [__________]{0.04209}
      
      END_PGML
      
      ############################################################
      # Solution
      ############################################################
      
      BEGIN_PGML_SOLUTION
      Using geometric,
      
      [```\newcommand{\gt}{&gt;}P(X \gt 5) = 1 - F(5) = (1-p)^5 = 0.89^5 \approx 0.558```]
      
      Using geometric,
      
      [```P(X = 4) = f(4) = (1-p)^3 \cdot p = 0.89^3 \cdot 0.11 \approx 0.078```]
      
      Using negative binomial with r=2,
      
      [```P(X = 6) = f(6) = 5 (1-p)^4 \cdot p^2 = 5 \cdot 0.89^4 \cdot 0.11^2 \approx 0.04209```]
      
      END_PGML_SOLUTION
      
      ############################################################
      # End Problem
      ############################################################
      
      ENDDOCUMENT();
      
    </pg>

      
    <static seed="27">
      <statement><p>A telephone saleswoman arranges a sequence of interviews of potential customers in order to sell them an insurance policy. She believes that her success rate in completing a sale in any interview is 11 <percent/>. Provide answers to at least 3 decimal places.</p><p>Determine the probability that she fails to make a sale on the first five interviews:  <fillin name="AnSwEr0001" characters="10"/></p><p>Determine the probability that she makes her first sale on the fourth interview: <fillin name="AnSwEr0002" characters="10"/></p><p>Determine the probability that the second sale is made on the sixth interview: <fillin name="AnSwEr0003" characters="10"/></p></statement>
      
      <solution><p>Using geometric,</p><p><me>P(X \gt 5) = 1 - F(5) = (1-p)^5 = 0.89^5 \approx 0.558</me></p><p>Using geometric,</p><p><me>P(X = 4) = f(4) = (1-p)^3 \cdot p = 0.89^3 \cdot 0.11 \approx 0.078</me></p><p>Using negative binomial with r=2,</p><p><me>P(X = 6) = f(6) = 5 (1-p)^4 \cdot p^2 = 5 \cdot 0.89^4 \cdot 0.11^2 \approx 0.04209</me></p></solution>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=27&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGd0fXs%2BfVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkEgdGVsZXBob25lIHNhbGVzd29tYW4gYXJyYW5nZXMgYSBzZXF1ZW5jZSBvZiBpbnRlcnZpZXdzIG9mIHBvdGVudGlhbCBjdXN0b21lcnMgaW4gb3JkZXIgdG8gc2VsbCB0aGVtIGFuIGluc3VyYW5jZSBwb2xpY3kuIFNoZSBiZWxpZXZlcyB0aGF0IGhlciBzdWNjZXNzIHJhdGUgaW4gY29tcGxldGluZyBhIHNhbGUgaW4gYW55IGludGVydmlldyBpcyAxMSAlLiBQcm92aWRlIGFuc3dlcnMgdG8gYXQgbGVhc3QgMyBkZWNpbWFsIHBsYWNlcy4KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCBzaGUgZmFpbHMgdG8gbWFrZSBhIHNhbGUgb24gdGhlIGZpcnN0IGZpdmUgaW50ZXJ2aWV3czogIFtfX19fX19fX19fXXswLjU1OH0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCBzaGUgbWFrZXMgaGVyIGZpcnN0IHNhbGUgb24gdGhlIGZvdXJ0aCBpbnRlcnZpZXc6IFtfX19fX19fX19fXXswLjA3OH0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCB0aGUgc2Vjb25kIHNhbGUgaXMgbWFkZSBvbiB0aGUgc2l4dGggaW50ZXJ2aWV3OiBbX19fX19fX19fX117MC4wNDIwOX0KCgpFTkRfUEdNTAoKQkVHSU5fUEdNTF9TT0xVVElPTgpVc2luZyBnZW9tZXRyaWMsCgpbYGBgUChYIFxndCA1KSA9IDEgLSBGKDUpID0gKDEtcCleNSA9IDAuODleNSBcYXBwcm94IDAuNTU4YGBgXQoKCgpVc2luZyBnZW9tZXRyaWMsCgpbYGBgUChYID0gNCkgPSBmKDQpID0gKDEtcCleMyBcY2RvdCBwID0gMC44OV4zIFxjZG90IDAuMTEgXGFwcHJveCAwLjA3OGBgYF0KCgoKVXNpbmcgbmVnYXRpdmUgYmlub21pYWwgd2l0aCByPTIsCgpbYGBgUChYID0gNikgPSBmKDYpID0gNSAoMS1wKV40IFxjZG90IHBeMiA9IDUgXGNkb3QgMC44OV40IFxjZG90IDAuMTFeMiBcYXBwcm94IDAuMDQyMDlgYGBdCgoKCgpFTkRfUEdNTF9TT0xVVElPTgoKRU5ERE9DVU1FTlQoKTs%3D</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=27&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGd0fXs%2BfVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkEgdGVsZXBob25lIHNhbGVzd29tYW4gYXJyYW5nZXMgYSBzZXF1ZW5jZSBvZiBpbnRlcnZpZXdzIG9mIHBvdGVudGlhbCBjdXN0b21lcnMgaW4gb3JkZXIgdG8gc2VsbCB0aGVtIGFuIGluc3VyYW5jZSBwb2xpY3kuIFNoZSBiZWxpZXZlcyB0aGF0IGhlciBzdWNjZXNzIHJhdGUgaW4gY29tcGxldGluZyBhIHNhbGUgaW4gYW55IGludGVydmlldyBpcyAxMSAlLiBQcm92aWRlIGFuc3dlcnMgdG8gYXQgbGVhc3QgMyBkZWNpbWFsIHBsYWNlcy4KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCBzaGUgZmFpbHMgdG8gbWFrZSBhIHNhbGUgb24gdGhlIGZpcnN0IGZpdmUgaW50ZXJ2aWV3czogIFtfX19fX19fX19fXXswLjU1OH0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCBzaGUgbWFrZXMgaGVyIGZpcnN0IHNhbGUgb24gdGhlIGZvdXJ0aCBpbnRlcnZpZXc6IFtfX19fX19fX19fXXswLjA3OH0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCB0aGUgc2Vjb25kIHNhbGUgaXMgbWFkZSBvbiB0aGUgc2l4dGggaW50ZXJ2aWV3OiBbX19fX19fX19fX117MC4wNDIwOX0KCgpFTkRfUEdNTAoKRU5ERE9DVU1FTlQoKTs%3D</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=27&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGd0fXs%2BfVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkEgdGVsZXBob25lIHNhbGVzd29tYW4gYXJyYW5nZXMgYSBzZXF1ZW5jZSBvZiBpbnRlcnZpZXdzIG9mIHBvdGVudGlhbCBjdXN0b21lcnMgaW4gb3JkZXIgdG8gc2VsbCB0aGVtIGFuIGluc3VyYW5jZSBwb2xpY3kuIFNoZSBiZWxpZXZlcyB0aGF0IGhlciBzdWNjZXNzIHJhdGUgaW4gY29tcGxldGluZyBhIHNhbGUgaW4gYW55IGludGVydmlldyBpcyAxMSAlLiBQcm92aWRlIGFuc3dlcnMgdG8gYXQgbGVhc3QgMyBkZWNpbWFsIHBsYWNlcy4KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCBzaGUgZmFpbHMgdG8gbWFrZSBhIHNhbGUgb24gdGhlIGZpcnN0IGZpdmUgaW50ZXJ2aWV3czogIFtfX19fX19fX19fXXswLjU1OH0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCBzaGUgbWFrZXMgaGVyIGZpcnN0IHNhbGUgb24gdGhlIGZvdXJ0aCBpbnRlcnZpZXc6IFtfX19fX19fX19fXXswLjA3OH0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCB0aGUgc2Vjb25kIHNhbGUgaXMgbWFkZSBvbiB0aGUgc2l4dGggaW50ZXJ2aWV3OiBbX19fX19fX19fX117MC4wNDIwOX0KCgpFTkRfUEdNTAoKQkVHSU5fUEdNTF9TT0xVVElPTgpVc2luZyBnZW9tZXRyaWMsCgpbYGBgUChYIFxndCA1KSA9IDEgLSBGKDUpID0gKDEtcCleNSA9IDAuODleNSBcYXBwcm94IDAuNTU4YGBgXQoKCgpVc2luZyBnZW9tZXRyaWMsCgpbYGBgUChYID0gNCkgPSBmKDQpID0gKDEtcCleMyBcY2RvdCBwID0gMC44OV4zIFxjZG90IDAuMTEgXGFwcHJveCAwLjA3OGBgYF0KCgoKVXNpbmcgbmVnYXRpdmUgYmlub21pYWwgd2l0aCByPTIsCgpbYGBgUChYID0gNikgPSBmKDYpID0gNSAoMS1wKV40IFxjZG90IHBeMiA9IDUgXGNkb3QgMC44OV40IFxjZG90IDAuMTFeMiBcYXBwcm94IDAuMDQyMDlgYGBdCgoKCgpFTkRfUEdNTF9TT0xVVElPTgoKRU5ERE9DVU1FTlQoKTs%3D</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=27&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGd0fXs%2BfVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkEgdGVsZXBob25lIHNhbGVzd29tYW4gYXJyYW5nZXMgYSBzZXF1ZW5jZSBvZiBpbnRlcnZpZXdzIG9mIHBvdGVudGlhbCBjdXN0b21lcnMgaW4gb3JkZXIgdG8gc2VsbCB0aGVtIGFuIGluc3VyYW5jZSBwb2xpY3kuIFNoZSBiZWxpZXZlcyB0aGF0IGhlciBzdWNjZXNzIHJhdGUgaW4gY29tcGxldGluZyBhIHNhbGUgaW4gYW55IGludGVydmlldyBpcyAxMSAlLiBQcm92aWRlIGFuc3dlcnMgdG8gYXQgbGVhc3QgMyBkZWNpbWFsIHBsYWNlcy4KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCBzaGUgZmFpbHMgdG8gbWFrZSBhIHNhbGUgb24gdGhlIGZpcnN0IGZpdmUgaW50ZXJ2aWV3czogIFtfX19fX19fX19fXXswLjU1OH0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCBzaGUgbWFrZXMgaGVyIGZpcnN0IHNhbGUgb24gdGhlIGZvdXJ0aCBpbnRlcnZpZXc6IFtfX19fX19fX19fXXswLjA3OH0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCB0aGUgc2Vjb25kIHNhbGUgaXMgbWFkZSBvbiB0aGUgc2l4dGggaW50ZXJ2aWV3OiBbX19fX19fX19fX117MC4wNDIwOX0KCgpFTkRfUEdNTAoKRU5ERE9DVU1FTlQoKTs%3D</server-url>

  </webwork-reps>
        </exercise>
        <p>
<theorem><title>Statistics for Negative Binomial Distribution</title><statement><p xml:id="NegativeBinomialStatistics">
		For the Negative Binomial Distribution, 
		<me>\mu = \frac{r}{p}</me>
		<me>\sigma^2 = r \frac{1-p}{p^2}</me>
		<me>\gamma_1 = \frac{2-p}{\sqrt{r(1-p)}}</me>
		<me>\gamma_2 = \frac{p^2-6p+6}{r(1-p)} + 3</me>
	</p></statement><proof>	
See interactive cell below...
</proof></theorem>
</p>
        <p>
<sage><input>
# Negative Binomial
var('x,n,p,r,alpha')
assume(x,'integer')
assume(alpha,'integer')
assume(alpha &gt; 2)
assume(0 &lt; p &lt; 1)
@interact
def _(r=[2,5,10,15,alpha]):
    f(x) = binomial(x-1,r-1)*p^r*(1-p)^(x-r)
    mu = sum(x*f,x,r,oo).full_simplify()
    M2 = sum(x^2*f,x,r,oo).full_simplify()
    M3 = sum(x^3*f,x,r,oo).full_simplify()
    M4 = sum(x^4*f,x,r,oo).full_simplify()
        
    pretty_print('Mean = ',mu)
    
    v = (M2-mu^2).full_simplify()
    pretty_print('Variance = ',v)
    stand = sqrt(v)
    
    sk = (((M3 - 3*M2*mu + 2*mu^3)).full_simplify()/stand^3).factor()
    pretty_print('Skewness = ',sk)
    
    kurt = ((M4 - 4*M3*mu + 6*M2*mu^2 -3*mu^4)/v^2).full_simplify()
    pretty_print('Kurtosis = ',(kurt-3).factor(),'+3')
</input></sage>
</p>
        <p>
<sage language="r"><input>
r = 3
p = 0.4
M = 20*r
X = r:M    # the space R of the random variable should be infinite 
Xshift = 0:(M-r)   # because this is the way r does dbinom, etc. by letting
                   # x measure the number of failures rather than the number
                   # of total trials.  So, our x=r would be 0 failures and so
                   # r would count that as x=0.
mu = r/p      # the formula for mean of the Binomial Distributions
sdev = sqrt(r*(1-p)/p^2)  # the formula for the standard deviation
if(M &lt; 101){
dnbinom( Xshift, r, p )   # let's print out a bunch of actual probs
}
Pnbinom = dnbinom(Xshift, r, p )  # create the probability function over X

Psample = rnbinom(10^6, r, p)  # to create a histogram, sample a lot

Xtop=max(Psample)          # for scaling the x-axis. Shift by 1/2 below.
hist(Psample, prob=TRUE, br=(-1:Xtop)+0.5, col="skyblue2", xlab="X - r", 
  main="Negative Binomial Probability Function vs Approximating 'Bell Curve'")

points(Xshift, Pnbinom, pch=19, col="darkgreen")  # to create actual (x,f(x))

Pnormal &lt;- function(X){dnorm(X, mean=mu-r, sd=sdev)}   
# to overlap a bell curve, shifting our mean by r in order to fit the r protocol
curve(Pnormal, col="red", lwd=2, add=TRUE)
</input></sage>
</p>
      </section>
      <section>
        <title>Summary</title>
        <introduction>
Here is a summary of the major results dealing with Bernoulli-based variables:
</introduction>
        <p>
<xref ref="BinomialProbabilityFunction">Binomial Distribution</xref>
</p>
        <p>
<xref ref="BinomialStatistics">Binomial Distribution Statistics</xref>
</p>
        <p>
<xref ref="GeometricProbabilityFunction">Geometric Distribution</xref>
</p>
        <p>
<xref ref="GeometricStatistics">Geometric Distribution Statistics</xref>
</p>
        <p>
<xref ref="NegativeBinomialProbabilityFunction">Negative Binomial Distribution</xref>
</p>
        <p>
<xref ref="NegativeBinomialStatistics">Negative Binomial Distribution Statistics</xref>
</p>
      </section>
      <section>
        <title>Exercises</title>
        <p>
<exercise><title> - Gallup Consumer Confidence Polling</title><p>
A January 2008 Gallup poll on consumer confidence asked the question "How would you rate economic conditions in this country today" and 22% responded "Excellent" or "Good", 45% responded "Only Fair", and 33% responded "Poor". If you pick a representative sample of 25 people and ask them the same question, if X measures the number of responses that are "Excellent" or "Good", determine
<ul><li>P(X is at most 5).</li><li>P(X is at least 5).</li><li>the expected number of Excellent or Good responses.</li></ul>
</p><solution><p>
This is a Binomial distribution with n=25 and p = 0.22.

<ul><li>P(X is at most 5) = F(5) = f(0)+f(1)+f(2)+f(3)+f(4)+f(5) = 0.51843</li><li>P(X is at least 5) = 1 - F(4) = 0.67183</li><li><m>\mu = np = 25 \cdot .22 = 5.5</m></li></ul>
</p></solution></exercise>
</p>
        <p>
<exercise><title> - Rolling Dice</title><p>
You keep on rolling a pair of dice and let X be the number of rolls needed until you get a sum of 7 or 11 for the second time. Determine:
<ol><li>P(7 or 11 on one roll)</li><li>The expected number of rolls until you get the second 7 or 11 sum.</li><li>P(X = 12)</li><li><m>P(X \ge 4)</m></li></ol>
</p><solution><p> For this problem, use the Negative Binomial Distribution when looking for the number of trials till the 2nd success. p is determined in the first answer.
<ol><li>P(7 or 11 on one roll) = 8/36 = 2/9, using equally likely outcomes.</li><li><m>\mu = \frac{r}{p} = \frac{2}{2/9} = 9</m></li><li><m>P( X = 12) = \binom{11}{1} (7/9)^10 \cdot (2/9)^2 = 0.044</m></li><li><md><mrow>P(X \ge 4) &amp; = 1- P(x \le 3) </mrow><mrow> &amp; = 1 - [ f(2) + f(3) ]</mrow><mrow> &amp; = 1 - \left[ \binom{1}{1} (2/9)^2 + \binom{2}{1} (7/9)^1 \cdot (2/9)^2 \right ]</mrow><mrow> &amp; = 1 - 0.1262 = 0.8738.</mrow></md></li></ol>
</p></solution></exercise>
</p>
        <p>
<exercise><title> - Collecting Kids Meal Prizes</title><p>
You love to eat at Chick-Fil-A with your kids and want to collect all of the five new book titles that come randomly included with each kids meal.  If the promotion with these books starts today, determine:
<ol><li>The probability that you get a book you don't have when purchasing the first children's meal.</li><li>The probability that you it takes more than four purchases in order to get a second title.</li><li>The expected total number of children's meals you would expect to purchase in order to get all five titles.</li></ol>
</p><solution><p>
<ol><li>One. The first meal will certainly have a book that you have not received yet.</li><li>This is a geometric distribution with p=4/5.  P(X &gt; 4) = 1 - F(4) = <m>(1 - 4/5)^4 = \frac{1}{625}</m> which is very small. Note, in this case you would have needed to receive the same title randomly for all of the first four kids meal purchases. If this were to ever happen, please let the people at the counter know and it will be their pleasure to swap out for a new title. </li><li>Use the geometric distribution five times with changing values for p. For the first book p = 1 means you are certain to get a new title. For the second book title the probability of success is p=4/5; for the third book title the probability of success is p=3/5; for the fourth the probability is p=2/5; and for the last the probability is p = 1/5. Using the mean as 1/p in each case and accumulating these gives the total expected number of meals to purchase as 
	<md><mrow> &amp; 1 + \frac{1}{\frac{4}{5}} + \frac{1}{\frac{3}{5}} + \frac{1}{\frac{2}{5}} + \frac{1}{\frac{1}{5}} </mrow><mrow> &amp; = 1 + \frac{5}{4} + \frac{5}{3} + \frac{5}{2} + \frac{5}{1} </mrow><mrow> &amp; = \frac{12 + 15 + 25 + 30 + 60}{12} </mrow><mrow> &amp; = \frac{142}{12} = 11.833</mrow></md> 
	and so you would need 12 kids meals.  If this were to happen, please be certain to donate the "extra" books to an organization that works with kids or directly to some kids that you might know.</li></ol>
</p></solution></exercise>
</p>
        <p>
<exercise><title> - Rolling Dice</title><p>Suppose you roll a standard pair of 6-sided dice 20 times and let X measure the number of outcomes which result in a sum of 7 or 11. Determine:
<ol><li>the expected number of rolls which have a sum of 7 or 11</li><li>P(X=5)</li><li>P( X &gt; 5)</li><li>P( X &lt; 5)</li></ol>
</p></exercise>
</p>
        <p>
<exercise><title> - Rolling Dice yet again</title><p>Suppose you roll a standard pair of 6-sided dice X times until you get a sum of 7 or 11 a third time. Determine:
<ol><li>the expected number of rolls needed on average.</li><li>P(X=5)</li><li>P( X &gt; 5)</li><li>P( X &lt; 5)</li></ol>
</p></exercise>
</p>
        <p>
<exercise><title> - 2 standard deviations from the mean</title><p>Given p = 0.3 determine the following:
<ol><li>For Binomial with n = 50, <m>P(\mu - 2\sigma \le X \le \mu + 2\sigma)</m></li><li>For Negative Binomial with r = 2, <m>P(\mu - 2\sigma \le X \le \mu + 2\sigma)</m></li></ol>
</p><solution><p>
For Binomial with p = 0.3 and n = 50, <m>\mu = n \cdot p = 15</m> and <m>\sigma^2 = n \cdot p \cdot (1-p) = 10.5</m>.  So, <m>\sigma = \sqrt{10.5}</m>.  Therefore,
<md><mrow>P(\mu - 2\sigma \le X \le \mu + 2\sigma) &amp; = P(15 - 2 \sqrt{10.5} \le X \le 15 + 2 \sqrt{10.5})</mrow><mrow> &amp; P( X \in \{9, 10, 11, ... , 19, 20, 21 \} )</mrow></md>
Then 
<me>F(21) - F(8) \approx 0.97491 - 0.01825 = 0.95666 </me>
</p><p>
For Negative Binomial with p = 0.3 and r = 2, <m>\mu = \frac{2}{0.3} = \frac{20}{3}</m> and <m>\sigma^2 = 2 \frac{0.7}{0.3^2} = \frac{140}{9}</m> and so <m>\sigma \approx 3.9</m>.  Therefore,
<md><mrow>P(\mu - 2\sigma \le X \le \mu + 2\sigma) &amp; = P(6.7 - 7.8 \le X \le 6.7 + 7.8)</mrow><mrow> &amp; P( X \in \{2, 3, ... , 14, 15, 16 \} )</mrow></md>
Then,
	<me>F(16) \approx 0.973888</me>
</p></solution></exercise>
</p>
        <p>
<exercise><title>Chapter Experiment</title><p>
Take a die and roll it 4 times, keeping track on paper each time you get a 6 (say).  Repeat this 100 times. (Actually, you can use a standard 6-sided die or find a more exotic one with more sides.)  You should have gotten anywhere from 0 of the rolls to be a 6 up to all of the rolls to be a 6.  Collect the relative frequencies of each of the possible outcomes in R= \{0,1,2, ..., 100\} and plot.  Compare several of the experimental relative frequencies with the theoretical value you would expect using the proper distribution from this chapter. Comment on how well you did. 
</p></exercise>
</p>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="PoissonExponentialGamma">
      <title>Distributions based upon Poisson Processes</title>
      <section>
        <title>Introduction</title>
        <p>
In this chapter, you will investigate the relationship between number of successes over some interval.  For each, one of these quantities will be fixed and the other one variable. First, consider the following:
</p>
        <p>
<definition><title>Poisson Process</title><statement><p>
A Poisson process is a course of action in which:
<ol><li>Successes in non-overlapping subintervals are independent of each other.</li><li>The probability of exactly one success in a sufficiently small interval of length h is proportional to h.  In notation, P(one success) = <m>\lambda h</m>.</li><li>The probability of two or more successes in a sufficiently small interval is essentially 0.</li></ol>
</p></statement></definition>
</p>
        <p>
You should presume these assumptions implicitly for the distributions discussed in this chapter.
</p>
        <p>
In this chapter, you will investigate the following distributions:
<ol><li>Poisson - the interval is fixed and X measures the variable number of successes.</li><li>Exponential - the number of successes is fixed--at 1--and X measures the variable interval length needed to get that success.</li><li>Gamma - the number of successes is fixed and X measures the variable interval needed to get the desired number of successes.</li></ol>
</p>
      </section>
      <section>
        <title>Poisson Distribution</title>
        <p>
Consider a Poisson Process where you start with an interval of fixed length T and where X measures the variable number of successes, or changes, within that interval. The resulting distribution of X will be called a Poisson distribution.
</p>
        <p>
<theorem><title>Poisson Probability Function</title><statement><p>Assume X measures the number of successes in an interval [0,T] within some Poisson process. Then, 
<me>f(x) = \frac{\mu^x e^{-\mu}}{x!}</me>
for <m>R = \{ 0, 1, 2, ... \}</m>.
</p></statement><proof><p>
For a sufficiently large natural number n, break up the given interval [0,T] into n uniform parts each of width h = T/n.  Using the properties of Poisson processes, n very large implies h will be very small and eventually small enough so that 
<me>P(\text{exactly one success on a given interval}) = p = \lambda \frac{T}{n}.</me> 

However, since there are a finite number of independent intervals each with probability p of containing a success then you can use a Binomial distribution to evaluate the corresponding probabilities so long as n is finite. Doing so yields and taking the limit as n approaches infinity gives:
<md><mrow>f(x) &amp; = P(\text{x changes in [0,T]}) </mrow><mrow> &amp; = \lim_{n \rightarrow \infty} \binom{n}{x} p^x (1-p)^{n-x}</mrow><mrow> &amp; = \lim_{n \rightarrow \infty} \binom{n}{x} (\frac{\lambda T}{n})^x (1-\frac{\lambda T}{n})^{n-x}</mrow><mrow> &amp; = \lim_{n \rightarrow \infty} \frac{n(n-1)...(n-x+1)}{x!} ( \frac{\lambda T}{n})^x (1- \frac{\lambda T}{n})^{n-x}</mrow><mrow> &amp; = \frac{(\lambda T)^x}{x!} \lim_{n \rightarrow \infty} \frac{n(n-1)...(n-x+1)}{n \cdot n \cdot ... \cdot n} (1-\lambda \frac{T}{n})^{n}(1-\lambda \frac{T}{n})^{-x}</mrow><mrow> &amp; = \frac{(\lambda T)^x}{x!} \lim_{n \rightarrow \infty} (1-\frac{1}{n})...(1-\frac{x-1}{n})  (1- \frac{\lambda T}{n})^{n}(1- \frac{\lambda T}{n})^{-x}</mrow><mrow> &amp; = \frac{(\lambda T)^x}{x!} 
	\lim_{n \rightarrow \infty} (1- \frac{\lambda T}{n})^{n}
	\lim_{n \rightarrow \infty} (1- \frac{\lambda T}{n})^{-x}</mrow><mrow> &amp; = \frac{(\lambda T)^x}{x!} 
	\lim_{n \rightarrow \infty} (1- \frac{\lambda T}{n})^{n} \cdot 1</mrow><mrow> &amp; = \frac{(\lambda T)^x}{x!} 
	e^{-\lambda T}</mrow></md>
</p></proof></theorem>
</p>
        <p>
<theorem><title>Verify Poisson Probability Function</title><statement><p>
	<me>\sum_{x=0}^{\infty} \frac{(\lambda T)^x}{x!} e^{-\lambda T} = 1</me>
</p></statement><proof><p>Using the Power Series expansion for the natural exponential,
<md><mrow> \sum_{x=0}^{\infty} f(x) &amp; = \sum_{x=0}^{\infty} \frac{(\lambda T)^x}{x!} e^{-\lambda T} </mrow><mrow> &amp; = e^{-\lambda T} \sum_{x=0}^{\infty} \frac{(\lambda T)^x}{x!} </mrow><mrow> &amp; = e^{-\lambda T} e^{\lambda T}  </mrow><mrow> &amp; = 1</mrow></md>
</p></proof></theorem>
</p>
        <p>
<example><title>Router Requests</title><p>
Everyone using the internet utilizes a series of "routers" who spend their time waiting for someone to show up and ask for something to be done. Let's consider one such router which, over time, has been shown to receive on average 1000 such requests in any given 10 minute period during regular working hours. In general, a Poisson process with mean 1000 would seem to fit and therefore the Poisson distribution would be a good model. We will find out below that <m>\lambda T = \mu = 1000</m> and will use that here to get 
<me> f(x) = \frac{1000^x}{x!} e^{-1000}.</me>
</p><p>
So, suppose we would like to know the likelihood of receiving exactly 1020 requests in a 10 minute time interval.  This means we need
<me>P(X = 1020) = f(1020) = \frac{1000^{1020}}{1020!} e^{-1000}</me>
which might be totally impossible to compute directly using a regular calculator. However, many graphing calculators have a built-in function where f(x) = poissonpdf(mu,x) and F(x) = poissoncdf(mu,x). To answer our question,
<me> f(1020) = \text{poissonpdf(1000,1020)} \approx 0.01024.</me>

On the other hand, suppose the question is to ask whether 1020 or fewer requests wil be made in the 10 minute interval. If so, then
<me> F(1020) = \text{poissoncdf(1000,1020)} \approx 0.74258.</me> 
</p></example>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		This one uses the poisson distribution.
		</p></introduction><webwork-reps xml:id="extracted-webwork-28" ww-id="webwork-28">
    <pg source="Library/UBC/STAT/STAT302/HW06/HW06-03.pg"/>

      
    <static source="Library/UBC/STAT/STAT302/HW06/HW06-03.pg" seed="28">
      <statement><p>Customers arrive at a grocery store at an average of 1.8 per minute. Assume that the number of arrivals in a minute follows the Poisson distribution. Provide answers to the following to 3 decimal places.</p><p><em> Part a) </em></p><p>What is the probability that exactly two customers arrive in a minute?</p><p><fillin name="AnSwEr0001" characters="6"/></p><p><em> Part b) </em></p><p>Find the probability that more than three customers arrive in a two-minute period.</p><p><fillin name="AnSwEr0002" characters="6"/></p><p><em> Part c) </em></p><p>What is the probability that at least seven customers arrive in three minutes, given that exactly two arrive in the first minute?</p><p><fillin name="AnSwEr0003" characters="6"/></p></statement>
      
      <solution><p><em> Part a) </em></p><p>Let <m>X</m> be the number of customers arriving in a one-minute interval. Then <m>X \sim Po(1.8),</m> and</p><p><m>\Pr(X = 2) = \frac{\text{e}^{-1.8} 1.8^2}{2!}</m>
      <m>= 0.268.</m></p><p><em> Part b) </em></p><p>If <m>Y</m> denotes the number of customers arriving in a two-minute interval, then <m>Y \sim Po(2 \times 1.8),</m> and <m>\Pr(Y &gt; 3) = 1 - \Pr(Y \leq 3) = 0.000.</m> Via R:</p><p>ppois(3, lambda=3.6, lower.tail=FALSE)</p><p><em> Part c) </em></p><p>For <m>i = 1, 2, 3,</m> let <m>X_i</m> be the number of customers arriving in minute <m>i</m>. These variables are independent, since counts in a Poisson process over non-overlapping intervals are independent; moreover <m>X \sim Po(1.8).</m> Hence</p><p><m>\begin{align*} \Pr(X_1 + X_2 + X_3 \geq 7 | X_1 = 2) \amp = \frac{\Pr(X_1 + X_2 + X_3 \geq 7, X_1 = 2)}{\Pr(X_1 = 2)} \\ \amp = \frac{\Pr(X_2 + X_3 \geq 5) \Pr(X_1 = 2)}{\Pr(X_1 = 2)} \\ \amp = \Pr(X_2 + X_3 \geq 5) \\ \amp = \Pr(Y \geq 5) \end{align*}</m></p><p>where <m>Y \sim Po(3.6)</m> as in part b. The result is <m>0.000.</m> Via R:</p><p>ppois(4, 3.6, lower.tail=FALSE)</p></solution>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=28&amp;sourceFilePath=Library/UBC/STAT/STAT302/HW06/HW06-03.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=28&amp;sourceFilePath=Library/UBC/STAT/STAT302/HW06/HW06-03.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=28&amp;sourceFilePath=Library/UBC/STAT/STAT302/HW06/HW06-03.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=28&amp;sourceFilePath=Library/UBC/STAT/STAT302/HW06/HW06-03.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<theorem><title>Statistics for Poisson</title><statement><p>
<me>\mu = \lambda T</me>
<me>\sigma^2 = \mu</me>
<me>\gamma_1 = \frac{1}{\sqrt{\mu}}</me>
<me>\gamma_2 = \frac{1}{\mu}+3</me>
</p></statement><proof><p> Using the f(x) generated in the previous theorem
<md><mrow>\mu &amp; = E[X] </mrow><mrow> &amp; = \sum_{x=0}^{\infty} x \cdot \frac{(\lambda T)^x}{x!} e^{-\lambda T}</mrow><mrow> &amp; = \lambda T e^{-\lambda T} \sum_{x=1}^{\infty} \frac{(\lambda T)^{x-1}}{(x-1)!} </mrow><mrow> &amp; = \lambda T e^{-\lambda T} \sum_{k=0}^{\infty} \frac{(\lambda T)^k}{k!} </mrow><mrow> &amp; = \lambda T e^{-\lambda T} e^{\lambda T} </mrow><mrow> &amp; = \lambda T </mrow></md>
which confirms the use of <m>\mu</m> in the original probability formula.
</p><p>
Continuing with <m>\mu = \lambda T</m>, the variance is given by
<md><mrow>\sigma^2 &amp; = E[X(X-1)] + \mu - \mu^2 </mrow><mrow> &amp; = \sum_{x=0}^{\infty} x(x-1) \cdot \frac{\mu^x}{x!} e^{-\mu} + \mu - \mu^2</mrow><mrow> &amp; = e^{-\mu} \mu^2 \sum_{x=2}^{\infty} \frac{\mu^{x-2}}{(x-2)!} + \mu - \mu^2</mrow><mrow> &amp; = e^{-\mu} \mu^2 \sum_{k=0}^{\infty} \frac{\mu^k}{k!} + \mu - \mu^2</mrow><mrow> &amp; = \mu^2 + \mu - \mu^2 </mrow><mrow> &amp; = \mu</mrow></md>

To derive the skewness and kurtosis, you can depend upon Sage...see the live cell below.
</p></proof></theorem>
</p>
        <p>
<sage><input>
var('x,mu')
assume(x,'integer')

f(x) =e^(-mu)*mu^x/factorial(x)
mu = sum(x*f,x,0,oo).factor()
M2 = sum(x^2*f,x,0,oo).factor()
M3 = sum(x^3*f,x,0,oo).factor()
M4 = sum(x^4*f,x,0,oo).factor()

pretty_print('Mean = ',mu)

v = (M2-mu^2).factor()
pretty_print('Variance = ',v)
stand = sqrt(v)

sk = ((M3 - 3*M2*mu + 2*mu^3)).factor()/stand^3
pretty_print('Skewness = ',sk)

kurt = (M4 - 4*M3*mu + 6*M2*mu^2 -3*mu^4).factor()/stand^4
pretty_print('Kurtosis = ',(kurt-3).factor(),'+3')
	</input></sage>
</p>
        <p>
<sage language="r"><input>
mu = 3           # the mean must be given
sdev = sqrt(mu)  # the formula for the standard deviation

M = mu*6   # the space is infinite but we just go out 6 standard deviations
X = 0:M    # part of the space R of the random variable 
if(M &lt; 101){
dpois( X, mu, log = FALSE )   # let's print out a bunch of actual probs if M reasonable
}

Ppois = dpois(X, mu )  # create the probability function over X

Psample = rpois(10^6, mu)  # to create a histogram, sample a lot
Xtop=max(Psample)          # for scaling the x-axis. Shift by 1/2 below.
hist(Psample, prob=TRUE, br=(-1:Xtop)+0.5, col="skyblue2", xlab="X", 
  main="Poisson Probability Function vs Approximating 'Bell Curve'")

points(X, Ppois, pch=19, col="darkgreen")  # to create actual (x,f(x))

Pnormal &lt;- function(X){dnorm(X, mean=mu, sd=sdev)}   # to overlap a bell curve
curve(Pnormal, col="red", lwd=2, add=TRUE) 
</input></sage>
</p>
      </section>
      <section>
        <title>Exponential Distribution</title>
        <p>
Once again, consider a Poisson Process where you start with an interval of variable length X so that X measures the interval needed in order to obtain a first success with <m>R = (0,\infty)</m>. The resulting distribution of X will be called an Exponential distribution.
	</p>
        <p>
To derive the probability function for this distribution, consider finding f(x) by first considering F(x). This gives

<md><mrow>F(x)&amp;  = P(X \le x)</mrow><mrow> &amp; = 1 - P(X \gt x)</mrow><mrow> &amp; = 1 - P(\text{first change occurs after an interval of length x})</mrow><mrow> &amp; = 1 - P(\text{no changes in the interval [0,x]})</mrow><mrow> &amp; = 1 - \frac{(\lambda x)^0 e^{-\lambda x}}{0!}</mrow><mrow> &amp; = 1 - e^{-\lambda x}</mrow></md>
where the discrete Poisson Probability Function is used to answer the probability of exactly no changes in the "fixed" interval [0,x]. Using this distribution function and taking the derivative yields
<me>f(x) = F'(x) = \lambda e^{-\lambda x}.</me>
</p>
        <p>
<definition><title>Exponential Distribution Probability Function</title><statement><p>Given a Poisson process and a constant <m>\mu</m>, suppose X measures the variable interval length needed until you get a first success.  Then X has an exponential distribution with probability function
		<me>f(x) = \frac{1}{\mu} e^{-\frac{x}{\mu}}.</me>
	</p></statement></definition>
</p>
        <p>
<example><title>Router Requests Revisited</title><p>
Once again, let's consider a router which, over time, has been shown to receive on average 1000 such requests in any given 10 minute period during regular working hours. This would mean that, on average, it would take <m>\mu = \frac{10}{1000} = \frac{1}{100} = 0.01</m> minutes (i.e., less than a second) to receive the first request. If X were to measure the time interval until the first actual request comes in, then the Exponential distribution would be a good model using 
<me> f(x) = \frac{1}{0.01} e^{-\frac{x}{0.01}}.</me>
</p><p>
Let's determine the probability that a first request arrives in the next two seconds. First, note that since X is a continuous variable that f(x) is NOT the probability of exactly X minutes but you must integrate to compute all probabilities. Also, the next 2 seconds is actually the next <m>\frac{2}{60} = \frac{1}{30}</m> of a minute. Therefore, F(x) is what you need in general and you find
<me>P(X \le \frac{1}{30}) = F(\frac{1}{30}) = 1 - e^{-\frac{\frac{1}{30}}{0.01}} \approx 0.96433.</me> 
</p></example>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		This one uses the exponential distribution.
		</p></introduction><webwork-reps xml:id="extracted-webwork-29" ww-id="webwork-29">
    <pg source="Library/Rochester/setProbability14ExponentialDist/ur_pb_14_1.pg"/>

      
    <static source="Library/Rochester/setProbability14ExponentialDist/ur_pb_14_1.pg" seed="29">
      <statement><p>Suppose that the time (in hours) required to repair a machine is an exponentially distributed random variable with
      parameter <m>\lambda = 0.2</m>. What is</p><p>(a) the probability that a repair takes less than <m>3</m> hours? <fillin name="AnSwEr0001" characters="20"/></p><p>(b) the conditional probability that a repair takes at least <m>7</m> hours, given that it takes more than <m>4</m> hours?
      <fillin name="AnSwEr0002" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=29&amp;sourceFilePath=Library/Rochester/setProbability14ExponentialDist/ur_pb_14_1.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=29&amp;sourceFilePath=Library/Rochester/setProbability14ExponentialDist/ur_pb_14_1.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=29&amp;sourceFilePath=Library/Rochester/setProbability14ExponentialDist/ur_pb_14_1.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=29&amp;sourceFilePath=Library/Rochester/setProbability14ExponentialDist/ur_pb_14_1.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<theorem><title>Verification of Exponential Probability Function</title><statement><p>
		<me>\int_0^{\infty} \frac{1}{\mu} e^{-\frac{x}{\mu}} dx = 1</me>
	</p></statement><proof><p>
		<md><mrow> &amp; \int_0^{\infty} \frac{1}{\mu} e^{-\frac{x}{\mu}} dx</mrow><mrow> &amp; = \int_0^{\infty} e^{-u} dx</mrow><mrow> &amp; = -e^{-u} \big |_0^{\infty} = 1</mrow></md>
		</p></proof></theorem>
</p>
        <p>
<theorem><title>Distribution function for Exponential Distribution</title><statement><p>
		<me>F(x) = 1 - e^{-\frac{x}{\mu}}</me>
	</p></statement><proof><p>
	Using <m>f(x) = \frac{1}{\mu} e^{-\frac{x}{\mu}}</m>, note
	<md><mrow>F(x) &amp; = \int_0^x \frac{1}{\mu} e^{-\frac{u}{\mu}} du</mrow><mrow> &amp; =  - e^{-\frac{u}{\mu}} \big |_0^x</mrow><mrow> &amp; = 1 - e^{-\frac{x}{\mu}}</mrow></md>
	</p></proof></theorem>
</p>
        <p>
<theorem><title>Derivation of Statistics for Exponential Distribution and Plotting</title><statement><p>
	<me>\sigma^2 = \mu^2</me>
	<me>\gamma_1 = 2</me>
	<me>\gamma_2 = 9</me>
	</p></statement><proof><p>
	For the mean, notice that
	<md><mrow>\text{Mean} &amp; = \int_0^{\infty} x \cdot \frac{1}{\mu} e^{-\frac{x}{\mu}} </mrow><mrow> &amp; = [ (1-x) e^{-\frac{x}{\mu}} ] \big |_0^{\infty} = \mu</mrow></md>
	and so the use of <m>\mu</m> in f(x) is warranted.
	</p><p>
	The remaining statistics are derived similarly using repeated integration by parts. The interactive Sage cell below calculates those for you automatically.
	</p></proof></theorem>
</p>
        <p>
<sage><input>
# Exponential Distribution
var('x,mu')
assume(mu&gt;0)

f(x) =e^(-x/mu)/mu
mu = integral(x*f,x,0,oo).factor()
M2 = integral(x^2*f,x,0,oo).factor()
M3 = integral(x^3*f,x,0,oo).factor()
M4 = integral(x^4*f,x,0,oo).factor()

pretty_print('Mean = ',mu)

v = (M2-mu^2).factor()
pretty_print('Variance = ',v)
stand = sqrt(v)

sk = (((M3 - 3*M2*mu + 2*mu^3))/stand^3).simplify()
pretty_print('Skewness = ',sk)

kurt = (M4 - 4*M3*mu + 6*M2*mu^2 -3*mu^4).factor()/stand^4
pretty_print('Kurtosis = ',(kurt-3).factor(),'+3')
@interact
def _(m = slider(1,12,1/2,2,label='mu')):
    plot(f(mu=m),x,0,30).show(ymax=1)
	</input></sage>
</p>
        <p>
<sage language="r"><input>
r=1                # the number of successes desired
            # the mean till first must be given
mu = 3
sdev = sqrt(mu)  # the formula for the standard deviation

M = mu*3   # the space is infinite but we just go out 3 standard deviations
X = 0:M    # quantiles for the space R of the random variable 

Pexp &lt;- function(x){dexp(x, mu )}  # create the probability function over X

curve(Pexp, from=0, to=M, xlab="X", col="blue", lwd=3,
 main="Gamma Sampling vs Gamma Curve vs Approximating 'Bell Curve'") 
Pnormal &lt;- function(X){dnorm(X, mean=mu, sd=sdev)}   # to overlap a bell curve
curve(Pnormal, col="red", lwd=2, add=TRUE) 

Psample = rexp(10^6, mu)  # to create a histogram, sample a lot
# Xtop=max(Psample)          # for scaling the x-axis. Shift by 1/2 below.
hist(Psample, prob=TRUE, add=TRUE)
</input></sage>
</p>
        <p>
<theorem><title>The Exponential Distribution yields a continuous memoryless model.</title><statement><p>
	If X has an exponential distribution and a and b are nonnegative integers, then
	<me>P( X &gt; a + b | X &gt; b ) = P( X &gt; a)</me>
	</p></statement><proof><p>Using the definition of conditional probability,
	<md><mrow>P( X &gt; a + b | X &gt; b ) &amp; = P( X &gt; a + b \cap X &gt; b ) \ P( X &gt; b)</mrow><mrow> &amp; = P( X &gt; a + b ) / P( X &gt; b)</mrow><mrow> &amp; = e^{-(a+b)/ \mu} / e^{-b / \mu}</mrow><mrow> &amp; = e^{-a/ \mu}</mrow><mrow> &amp; = P(X &gt; a)</mrow></md>
	</p></proof></theorem>
</p>
        <!--
Adapted from "Library/UBC/STAT/STAT241_251/setAssignment-04/HW04-01.pg"
-->
        <p>
<exercise><webwork-reps xml:id="extracted-webwork-30" ww-id="webwork-30">
    <authored>
      
        <setup><pg-code>
          </pg-code></setup>
        <statement><p>
      It can be presumed that the life span in years of a certain brand of lightbulbs follows the Poisson process assumptions.  Suppose that the mean life span till failure is known to be 0.7 years. A tester makes random observations of the life times of this particular brand of lightbulbs and records them one by one as either a success if the life time exceeds 1 year, or as a failure otherwise.
      </p><p>
      Determine the probability that a randomly tested bulb lasts more than 1 year:
      <var name="0.2397" width="10"/>
      </p><p>
      Determine probability that the first success occurs in the fifth observation: <var name="0.0801" width="10"/>
      </p><p>  
      Determine the probability that the second success occurs in the 8th observation given that the first success occurred in the 3rd observation:  <var name="0.0801" width="10"/>
      </p><p>
      Determine the probability that the first success occurs in an odd-numbered observation: <var name="0.5681" width="10"/>
      </p></statement>
        <hint><p>
      Use the exponential distribution to get the first answer. Use the geometric to get the remainder.
      </p></hint>
        <solution><p>Using the exponential distribution, 
      <me>p = P(X \gt 1) = 1 - F(1) = 1 - (1-e^{-\frac{1}{0.7}}) \approx 0.2397.</me>
      </p><p>
      Now, use the geometric distribution with <m>p = 0.2397</m>...
      <me>P(X = 5) = f(5) = (1-0.2397)^4 \cdot 0.2397 \approx 0.0801.</me>
      <me>P(\text{2nd success on 8} | \text{1st success on 3}) = P(X = 5) \approx 0.0801</me>
      <me>P(\text{1st success on an odd trial}) = f(1) + f(3) + f(5) + ... \\ 
        = p + (1-p)^2 \cdot p + (1-p)^4 \cdot p + (1-p)^6 \cdot p + ... \\
        = p \sum_{x=0}^{\infty} \left ( (1-p)^2 \right)^k = p \frac{1}{1-(1-p)^2} \approx 0.5681</me>
      </p></solution>
      
    </authored>

    <pg>
      #######################################
      ###    Generated from PreTeXt source   
      ###    on 2018-11-07T13:06:50-06:00    
      ###                                    
      ###   http://mathbook.pugetsound.edu   
      ###                                    
      #######################################
      ## DBsubject()
      ## DBchapter()
      ## DBsection()
      ## Level()
      ## KEYWORDS()
      ## TitleText1(Essentials of Mathematical Probability and Statistics)
      ## EditionText1()
      ## AuthorText1(John Travis)
      ## Section1(not reported)
      ## Problem1(8.3.8)
      ## Author()
      ## Institution()
      ## Language(en-US)
      
      DOCUMENT();
      
      ############################################################
      # Load Macros
      ############################################################
      loadMacros(
        "PGstandard.pl",
        "MathObjects.pl",
        "PGML.pl",
        "AnswerFormatHelp.pl",
        "PGcourse.pl",
      );
      
      ############################################################
      # Header
      ############################################################
      COMMENT('Authored in PreTeXt');
      TEXT(beginproblem());
      
      ############################################################
      # PG Setup
      ############################################################
      Context('Numeric');
      
      ############################################################
      # Body
      ############################################################
      
      BEGIN_PGML
      It can be presumed that the life span in years of a certain brand of lightbulbs follows the Poisson process assumptions.  Suppose that the mean life span till failure is known to be 0.7 years. A tester makes random observations of the life times of this particular brand of lightbulbs and records them one by one as either a success if the life time exceeds 1 year, or as a failure otherwise.
      
      Determine the probability that a randomly tested bulb lasts more than 1 year: [__________]{0.2397}
      
      Determine probability that the first success occurs in the fifth observation: [__________]{0.0801}
      
      Determine the probability that the second success occurs in the 8th observation given that the first success occurred in the 3rd observation:  [__________]{0.0801}
      
      Determine the probability that the first success occurs in an odd-numbered observation: [__________]{0.5681}
      
      END_PGML
      
      ############################################################
      # Hint
      ############################################################
      #Set value of $showHint in PGcourse.pl for course-wide attempt threshhold for revealing hints
      
      BEGIN_PGML_HINT
      Use the exponential distribution to get the first answer. Use the geometric to get the remainder.
      
      END_PGML_HINT
      
      ############################################################
      # Solution
      ############################################################
      
      BEGIN_PGML_SOLUTION
      Using the exponential distribution,
      
      [```\newcommand{\gt}{&gt;}p = P(X \gt 1) = 1 - F(1) = 1 - (1-e^{-\frac{1}{0.7}}) \approx 0.2397.```]
      
      Now, use the geometric distribution with [`p = 0.2397\text{...}`]
      
      [```P(X = 5) = f(5) = (1-0.2397)^4 \cdot 0.2397 \approx 0.0801.```]
      
      [```P(\text{2nd success on 8} | \text{1st success on 3}) = P(X = 5) \approx 0.0801```]
      
      [```P(\text{1st success on an odd trial}) = f(1) + f(3) + f(5) + ... \\ 
        = p + (1-p)^2 \cdot p + (1-p)^4 \cdot p + (1-p)^6 \cdot p + ... \\
        = p \sum_{x=0}^{\infty} \left ( (1-p)^2 \right)^k = p \frac{1}{1-(1-p)^2} \approx 0.5681```]
      
      END_PGML_SOLUTION
      
      ############################################################
      # End Problem
      ############################################################
      
      ENDDOCUMENT();
      
    </pg>

      
    <static seed="30">
      <statement><p>It can be presumed that the life span in years of a certain brand of lightbulbs follows the Poisson process assumptions.  Suppose that the mean life span till failure is known to be 0.7 years. A tester makes random observations of the life times of this particular brand of lightbulbs and records them one by one as either a success if the life time exceeds 1 year, or as a failure otherwise.</p><p>Determine the probability that a randomly tested bulb lasts more than 1 year: <fillin name="AnSwEr0001" characters="10"/></p><p>Determine probability that the first success occurs in the fifth observation: <fillin name="AnSwEr0002" characters="10"/></p><p>Determine the probability that the second success occurs in the 8th observation given that the first success occurred in the 3rd observation:  <fillin name="AnSwEr0003" characters="10"/></p><p>Determine the probability that the first success occurs in an odd-numbered observation: <fillin name="AnSwEr0004" characters="10"/></p></statement>
      
      <hint><p>Use the exponential distribution to get the first answer. Use the geometric to get the remainder.</p></hint>
      
      <solution><p>Using the exponential distribution,</p><p><me>p = P(X \gt 1) = 1 - F(1) = 1 - (1-e^{-\frac{1}{0.7}}) \approx 0.2397.</me></p><p>Now, use the geometric distribution with <m>p = 0.2397\text{...}</m></p><p><me>P(X = 5) = f(5) = (1-0.2397)^4 \cdot 0.2397 \approx 0.0801.</me></p><p><me>P(\text{2nd success on 8} | \text{1st success on 3}) = P(X = 5) \approx 0.0801</me></p><p><me>P(\text{1st success on an odd trial}) = f(1) + f(3) + f(5) + ... \\ 
        = p + (1-p)^2 \cdot p + (1-p)^4 \cdot p + (1-p)^6 \cdot p + ... \\
        = p \sum_{x=0}^{\infty} \left ( (1-p)^2 \right)^k = p \frac{1}{1-(1-p)^2} \approx 0.5681</me></p></solution>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=30&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGd0fXs%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</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=30&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGd0fXs%2BfVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkl0IGNhbiBiZSBwcmVzdW1lZCB0aGF0IHRoZSBsaWZlIHNwYW4gaW4geWVhcnMgb2YgYSBjZXJ0YWluIGJyYW5kIG9mIGxpZ2h0YnVsYnMgZm9sbG93cyB0aGUgUG9pc3NvbiBwcm9jZXNzIGFzc3VtcHRpb25zLiAgU3VwcG9zZSB0aGF0IHRoZSBtZWFuIGxpZmUgc3BhbiB0aWxsIGZhaWx1cmUgaXMga25vd24gdG8gYmUgMC43IHllYXJzLiBBIHRlc3RlciBtYWtlcyByYW5kb20gb2JzZXJ2YXRpb25zIG9mIHRoZSBsaWZlIHRpbWVzIG9mIHRoaXMgcGFydGljdWxhciBicmFuZCBvZiBsaWdodGJ1bGJzIGFuZCByZWNvcmRzIHRoZW0gb25lIGJ5IG9uZSBhcyBlaXRoZXIgYSBzdWNjZXNzIGlmIHRoZSBsaWZlIHRpbWUgZXhjZWVkcyAxIHllYXIsIG9yIGFzIGEgZmFpbHVyZSBvdGhlcndpc2UuCgpEZXRlcm1pbmUgdGhlIHByb2JhYmlsaXR5IHRoYXQgYSByYW5kb21seSB0ZXN0ZWQgYnVsYiBsYXN0cyBtb3JlIHRoYW4gMSB5ZWFyOiBbX19fX19fX19fX117MC4yMzk3fQoKRGV0ZXJtaW5lIHByb2JhYmlsaXR5IHRoYXQgdGhlIGZpcnN0IHN1Y2Nlc3Mgb2NjdXJzIGluIHRoZSBmaWZ0aCBvYnNlcnZhdGlvbjogW19fX19fX19fX19dezAuMDgwMX0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCB0aGUgc2Vjb25kIHN1Y2Nlc3Mgb2NjdXJzIGluIHRoZSA4dGggb2JzZXJ2YXRpb24gZ2l2ZW4gdGhhdCB0aGUgZmlyc3Qgc3VjY2VzcyBvY2N1cnJlZCBpbiB0aGUgM3JkIG9ic2VydmF0aW9uOiAgW19fX19fX19fX19dezAuMDgwMX0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCB0aGUgZmlyc3Qgc3VjY2VzcyBvY2N1cnMgaW4gYW4gb2RkLW51bWJlcmVkIG9ic2VydmF0aW9uOiBbX19fX19fX19fX117MC41NjgxfQoKCkVORF9QR01MCgpCRUdJTl9QR01MX0hJTlQKVXNlIHRoZSBleHBvbmVudGlhbCBkaXN0cmlidXRpb24gdG8gZ2V0IHRoZSBmaXJzdCBhbnN3ZXIuIFVzZSB0aGUgZ2VvbWV0cmljIHRvIGdldCB0aGUgcmVtYWluZGVyLgoKCkVORF9QR01MX0hJTlQKCkVORERPQ1VNRU5UKCk7</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=30&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGd0fXs%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%3D%3D</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=30&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGd0fXs%2BfVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkl0IGNhbiBiZSBwcmVzdW1lZCB0aGF0IHRoZSBsaWZlIHNwYW4gaW4geWVhcnMgb2YgYSBjZXJ0YWluIGJyYW5kIG9mIGxpZ2h0YnVsYnMgZm9sbG93cyB0aGUgUG9pc3NvbiBwcm9jZXNzIGFzc3VtcHRpb25zLiAgU3VwcG9zZSB0aGF0IHRoZSBtZWFuIGxpZmUgc3BhbiB0aWxsIGZhaWx1cmUgaXMga25vd24gdG8gYmUgMC43IHllYXJzLiBBIHRlc3RlciBtYWtlcyByYW5kb20gb2JzZXJ2YXRpb25zIG9mIHRoZSBsaWZlIHRpbWVzIG9mIHRoaXMgcGFydGljdWxhciBicmFuZCBvZiBsaWdodGJ1bGJzIGFuZCByZWNvcmRzIHRoZW0gb25lIGJ5IG9uZSBhcyBlaXRoZXIgYSBzdWNjZXNzIGlmIHRoZSBsaWZlIHRpbWUgZXhjZWVkcyAxIHllYXIsIG9yIGFzIGEgZmFpbHVyZSBvdGhlcndpc2UuCgpEZXRlcm1pbmUgdGhlIHByb2JhYmlsaXR5IHRoYXQgYSByYW5kb21seSB0ZXN0ZWQgYnVsYiBsYXN0cyBtb3JlIHRoYW4gMSB5ZWFyOiBbX19fX19fX19fX117MC4yMzk3fQoKRGV0ZXJtaW5lIHByb2JhYmlsaXR5IHRoYXQgdGhlIGZpcnN0IHN1Y2Nlc3Mgb2NjdXJzIGluIHRoZSBmaWZ0aCBvYnNlcnZhdGlvbjogW19fX19fX19fX19dezAuMDgwMX0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCB0aGUgc2Vjb25kIHN1Y2Nlc3Mgb2NjdXJzIGluIHRoZSA4dGggb2JzZXJ2YXRpb24gZ2l2ZW4gdGhhdCB0aGUgZmlyc3Qgc3VjY2VzcyBvY2N1cnJlZCBpbiB0aGUgM3JkIG9ic2VydmF0aW9uOiAgW19fX19fX19fX19dezAuMDgwMX0KCkRldGVybWluZSB0aGUgcHJvYmFiaWxpdHkgdGhhdCB0aGUgZmlyc3Qgc3VjY2VzcyBvY2N1cnMgaW4gYW4gb2RkLW51bWJlcmVkIG9ic2VydmF0aW9uOiBbX19fX19fX19fX117MC41NjgxfQoKCkVORF9QR01MCgpFTkRET0NVTUVOVCgpOw%3D%3D</server-url>

  </webwork-reps></exercise>
</p>
      </section>
      <section>
        <title>Gamma Distribution</title>
        <p>
Extending the exponential distribution model developed above, consider a Poisson Process where you start with an interval of variable length X so that X measures the interval needed in order to obtain the rth success for some natural number r. Then <m>R = (0,\infty)</m> and the resulting distribution of X will be called a Gamma distribution.
</p>
        <p>
<definition><title>Gamma Function</title><statement><p>
	<me>\Gamma(t) = \int_0^{\infty} u^{t-1} e^{-u} du</me>
	</p></statement></definition>
</p>
        <p>
<theorem><title>Gamma Function on the natural numbers</title><statement><p>
For <m>n \in \mathbb{N}</m>,
<me>\Gamma(n+1) = n!</me>
</p></statement><proof><p>
Letting n be a natural number and applying integration by parts one time gives
<md><mrow>\Gamma(n+1) &amp; = \int_0^{\infty} u^n e^{-u} du</mrow><mrow> &amp; = -u^n \cdot e^{-u} \big |_0^{\infty} + n \int_0^{\infty} u^{n-1} e^{-u} du </mrow><mrow> &amp; = 0 - 0 + n \Gamma(n)</mrow></md>
Continuing using an inductive argument to obtain the final result.
</p></proof></theorem>
</p>
        <p>To find the probability function for the gamma distribution, once again focus on the development of F(x). Assuming r is a natural number greater than 1 and noting that X measures the interval length needed in order to achieve the rth success
<md><mrow>F(x) &amp; = P(X \le x)</mrow><mrow> &amp; = 1 - P(X \gt x)</mrow><mrow> &amp; = 1 - P(\text{fewer than r successes in [0,x]})</mrow><mrow> &amp; = 1 - \big [ \frac{(\lambda x)^0 e^{-\lambda x}}{0!} + \frac{(\lambda x)^1 e^{-\lambda x}}{1!} + ... + \frac{(\lambda x)^{r-1} e^{-\lambda x}}{(r-1)!} \big ]</mrow><mrow> &amp; = 1 - \sum_{k=0}^{r-1} \frac{(\lambda x)^k e^{-\lambda x}}{k!} </mrow></md>
where the discrete Poisson probability function is used on the interval [0,x]. The derivative of this function however is "telescoping" and terms cancel. Indeed,
<md><mrow>F'(x) &amp; = \lambda e^{-\lambda x}/0!</mrow><mrow> &amp; - \lambda e^{-\lambda x}/1! + \lambda x \cdot \lambda e^{-\lambda x}/1!</mrow><mrow> &amp; - \lambda^2 2x e^{-\lambda x}/2! + \lambda^2 x^2 \cdot \lambda e^{-\lambda x}/2!</mrow><mrow> &amp; - \lambda^3 3x^2 e^{-\lambda x}/3! + \lambda^3 x^3 \cdot \lambda e^{-\lambda x}/3!</mrow><mrow> &amp; . . .</mrow><mrow> &amp; - \lambda^{r-1} (r-1)x^{r-2} e^{-\lambda x}/(r-1)! + \lambda^{r-1} x^{r-1} \cdot \lambda e^{-\lambda x}/(r-1)!</mrow><mrow> &amp; = \lambda^r x^{r-1} e^{-\lambda x}/(r-1)!</mrow></md>
where you can replace <m>(r-1)! = \Gamma(r)</m>.
</p>
        <p>
Notice that for this random variable, <m>\mu = \lambda T</m> can be obtained for the exponential distribution. For the Gamma distribution, the following takes <m>\mu</m> to be the average interval till the first success and then modifies the corresponding Gamma parameters according to increasing values of r.
</p>
        <p>
<definition><title>Gamma Distribution Probability Function</title><statement><p>
If X measures the interval until the rth success and <m>\mu</m> as the average interval until the 1st success, then X with probability function
<me>f(x) =  \frac{x^{r-1} \cdot e^{-\frac{x}{\mu}}}{\Gamma(r) \cdot \mu^r}</me>
has a Gamma Distribution.
</p></statement></definition>
</p>
        <p>
<exercise><webwork-reps xml:id="extracted-webwork-31" ww-id="webwork-31">
    <authored>
      
        <setup><pg-code>
          </pg-code></setup>
        <statement><p>
      It can be presumed that the life span in years of a certain brand of lightbulbs follows the Poisson process assumptions.  Suppose that the mean life span till failure is known to be 0.7 years. To do long-term study, a series of light bulbs are arranged so that when the first one fails, the next one comes on, etc.
      </p><p>
      Determine the probability that it takes at most 3.5 years before the 4th bulb fails:
      <var name="0.73497" width="10"/>
      </p></statement>
        <solution><p>
      This is a gamma distribution with r = 4 and
      <me>F(x) = 1 - \sum_{k=0}^3 \frac{ (x/0.7)^k e^{-x/0.7}}{k!}</me>
      So, 
      <md><mrow>P(X \lt 3.5) &amp; = F(3.5)</mrow><mrow> &amp; = 1 - \frac{ (3.5/0.7)^0 e^{-3.5/0.7}}{0!} \\ - \frac{ (3.5/0.7)^1 e^{-3.5/0.7}}{1!} \\ - \frac{ (3.5/0.7)^2 e^{-3.5/0.7}}{2!} - \frac{ (3.5/0.7)^3 e^{-3.5/0.7}}{3!}</mrow><mrow> &amp; = 1 - e^{-5} - 5 \cdot e^{-5} - \frac{25}{2} \cdot e^{-5} - \frac{125}{6} \cdot e^{-5}</mrow><mrow> &amp; = 1 - e^{-5} \left ( 1 + 5 + 25/2 + 125/6 \right ) \approx 0.73497.</mrow></md>
      </p></solution>
      
    </authored>

    <pg>
      #######################################
      ###    Generated from PreTeXt source   
      ###    on 2018-11-07T13:06:50-06:00    
      ###                                    
      ###   http://mathbook.pugetsound.edu   
      ###                                    
      #######################################
      ## DBsubject()
      ## DBchapter()
      ## DBsection()
      ## Level()
      ## KEYWORDS()
      ## TitleText1(Essentials of Mathematical Probability and Statistics)
      ## EditionText1()
      ## AuthorText1(John Travis)
      ## Section1(not reported)
      ## Problem1(8.4.4)
      ## Author()
      ## Institution()
      ## Language(en-US)
      
      DOCUMENT();
      
      ############################################################
      # Load Macros
      ############################################################
      loadMacros(
        "PGstandard.pl",
        "MathObjects.pl",
        "PGML.pl",
        "AnswerFormatHelp.pl",
        "PGcourse.pl",
      );
      
      ############################################################
      # Header
      ############################################################
      COMMENT('Authored in PreTeXt');
      TEXT(beginproblem());
      
      ############################################################
      # PG Setup
      ############################################################
      Context('Numeric');
      
      ############################################################
      # Body
      ############################################################
      
      BEGIN_PGML
      It can be presumed that the life span in years of a certain brand of lightbulbs follows the Poisson process assumptions.  Suppose that the mean life span till failure is known to be 0.7 years. To do long-term study, a series of light bulbs are arranged so that when the first one fails, the next one comes on, etc.
      
      Determine the probability that it takes at most 3.5 years before the 4th bulb fails: [__________]{0.73497}
      
      END_PGML
      
      ############################################################
      # Solution
      ############################################################
      
      BEGIN_PGML_SOLUTION
      This is a gamma distribution with r = 4 and
      
      [```F(x) = 1 - \sum_{k=0}^3 \frac{ (x/0.7)^k e^{-x/0.7}}{k!}```]
      
      So,
      
      [```\newcommand{\lt}{&lt;}\begin{aligned}
      P(X \lt 3.5) &amp; = F(3.5)\\
       &amp; = 1 - \frac{ (3.5/0.7)^0 e^{-3.5/0.7}}{0!} \\ - \frac{ (3.5/0.7)^1 e^{-3.5/0.7}}{1!} \\ - \frac{ (3.5/0.7)^2 e^{-3.5/0.7}}{2!} - \frac{ (3.5/0.7)^3 e^{-3.5/0.7}}{3!}\\
       &amp; = 1 - e^{-5} - 5 \cdot e^{-5} - \frac{25}{2} \cdot e^{-5} - \frac{125}{6} \cdot e^{-5}\\
       &amp; = 1 - e^{-5} \left ( 1 + 5 + 25/2 + 125/6 \right ) \approx 0.73497.
      \end{aligned}```]
      
      END_PGML_SOLUTION
      
      ############################################################
      # End Problem
      ############################################################
      
      ENDDOCUMENT();
      
    </pg>

      
    <static seed="31">
      <statement><p>It can be presumed that the life span in years of a certain brand of lightbulbs follows the Poisson process assumptions.  Suppose that the mean life span till failure is known to be 0.7 years. To do long-term study, a series of light bulbs are arranged so that when the first one fails, the next one comes on, etc.</p><p>Determine the probability that it takes at most 3.5 years before the 4th bulb fails: <fillin name="AnSwEr0001" characters="10"/></p></statement>
      
      <solution><p>This is a gamma distribution with r = 4 and</p><p><me>F(x) = 1 - \sum_{k=0}^3 \frac{ (x/0.7)^k e^{-x/0.7}}{k!}</me></p><p>So,</p><p><me>\begin{aligned}
      P(X \lt 3.5) \amp  = F(3.5)\\
       \amp  = 1 - \frac{ (3.5/0.7)^0 e^{-3.5/0.7}}{0!} \\ - \frac{ (3.5/0.7)^1 e^{-3.5/0.7}}{1!} \\ - \frac{ (3.5/0.7)^2 e^{-3.5/0.7}}{2!} - \frac{ (3.5/0.7)^3 e^{-3.5/0.7}}{3!}\\
       \amp  = 1 - e^{-5} - 5 \cdot e^{-5} - \frac{25}{2} \cdot e^{-5} - \frac{125}{6} \cdot e^{-5}\\
       \amp  = 1 - e^{-5} \left ( 1 + 5 + 25/2 + 125/6 \right ) \approx 0.73497.
      \end{aligned}</me></p></solution>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=31&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGx0fXs8fVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkl0IGNhbiBiZSBwcmVzdW1lZCB0aGF0IHRoZSBsaWZlIHNwYW4gaW4geWVhcnMgb2YgYSBjZXJ0YWluIGJyYW5kIG9mIGxpZ2h0YnVsYnMgZm9sbG93cyB0aGUgUG9pc3NvbiBwcm9jZXNzIGFzc3VtcHRpb25zLiAgU3VwcG9zZSB0aGF0IHRoZSBtZWFuIGxpZmUgc3BhbiB0aWxsIGZhaWx1cmUgaXMga25vd24gdG8gYmUgMC43IHllYXJzLiBUbyBkbyBsb25nLXRlcm0gc3R1ZHksIGEgc2VyaWVzIG9mIGxpZ2h0IGJ1bGJzIGFyZSBhcnJhbmdlZCBzbyB0aGF0IHdoZW4gdGhlIGZpcnN0IG9uZSBmYWlscywgdGhlIG5leHQgb25lIGNvbWVzIG9uLCBldGMuCgpEZXRlcm1pbmUgdGhlIHByb2JhYmlsaXR5IHRoYXQgaXQgdGFrZXMgYXQgbW9zdCAzLjUgeWVhcnMgYmVmb3JlIHRoZSA0dGggYnVsYiBmYWlsczogW19fX19fX19fX19dezAuNzM0OTd9CgoKRU5EX1BHTUwKCkJFR0lOX1BHTUxfU09MVVRJT04KVGhpcyBpcyBhIGdhbW1hIGRpc3RyaWJ1dGlvbiB3aXRoIHIgPSA0IGFuZAoKW2BgYEYoeCkgPSAxIC0gXHN1bV97az0wfV4zIFxmcmFjeyAoeC8wLjcpXmsgZV57LXgvMC43fX17ayF9YGBgXQoKU28sCgpbYGBgXGJlZ2lue2FsaWduZWR9ClAoWCBcbHQgMy41KSAmID0gRigzLjUpXFwKICYgPSAxIC0gXGZyYWN7ICgzLjUvMC43KV4wIGVeey0zLjUvMC43fX17MCF9IFxcIC0gXGZyYWN7ICgzLjUvMC43KV4xIGVeey0zLjUvMC43fX17MSF9IFxcIC0gXGZyYWN7ICgzLjUvMC43KV4yIGVeey0zLjUvMC43fX17MiF9IC0gXGZyYWN7ICgzLjUvMC43KV4zIGVeey0zLjUvMC43fX17MyF9XFwKICYgPSAxIC0gZV57LTV9IC0gNSBcY2RvdCBlXnstNX0gLSBcZnJhY3syNX17Mn0gXGNkb3QgZV57LTV9IC0gXGZyYWN7MTI1fXs2fSBcY2RvdCBlXnstNX1cXAogJiA9IDEgLSBlXnstNX0gXGxlZnQgKCAxICsgNSArIDI1LzIgKyAxMjUvNiBccmlnaHQgKSBcYXBwcm94IDAuNzM0OTcuClxlbmR7YWxpZ25lZH1gYGBdCgoKCgpFTkRfUEdNTF9TT0xVVElPTgoKRU5ERE9DVU1FTlQoKTs%3D</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=31&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGx0fXs8fVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkl0IGNhbiBiZSBwcmVzdW1lZCB0aGF0IHRoZSBsaWZlIHNwYW4gaW4geWVhcnMgb2YgYSBjZXJ0YWluIGJyYW5kIG9mIGxpZ2h0YnVsYnMgZm9sbG93cyB0aGUgUG9pc3NvbiBwcm9jZXNzIGFzc3VtcHRpb25zLiAgU3VwcG9zZSB0aGF0IHRoZSBtZWFuIGxpZmUgc3BhbiB0aWxsIGZhaWx1cmUgaXMga25vd24gdG8gYmUgMC43IHllYXJzLiBUbyBkbyBsb25nLXRlcm0gc3R1ZHksIGEgc2VyaWVzIG9mIGxpZ2h0IGJ1bGJzIGFyZSBhcnJhbmdlZCBzbyB0aGF0IHdoZW4gdGhlIGZpcnN0IG9uZSBmYWlscywgdGhlIG5leHQgb25lIGNvbWVzIG9uLCBldGMuCgpEZXRlcm1pbmUgdGhlIHByb2JhYmlsaXR5IHRoYXQgaXQgdGFrZXMgYXQgbW9zdCAzLjUgeWVhcnMgYmVmb3JlIHRoZSA0dGggYnVsYiBmYWlsczogW19fX19fX19fX19dezAuNzM0OTd9CgoKRU5EX1BHTUwKCkVORERPQ1VNRU5UKCk7</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=31&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGx0fXs8fVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkl0IGNhbiBiZSBwcmVzdW1lZCB0aGF0IHRoZSBsaWZlIHNwYW4gaW4geWVhcnMgb2YgYSBjZXJ0YWluIGJyYW5kIG9mIGxpZ2h0YnVsYnMgZm9sbG93cyB0aGUgUG9pc3NvbiBwcm9jZXNzIGFzc3VtcHRpb25zLiAgU3VwcG9zZSB0aGF0IHRoZSBtZWFuIGxpZmUgc3BhbiB0aWxsIGZhaWx1cmUgaXMga25vd24gdG8gYmUgMC43IHllYXJzLiBUbyBkbyBsb25nLXRlcm0gc3R1ZHksIGEgc2VyaWVzIG9mIGxpZ2h0IGJ1bGJzIGFyZSBhcnJhbmdlZCBzbyB0aGF0IHdoZW4gdGhlIGZpcnN0IG9uZSBmYWlscywgdGhlIG5leHQgb25lIGNvbWVzIG9uLCBldGMuCgpEZXRlcm1pbmUgdGhlIHByb2JhYmlsaXR5IHRoYXQgaXQgdGFrZXMgYXQgbW9zdCAzLjUgeWVhcnMgYmVmb3JlIHRoZSA0dGggYnVsYiBmYWlsczogW19fX19fX19fX19dezAuNzM0OTd9CgoKRU5EX1BHTUwKCkJFR0lOX1BHTUxfU09MVVRJT04KVGhpcyBpcyBhIGdhbW1hIGRpc3RyaWJ1dGlvbiB3aXRoIHIgPSA0IGFuZAoKW2BgYEYoeCkgPSAxIC0gXHN1bV97az0wfV4zIFxmcmFjeyAoeC8wLjcpXmsgZV57LXgvMC43fX17ayF9YGBgXQoKU28sCgpbYGBgXGJlZ2lue2FsaWduZWR9ClAoWCBcbHQgMy41KSAmID0gRigzLjUpXFwKICYgPSAxIC0gXGZyYWN7ICgzLjUvMC43KV4wIGVeey0zLjUvMC43fX17MCF9IFxcIC0gXGZyYWN7ICgzLjUvMC43KV4xIGVeey0zLjUvMC43fX17MSF9IFxcIC0gXGZyYWN7ICgzLjUvMC43KV4yIGVeey0zLjUvMC43fX17MiF9IC0gXGZyYWN7ICgzLjUvMC43KV4zIGVeey0zLjUvMC43fX17MyF9XFwKICYgPSAxIC0gZV57LTV9IC0gNSBcY2RvdCBlXnstNX0gLSBcZnJhY3syNX17Mn0gXGNkb3QgZV57LTV9IC0gXGZyYWN7MTI1fXs2fSBcY2RvdCBlXnstNX1cXAogJiA9IDEgLSBlXnstNX0gXGxlZnQgKCAxICsgNSArIDI1LzIgKyAxMjUvNiBccmlnaHQgKSBcYXBwcm94IDAuNzM0OTcuClxlbmR7YWxpZ25lZH1gYGBdCgoKCgpFTkRfUEdNTF9TT0xVVElPTgoKRU5ERE9DVU1FTlQoKTs%3D</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=31&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtsb2FkTWFjcm9zKCJQQ0NtYWNyb3MucGwiKTsKVEVYVChLZXlib2FyZEluc3RydWN0aW9ucyhxQFwoXG5ld2NvbW1hbmR7XGx0fXs8fVwpQCkpOwpDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkl0IGNhbiBiZSBwcmVzdW1lZCB0aGF0IHRoZSBsaWZlIHNwYW4gaW4geWVhcnMgb2YgYSBjZXJ0YWluIGJyYW5kIG9mIGxpZ2h0YnVsYnMgZm9sbG93cyB0aGUgUG9pc3NvbiBwcm9jZXNzIGFzc3VtcHRpb25zLiAgU3VwcG9zZSB0aGF0IHRoZSBtZWFuIGxpZmUgc3BhbiB0aWxsIGZhaWx1cmUgaXMga25vd24gdG8gYmUgMC43IHllYXJzLiBUbyBkbyBsb25nLXRlcm0gc3R1ZHksIGEgc2VyaWVzIG9mIGxpZ2h0IGJ1bGJzIGFyZSBhcnJhbmdlZCBzbyB0aGF0IHdoZW4gdGhlIGZpcnN0IG9uZSBmYWlscywgdGhlIG5leHQgb25lIGNvbWVzIG9uLCBldGMuCgpEZXRlcm1pbmUgdGhlIHByb2JhYmlsaXR5IHRoYXQgaXQgdGFrZXMgYXQgbW9zdCAzLjUgeWVhcnMgYmVmb3JlIHRoZSA0dGggYnVsYiBmYWlsczogW19fX19fX19fX19dezAuNzM0OTd9CgoKRU5EX1BHTUwKCkVORERPQ1VNRU5UKCk7</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<example><title>Router Requests Revisited Again</title><p>
For the third time, let's consider a router which, over time, has been shown to receive on average 1000 requests in any given 10 minute period during regular working hours and you want to know the likelihood that it takes more than 4 seconds in order to receive the 5th request. As you have already seen, it takes on average <m>\frac{10}{1000} = \frac{1}{100} = 0.01</m> minutes to receive the first request so we use that again here. If X were to measure the time interval until the fifth actual request comes in, then the Gamma distribution would be a good model using 
<me>f(x) =  \frac{x^{5-1} \cdot e^{- \frac{x}{0.01}}}{\Gamma(5) \cdot 0.01^5}</me>
</p><p>
The question above asks for
<me>P(X \gt 4 \text{seconds}) = P(X \gt \frac{4}{60} ) = 1 - F(\frac{4}{60}).</me>

Again, since X is a continuous variable you must integrate to compute probabilities. This will require integration by parts or you can use the F(x) from the derivation above. Here, let's just let Sage do the integration for us noting that <m>\Gamma(5) = 4! = 24</m>. You can compute the needed integral using the interactive cell immediately below.
</p></example>
</p>
        <p>
Therefore
<me>P(X \gt 4 \text{seconds}) = 1 - F(\frac{4}{60}) \approx 0.205627.</me>
</p>
        <p>
<sage><input>
var('x')
f = x^4*e^(-x/0.01)/(24*0.01^5)
prob_complement = integrate(f,x,0,4/60)
print n(1-prob_complement)
</input></sage>
</p>
        <p>
<theorem><title>Verify Gamma Probability function</title><statement><p>
<me>\int_0^{\infty} \frac{x^{r-1} e^{-x/ \mu}}{\Gamma(r) \mu^r} dx = 1</me>
</p></statement><proof><p>
Evaluate the sage code below.
</p></proof></theorem>
</p>
        <p>
<sage><input>
# Gamma Distribution
var('x,mu,r')
assume(mu&gt;0)
assume(r,'integer')
assume(r&gt;1)
f(x) =x^(r-1)*e^(-x/mu)/(gamma(r)*mu^r)
S = integral(f,x,0,oo).full_simplify()
F = '$ \int_0^{\infty} \\frac{x^{r-1} e^{-x/ \mu}}{\Gamma(r) \mu^r} dx = %s$'%str(S)
html(F) 
	</input></sage>
</p>
        <p>
<sage><input>
# Gamma Distribution Graphing
var('x,mu,r')
assume(mu&gt;0)
assume(r,'integer')
@interact
def _(r=[2,3,6,12,24],mu=slider(1,12,1,5,label='mu')):
    f(x) =x^(r-1)*e^(-x/mu)/(gamma(r)*mu^r)
    plot(f,x,0,200).show()
    
</input></sage>
</p>
        <p>
Derivation of mean, variance, skewness, and kurtosis. Pick "alpha" for the general formulas.
<sage><input>
# Gamma Distribution
var('x,mu,r,alpha')
assume(mu&gt;0)
assume(alpha,'integer')
assume(alpha&gt;1)
@interact
def _(r=[2,3,6,9,alpha]):
    f(x) =x^(r-1)*e^(-x/mu)/(gamma(r)*mu^r)
    mean = integral(x*f,x,0,oo).full_simplify()
    M2 = integral(x^2*f,x,0,oo).full_simplify()
    M3 = integral(x^3*f,x,0,oo).full_simplify()
    M4 = integral(x^4*f,x,0,oo).full_simplify()
    
    pretty_print('Mean = ',mean)
    
    v = (M2-mean^2).factor()
    pretty_print('Variance = ',v)
    stand = sqrt(v)
    
    sk = (((M3 - 3*M2*mean + 2*mean^3))/stand^3).full_simplify()
    pretty_print('Skewness = ',sk)
    
    kurt = (M4 - 4*M3*mean + 6*M2*mean^2 -3*mean^4).factor()/stand^4
    pretty_print('Kurtosis = ',(kurt-3).factor(),'+3')
	</input></sage>
</p>
        <p>The interactive cell below can be used to compute the distribution function for the gamma distribution for various input values. If you desire to let r get bigger than the slider allows, feel free to edit the cell above and evaluate again.

<sage><input>
# Gamma Distribution Calculator
var('x,mu,r')
pretty_print('Enter the number of successes desired, the given mean, and the value of X to get F(X)')
@interact
def _(r=slider(1,10,1,2),mu = input_box(2,label="$\mu = $",width=10),b=input_box(2,label="X = ",width=10)):
    f(x) =x^(r-1)*e^(-x/mu)/(gamma(r)*mu^r)
    p = integral(f,x,0,b)
    
    pretty_print('Probability = \t',p,' which is approximately \t',p.n(digits=5))
	</input></sage>
</p>
        <p>
<sage language="r"><input>
r=3                # the number of successes desired
mu1 = 3            # the mean till first must be given
mu = mu1*r
sdev = sqrt(r)*mu1  # the formula for the standard deviation

M = mu*3   # the space is infinite but we just go out 3 standard deviations
X = 0:M    # quantiles for the space R of the random variable 

Ppois &lt;- function(x){dgamma(x, shape=r, scale=mu1 )}  # create the probability function over X

curve(Ppois, from=0, to=M, xlab="X", col="blue", lwd=3,
 main="Gamma Sampling vs Gamma Curve vs Approximating 'Bell Curve'") 
Pnormal &lt;- function(X){dnorm(X, mean=mu, sd=sdev)}   # to overlap a bell curve
curve(Pnormal, col="red", lwd=2, add=TRUE) 

Psample = rgamma(10^6, shape=r, scale=mu1)  # to create a histogram, sample a lot
# Xtop=max(Psample)          # for scaling the x-axis. Shift by 1/2 below.
hist(Psample, prob=TRUE, add=TRUE)



</input></sage>
</p>
      </section>
      <section>
        <title>Summary</title>
        <introduction>
          <p>
Here is a summary of the major points in this chapter:
</p>
        </introduction>
        <p>
TBA
</p>
      </section>
      <section>
        <title>Exercises</title>
        <p>
<exercise><title> - Home Sales</title><p>
A local realty office sells on average 10 houses a week.  Let X measure the number of houses the sell in the next week.  Determine
<ol><li>the probability the realty office sells 12 houses next week.</li><li>the probability the realty office sells fewer than 10 houses next week.</li><li>the interval <m>\mu - 2\sigma \le X \le \mu + 2\sigma</m>.</li><li><m>P(\mu - 2\sigma \le X \le \mu + 2\sigma)</m>.</li></ol>
</p></exercise>
</p>
        <p>
<exercise><title> - Customer arrivals - Total</title><p>
Customers arrive at your store on the average of 10 per hour.  Assuming that the arrival of customers satisfies the properties of a Poisson process, determine:
<ol><li>the expected number of customers to arrive in a given 3 hour period.</li><li>the probability that fewer than 10 customers arrive in a given hour.</li></ol>
<solution><p>
Using the given information, apply the Poisson distribution.  For one hour <m>\mu = 10</m> so that for three hours the expected number of customers would be triple with 30 expected customers.
</p><p>
With <m>\mu_1 = 10</m>, 
<md><mrow>P(X \lt 10) &amp; = F(9)</mrow><mrow> &amp; = \frac{10^0 e^{-10}}{0!} + \frac{10^1 e^{-10}}{1!} + \frac{10^2 e^{-10}}{2!} + ... + \frac{10^8 e^{-10}}{8!} + \frac{10^9 e^{-10}}{9!}</mrow><mrow>&amp; = e^{-10} \cdot ( 1 + 10 + \frac{100}{2} + ... + \frac{10^8}{8!} + \frac{10^9}{9!} )</mrow></md>
</p></solution>
</p></exercise>
</p>
        <p>
<exercise><title> - Customer arrivals - First</title><p>
Customers arrive at your store on the average of 10 per hour.  Assuming that the arrival of customers satisfies the properties of a Poisson process, determine:
<ol><li>the number of minutes expected between the arrival of each customer</li><li>the probability it takes more than 9 minutes before the next customer arrives.</li></ol>
<solution><p>
Using the given information, apply the exponential distribution.  Since 10 arrive on average in one hour then you would expect 1 to arrive in 6 minutes.
</p><p>
With <m>\mu = 6</m> minutes, 
<me>P(X \gt 9) = 1 - F(9) = e^{-9/6}.</me>
</p></solution>
</p></exercise>
</p>
        <p>
<exercise><title> - Customer arrivals - 10th</title><p>
Customers arrive at your store on the average of 10 per hour.  Assuming that the arrival of customers satisfies the properties of a Poisson process, determine:
<ol><li>the number of minutes expected for the arrival of three customers.</li><li>the probability it takes less than 20 minutes before the third customer arrives.</li></ol>
<solution><p>
Using the given information, apply the gamma distribution.  Since 10 arrive on average in one hour then you would expect 1 to arrive in 6 minutes and therefore 3 to arrive on average in 18 minutes.
</p><p>
With <m>\mu = 18</m> minutes, 
<me>P(X \lt 20) = F(20).</me>
</p></solution>
</p></exercise>
</p>
        <p>
<exercise><title>Approximating Binomial with Poisson</title>
In our derivation above, we used the limit of a Binomial probability function to create the Poisson's probability function. Therefore, for large n the two should be computationally very close.  Use this fact to approximate P(X &gt; 10000) for a Binomial distribution with n = 40000 and p = 1/4 by converting to a Poisson probability function. 
<hint><p>
First determine the mean <m>\mu</m> for the binomial. Use this mean as the input for the Poisson distribution function.
</p></hint><solution><p>
From the formula, <m>\mu = np = 40000 \cdot \frac{1}{4} = 10000</m>. So, using Poisson's probability function
<me>f_{\text{Poisson}} = \frac{10000^{x}}{x!}e^{-10000}</me>
would require you to compute 
<me>e^{-10000} \sum_{x=10000}^{\infty} \frac{10000^{x}}{x!}</me>
which is also a mess. However with a computational resource such as a graphing calculator, just compare 1 - binomcdf(40000,0.25,9999) to 1-poissoncdf(10000,9999) noting that the complement of the given question is from X from 0 to 9999. The two values should be relatively close
</p><p>
This approximation method is not completely satisfactory since both being discrete distributions with no nice distribution function formulas require summations to accumulate. We have seen however that both the Poisson and the Binomial probability functions start to have a bell-shape as <m>\mu</m> increases for the Poisson and as n increases (i.e. and therefore <m>\mu</m> increases) for the Binomial. Hence, we will eventually approximate with each of these using the (continuous) bell-shaped distribution--the normal distribution discussed later--for which instead of accumulating probability function values we integrate them.  
</p></solution></exercise>
</p>
        <p>
<exercise><title> - Computer Network Data Traffic</title><p>
Consider the arrival of requests on a server. Presume that the requests are considered as coming from an anonymous and large collection of users independently of each other on an average of 50 requests per second. If X measures the number of requests per second, determine
<ol><li>the probability that in any given second the server gets fewer than 50 requests</li><li><m>P(\mu - 2\sigma \le X \le \mu + 2\sigma)</m></li><li>the expected number of requests per hour.</li></ol>

<solution><p>
Given the average of 50 requests per second and X measuring the number of "successes" in a given second long time interval given a Poission distribution
<me>f(x) = \frac{50^x}{x!}e^{-50}.</me>
Then,
<me>P(X \lt 50) = F(49) = \sum_{x=0}^{49} \frac{50^x}{x!} e^{-50}</me>
and using the graphing calculator function poissoncdf(50,49) = 0.48119.
</p><p>
For a time interval of one second, the mean is given to be 50 requests. Using the formulas developed above, the standard deviation therefore is <m>\sqrt{50}</m>. Therefore
<md><mrow>P(\mu - 2\sigma \le X \le \mu + 2\sigma) &amp; = P(50 - 2\sqrt{50} \le X \le 50 + 2\sqrt{50})</mrow><mrow> &amp; = P(X \in \{ 36, 37, 38, ..., 62, 63, 64 \}).</mrow></md>
Using the distribution function,
	<me>F(64) - F(35) \approx 0.97640 - 0.01621 = 0.96019</me>
</p><p>
Finally, notice that the time interval has been adjusted. Since the mean formula is proportional to the interval over which X is measured, using <m>\mu = \lambda T</m> with <m>\lambda = 1</m> when the interval is 1 second, then when the interval is one hour, T = 3600 seconds. Hence, we would expect on average <m>50 \cdot 3600 = 180,000</m> requests in one hour.
</p></solution>
</p></exercise>
</p>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="Normal">
      <title>Normal Distributions</title>
      <section>
        <title>Introduction</title>
        <p>
You should have noticed by now that many distributions tend to have a bell-shaped graph as parameters are allowed to increase. Indeed, the formulas for skewness <m>\gamma_1</m> and kurtosis <m>\gamma_2</m> approach 0 and 3 respectively for the Hypergeometric, Binomial, Negative Binomial, Poisson, and Gamma Distributions. One might wonder if this is just a happy coincidence or is something more insidious at play. 
</p>
        <p>
The answer by appealing to mathematics reveals that nothing sinister is going on but that it is indeed true that the eventual destiny for distributions is one that is bell-shaped. It is therefore of interest to figure out if that distribution has a nice form that can be accessed directly. The focus of this chapter is to consider this bell-shaped goal known as the "normal distribution."
</p>
        <p>
We present the normal distribution by simply presenting it's probability function without derivation. In order to more carefully investigate the development of the normal distribution (and the Chi-Square Distribution) you will need to study "Moment Generating Functions" and some serious mathematics. Without supplying this rigor you can still utilize the results. 
</p>
      </section>
      <section>
        <title>The Normal Distribution</title>
        <p>
<definition><title>The Normal Distribution</title><statement><p>
	Given two parameters <m>\mu</m> and <m>\sigma</m>, a random variable X over <m>R = (-\infty,\infty)</m> has a normal distribution provided it has a probability function given by
		<me>
		f(x) = \frac{1}{\sigma \sqrt{2 \pi}} e^{ -\left ( \frac{x-\mu}{\sigma} \right ) ^2 / 2}
		</me>
	</p></statement></definition>
</p>
        <p>
The normal distribution is also sometimes referred to as the Gaussian Distribution (often by Physicists) or the Bell Curve (often by social scientists).
</p>
        <p>
<sage><input>
var('x,mu,sigma')
f(x) = e^(-((x-mu)/sigma)^2/2)/(sigma*sqrt(2*pi))
@interact
def _(m=slider(-10,10,1,0,label='$\mu$'),s=slider(1/5,5,1/10,1,label='$\sigma$')):
    titletext = "Normal Curve with mean "+str(m)+" and standard deviation "+str(s)
    G = plot(f(mu=m,sigma=s),(x,m-5*s,m+5*s))
    G += point((0,1),size=1)+point((12,0),size=1)+point((-12,0),size=1)
    G += point((m,f(x=m,mu=m,sigma=s)),color='red',size=20)
    G += point((m+s,f(x=m+s,mu=m,sigma=s)),color='green',size=20)
    G += point((m-s,f(x=m-s,mu=m,sigma=s)),color='green',size=20)    
    show(G,figsize=(5,3),title=titletext,ymin=0,ymax=1,xmin=-15,xmax=15)
    </input></sage>
</p>
        <p>
<theorem><statement><p>
If <m>\mu = 0</m> and <m>\sigma = 1</m>, then we say X has a standard normal distribution and often use Z as the variable name and will use <m>\Phi(z)</m> for the standard normal distribution function. In this case, the density function reduces to
		<me>f(z) = \frac{1}{\sqrt{2 \pi}} e^{ -z^2 / 2}</me>
</p></statement><proof><p>Convert to "standard units" using the conversion 
			<me>z = \frac{x-\mu}{\sigma} = \frac{x-0}{1} = x.</me>
		</p></proof></theorem>
</p>
        <p>
<theorem><title>Verifying the normal probability function</title><statement><p>
		<me>\int_{-\infty}^{\infty} \frac{1}{\sigma \sqrt{2 \pi}} e^{ -\left ( \frac{x-\mu}{\sigma} \right ) ^2 / 2} dx = 1</me>
		</p></statement><proof><p>
Note that you can convert the integral above to <xref ref="StandardUnitConversion">standard units</xref> so that it is sufficient to show
<me>I = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi}} e^{ -\frac{z^2}{2} } dz = 1</me>
Toward this end, consider <m>I^2</m> and change the variables to get
<md><mrow>I^2 &amp; = \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi}} e^{ -\frac{u^2}{2} } du \cdot \int_{-\infty}^{\infty} \frac{1}{\sqrt{2 \pi}} e^{ -\frac{v^2}{2} } dv</mrow><mrow>&amp; = \frac{1}{2 \pi} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{ -\frac{u^2+v^2}{2} } du dv</mrow></md>
Converting to polar coordinates using 
<me> du dv = r dr d\theta </me> and
<me> u^2 + v^2 = r^2</me>
gives
<md><mrow>I^2 &amp; = \frac{1}{2 \pi} \int_0^{2 \pi} \int_0^{\infty} e^{ -\frac{r^2}{2} } r dr d\theta</mrow><mrow> &amp; = \frac{1}{2 \pi} \int_0^{2 \pi} -e^{ -\frac{r^2}{2} } \big |_0^{\infty} d\theta</mrow><mrow> &amp; = \frac{1}{2 \pi} \int_0^{2 \pi} 1 \cdot d\theta</mrow><mrow> &amp; = \frac{1}{2 \pi} \theta \big |_0^{2 \pi} = 1</mrow></md>
as desired.
</p></proof></theorem>
</p>
        <p>
<theorem><title>Verifying the normal probability mean</title><statement><p>
		<me>E[X] = \int_{-\infty}^{\infty} x \cdot \frac{1}{\sigma \sqrt{2 \pi}} e^{ - \left ( \frac{x-\mu}{\sigma} \right ) ^2 / 2} dx = \mu</me>
		</p></statement><proof><p>
	<me>z = \frac{x-\mu}{\sigma}</me>
	implies by solving that
	<me> x = \mu + z \sigma</me>
	and therefore
<md><mrow>E[X] &amp;= \int_{-\infty}^{\infty} x \cdot \frac{1}{\sigma \sqrt{2 \pi}} e^{ - \left ( \frac{x-\mu}{\sigma} \right ) ^2 / 2} dx </mrow><mrow> &amp;= \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} (\mu + z\sigma) \cdot e^{ -z^2 / 2} dz</mrow><mrow> &amp;= \mu \cdot \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} e^{ -z^2 / 2} dz + \sigma \cdot \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} z \cdot e^{ -z^2 / 2} dz</mrow><mrow> &amp;= \mu \cdot 1 + \sigma \cdot 0</mrow><mrow> &amp; = \mu</mrow></md>
	and therefore the use of <m>\mu</m> is warranted.
	</p></proof></theorem>
</p>
        <p>
<theorem><title>Verifying the normal probability variance</title><statement><p>
		<me>E[(X-\mu)^2] = \int_{-\infty}^{\infty} (x-\mu)^2 \cdot \frac{1}{\sigma \sqrt{2 \pi}} e^{ - \left ( \frac{x-\mu}{\sigma} \right ) ^2 / 2} dx = \sigma^2</me>
	</p></statement><proof><p>
	<md><mrow>E[(X-\mu)^2] &amp; = \int_{-\infty}^{\infty} (x-\mu)^2 \cdot \frac{1}{\sigma \sqrt{2 \pi}} e^{ - \left ( \frac{x-\mu}{\sigma} \right ) ^2 / 2} dx</mrow><mrow> &amp; = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} \sigma^2 z^2 \cdot  e^{ -z^2 / 2} dz</mrow><mrow> &amp; = \frac{\sigma^2}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} z \cdot z e^{ -z^2 / 2} dz</mrow><mrow> &amp; = \frac{\sigma^2}{\sqrt{2 \pi}} \cdot \big [ -z e^{-z^2 / 2} \big |_{-\infty}^{\infty} + \int_{-\infty}^{\infty}  e^{ -z^2 / 2}  dz \big ]</mrow><mrow> &amp; = \frac{\sigma^2}{\sqrt{2 \pi}} \cdot \big [ 0 + \sqrt{2 \pi} \big ]</mrow><mrow> &amp; = \sigma^2 </mrow></md>
	using integration by parts and using the integration in the proof of the mean above.  So, the use of <m>\sigma</m> is warranted.
	</p></proof></theorem>
</p>
        <p>	
<theorem><title>Properties of the Normal Distribution</title><statement>
TBA	
</statement></theorem>
</p>
        <p>
<theorem><title>Normal Distribution Maximum</title><statement><p>The maximum of the normal distribution probability function occurs when <m>x = \mu</m>
	</p></statement><proof><p>Take the derivative of the probability function to get 
	<me>\frac{\sqrt{2} {\left(\mu - x\right)} e^{\left(-\frac{{\left(\mu - x\right)}^{2}}{2 \, \sigma^{2}}\right)}}{2 \, \sqrt{\pi} \sigma^{3}}</me>
	which is zero only when <m>x = \mu</m>.  Easily by evaluating to the left and right of this value shows that this critical value yields a maximum.
	</p></proof></theorem>
</p>
        <p>
<theorem><title>Normal Distribution Points of Inflection</title><statement><p>Points of Inflection for the normal distribution probability function occurs when <m>x = \mu + \sigma</m> and <m>x = \mu - \sigma</m>.
	</p></statement><proof><p>Take the second derivative of the probability function to get 
	<me>\frac{\sqrt{2} {\left(\mu + \sigma - x\right)} {\left(\mu - \sigma - x\right)} e^{\left(-\frac{\mu^{2}}{2 \, \sigma^{2}} + \frac{\mu x}{\sigma^{2}} - \frac{x^{2}}{2 \, \sigma^{2}}\right)}}{2 \, \sqrt{\pi} \sigma^{5}}</me>
	which is zero only when <m>x = \mu \pm \sigma</m>.  Easily by evaluating to the left and right of this value shows that these critical values yield points of inflection.
	</p></proof></theorem>
</p>
        <p>
Notice that the work needed to complete the integrals over the entire domain above was pretty serious. To determine probabilities for a given interval is however not possible in general and therefore approximations are needed. When using TI graphing calculators, you can use 
<me>P( a \lt x \lt b ) = \text{normalcdf}(a,b,\mu, \sigma).</me>
Or you can use the calculator below.
</p>
        <p>
<sage><input>
@interact(layout=dict(top=[['a', 'b']],bottom=[['mu','sigma']]))
def _(a=input_box(-2,width=10,label='a = '),b=input_box(2,width=10,label='b = '),mu=input_box(0,width=8,label='$\mu = $'),sigma=input_box(1,width=8,label='$\sigma = $')):
    f = e^(-((x-mu)/sigma)^2/2)/(sigma*sqrt(2*pi))
    P = integral_numerical(f,a,b)[0]
    print "P("+str(a)+" &lt; X &lt; "+str(b)+") ~= "+str(P)
	</input></sage>
</p>
      </section>
      <section>
        <title>Chi-Square Distribution</title>
        <p>The following distribution is related to both the Normal Distribution and to the Gamma Distribution. Initially, consider a gamma distribution with probability function
	
	<me>\frac{x^{r-1} \cdot e^{-x / \mu}}{\Gamma(r) \cdot \mu^r}.</me>

Replacing <m>\mu = 2</m> and r with r/2 gives

	<me>\frac{x^{r/2-1} \cdot e^{-x/2}}{\Gamma(r/2) \cdot 2^{r/2}}</me>

which is given a special name below.
</p>
        <p>
<definition><title>Chi-Square Probability Function</title><statement>Given an natural number r, suppose X is a random variable over the space <m>R = (0,\infty)</m> with probability function given by
	<me>f(x) = \frac{x^{r/2-1} e^{-x/2} }{\Gamma(r/2) 2^{r/2}}.</me>
	Then X has a Chi-Square distribution with r degrees of freedom. This is often denoted <m>\chi^2(r)</m>.
</statement></definition>
</p>
        <p>
<sage><input>
# Chi-Square Grapher
@interact
def _(r=slider(1,20,1,3,label='r =')):
    f = x^(r/2-1)*e^(-x/2)/(gamma(r/2)*2^(r/2))
    plot(f,x,0,20).show()
	</input></sage>
</p>
        <p>
<theorem><title><m>\chi^2</m> statistics</title><statement><me>\mu = r</me><me>\sigma^2 = 2r</me><me>\gamma_1 = 2 \sqrt{2/r}</me><me>\gamma_2 = \frac{12}{r} + 3</me></statement></theorem>
</p>
        <p>	
<theorem><title>Relationship between Normal and <m>\chi^2</m></title><statement>
	If <m>Z_1, Z_2, ..., Z_r</m> are r standard normal variables, then
	<me> X = \sum_{k=1}^r Z_k^2</me>
	is <m>\chi^2(r)</m>.
</statement></theorem>
</p>
        <p>	
It also can be difficult to compute Chi-Square probabilities manually so you will perhaps want to use a numerical approximation in this case as well. The TI graphing calculator can be used with <m>\chi ^2</m>cdf(a,b,r).  Or, you can use the calculator below.
</p>
        <p>
<sage><input>
# Chi-Square Calculator
@interact(layout=dict(top=[['a', 'b']],bottom=[['r']]))
def _(a=input_box(0,width=10,label='a = '),b=input_box(2,width=10,label='b = '),r=input_box(2,width=8,label='r =')):
    f = x^(r/2-1)*e^(-x/2)/(gamma(r/2)*2^(r/2))
    P = numerical_integral(f,a,b)[0]
    print "P("+str(a)+" &lt; X &lt; "+str(b)+") ~= "+str(P)
    </input></sage>
</p>
      </section>
      <section>
        <title>Other "Bell Shaped" distributions</title>
        <p>The Normal distribution discussed above is very important when doing statistical analysis. It however is not the only distribution that is symmetrical about the mean and looks like a bell.  In this section, we consider two other options--one which is virtually useless and another which is very useful.
</p>
        <p>
<definition><title>The Cauchy Distribution</title><statement><p>
Consider a continuous random variable on the real numbers defined by
<me>f(x) = \frac{1/\pi}{1+x^2}.</me>
A random variable with this probability function is said to be a Cauchy Distribution.
</p></statement></definition>
</p>
        <theorem>
          <title>The Cauchy Distribution</title>
          <statement><me>f(x) = \frac{1/\pi}{1+x^2}</me>
is a probability function on <m>(-\infty, \infty)</m>.
</statement>
          <proof>
Easily, note that 
<me>\int_{-\infty}^{\infty} \frac{1}{1+x^2} dx = arctan(\infty) - arctan(-\infty) = \pi/2 - (-\pi/2) = \pi.</me>
Dividing by <m>\pi</m> gives the Cauchy probability function integrates to 1.
</proof>
        </theorem>
        <sage language="r">
          <input>
n &amp;- 10
p &amp;- 0.3

paste('Probability Function')
dcauchy(x, location = 0, scale = 1, log = FALSE)   # gives the probability function
paste('Distribution function')
pcauchy(q, location = 0, scale = 1, lower.tail = TRUE, log.p = FALSE)
   # gives the distribution function
paste('A random sample')
rcauchy(n, location = 0, scale = 1)    # gives a random sample of 15 items from b(n,p)

x=seq(-4,4,length=200)
y=dcauchy(x,dcauchy(x, location = 0, scale = 1, log = FALSE))
plot(x,y,type="l",lwd=2,col="red",ylab="p")

</input>
        </sage>
        <p>
Now that we have a probability function, it is important to determine its mean and variance. It should be obvious that when doing so using the Cauchy probability function, problems quickly arise.  Indeed,
<me>\int_{-\infty}^{\infty} x \frac{1}{1+x^2} dx = (1/2) ( \ln( | \infty |) - \ln( | -\infty |)</me>
which is problematic.  Further, for the variance
<me>\int_{-\infty}^{\infty} x^2 \frac{1}{1+x^2} dx </me>
and note that the integrand does not converge to 0 at the endpoints and therefore the integral is automatically considered divergent.  Thus it is reasonable to note that the Cauchy distribution has no variance.
</p>
        <p>On the other hand, there is another bell-shaped distribution that is useful and its random variable can be created by using a mixture of a normal variable and a Cauchy variable. Indeed, suppose Z is a standard normal variable and Y is <m>\Chi^2(r)</m> with Y and Z independent.  Define a new random variable
<me>T = \frac{Z}{\sqrt(Y/r)}.</me>
Then, T is said to have a (Student) t distribution.  The good news is that this distribution is useful and its statistics are presented below without proof.

<theorem><title>Student t-distribution</title><statement>For the Student t variable T defined above, 
<me> \mu = 0</me>
and if r&gt;2
<me> \sigma^2 = \frac{r}{r-2}.</me></statement></theorem>
</p>
        <sage language="r">
          <input>
# Display the Student's t distributions with various
# degrees of freedom and compare to the normal distribution
# Copied from www.statmethods.net

x &lt;- seq(-4, 4, length=100)
hx &lt;- dnorm(x)

degf &lt;- c(1, 3, 8, 30)
colors &lt;- c("red", "blue", "darkgreen", "gold", "black")
labels &lt;- c("df=1", "df=3", "df=8", "df=30", "normal")

plot(x, hx, type="l", lty=2, xlab="x value",
  ylab="Density", main="Comparison of t Distributions")

for (i in 1:4){
  lines(x, dt(x,degf[i]), lwd=2, col=colors[i])
}

legend("topright", inset=.05, title="Distributions",
  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)
</input>
        </sage>
      </section>
      <section>
        <title>Normal Distribution as a Limiting Distribution</title>
        <p>Over the past several chapters you should have noticed that many distributions have skewness and kurtosis formulae which have limiting values of 0 and 3 respectively. This means that each of those distributions which can be approximated by the normal distribution for "large" parameter values.
</p>
        <p>To see how this works, consider a "random" distribution in the following two interactive experiments.  For the first graph below, a sequence of N random samples, each of size r, ranging from 0 to "Range" is generated and graphed as small data points.  As the number of samples N and the sample size r increase, notice that the data seems to cover the entire range of possible values relatively uniformly.  (For this scatter plot note that each row represents the data for one sample of size r.  The larger the N, the greater the number of rows.)  Each row is averaged and that mean value is plotted on the graph as a red circle.  If you check the "Show_Mean" box, the mean of these circles is indicated by the green line in the middle of the plot.
</p>
        <p>
For the second graph below, the means are collected and the relative frequency of each is plotted.  As N increases, you should see that the results begin to show an interesting tendency.   As you increase the data range, you may notice this graph has a larger number of data values.  Smoothing groups this data into intervals of length two for perhaps a graph with less variability.
</p>
        <p>
Consider each of the following:
<ul><li>
As N increases with single digit values of r, what appears to happen to the mean and range of the means?  How does increasing the data range from 1-100 to 1-200 or 1-300 affect these results?</li><li>As N increases (say, for a middle value of r), what appears to happen to the means?  How does increasing the data range from 1-100 to 1-200 or 1-300 affect these results?</li><li>As r increases (say, for a middle value of N), what appears to happen to the range of the averages?  Does your conclusion actually depend upon the value of N?  (Look at the graph and don't worry about the actual numerical values.)
How does increasing N for the second graph affect the skewness and kurtosis of that graph?  Do things change significantly as r is increased?  </li></ul>
</p>
        <sage>
          <input>
var('n,k')
from sage.finance.time_series import TimeSeries

@interact(layout=dict(top=[['Range'],['Show_Mean', 'Smoothing']],  
bottom=[['N'],['r']]))

def _(Range=[100,200,300,500],N=slider(5,200,2,2,label="N = Number of Samples"),r=slider(3,200,1,2,label="r = Sample Size"),Show_Mean=False,Smoothing=False):
    R=[1..N]     #  R ranges over the number of samples...will point to the list of averages
    rangemax = Range

    data = random_matrix(ZZ,N,r,x=rangemax)
    datapoints = []
    avg_values = []
    avg_string = []
    averages = []
    for n in range(N):
        temp = 0
        for k in range(r):
            datapoints += [(data[n][k],n)]
            temp += data[n][k]
        avg_values.append(round(temp/r))
        if Smoothing:
            avg_string.append(str(2*round((temp/r)/2)))    
        else:
            avg_string.append(str(round(temp/r)))
            
        averages += [(round(temp/r),n)]   #  make these averages integers for use in grouping later
    SCAT = scatter_plot(datapoints,markersize=2,edgecolor='red',figsize=(10,4),axes_labels=['Sample Values','Sample Number'])
    AVGS = scatter_plot(averages,markersize=50,edgecolor='blue',marker='o',figsize=(7,4))
    
    freqslist = frequency_distribution(avg_string,1).function().items()
       
       
# compute sample statistics for the raw data as well as for the N averages
    Mean_data = (sum(sum(data))/(N*r)).n()
#    STD_data = sqrt(sum(sum( (data-Mean_data)^2 ))/(N*r)).n()
    Mean_averages = mean(avg_values).n()
#    STD_averages = sqrt(variance(avg_values).n())
#    print "Data mean =",Mean_data," vs Mean of the averages =",Mean_averages
#    print "Data STD = ",STD_data," vs Standard Dev of avgs =", STD_averages
    if Show_Mean:
        avg_line = line([(Mean_data,0),(Mean_data,N-1)],rgbcolor='green',thickness=10)
        avg_text = text('xbar',(Mean_data,N),horizontal_alignment='right',rgbcolor='green')
    else:
        avg_line = Graphics()
        avg_text = Graphics()
            
#  Plot a scatter plot exhibiting uniformly random data and the collection of averages 
    print(html("The random data plot on the left with each row representing a sample with size determined by\n"+
         "the slider above and each circle representing the average for that particular sample.\n"+
         "First, keep sample size relatively low and increase the number of samples.  Then, \n"+
         "watch what happens when you slowly increase the sample size."))

    
#  Plot the relative frequencies of the grouped sample averages
    print(html("Now, the averages (ie. the circles) from above are collected and counted\n"+
         "with the relative frequency of each average graphed below.  For a relatively large number of\n"+
         "samples, notice what seems to happen to these averages as the sample size increases."))
    if Smoothing:
        binRange = Range//2
    else:
        binRange = Range
    
    # normed=True  # if you want to have relative frequencies below
    
    his_low = 2*rangemax/7
    his_high = 5*rangemax/7
    
    T = histogram(avg_values,normed=False,bins=binRange,range=(his_low,his_high),axes_labels=['Sample Averages','Frequency']) 
    #T = TimeSeries(avg_values).plot_histogram(axes_labels=['Sample Averages','Frequency'])   
    
    pretty_print('Scatter Plot of random data.  Horizontal is number of samples.')
    (SCAT+AVGS+avg_line+avg_text).show()
    pretty_print('Histogram of Sample Averages')
    T.show(figsize=(5,2))
	</input>
        </sage>
        <sage>
          <input>
var('n,k')
from sage.finance.time_series import TimeSeries

@interact(layout=dict(top=[['Range'],['Show_Mean', 'Smoothing']],  
bottom=[['N'],['r']]))

def _(Range=[100,200,300,500],N=slider(5,200,2,2,label="N = Number of Samples"),r=slider(3,200,1,2,label="r = Sample Size"),Show_Mean=False,Smoothing=False):
    R=[1..N]     #  R ranges over the number of samples...will point to the list of averages
    rangemax = Range

    data = random_matrix(ZZ,N,r,x=rangemax)
    datapoints = []
    avg_values = []
    avg_string = []
    averages = []
    for n in range(N):
        temp = 0
        for k in range(r):
            datapoints += [(data[n][k],n)]
            temp += data[n][k]
        avg_values.append(round(temp/r))
        if Smoothing:
            avg_string.append(str(2*round((temp/r)/2)))    
        else:
            avg_string.append(str(round(temp/r)))
            
        averages += [(round(temp/r),n)]   #  make these averages integers for use in grouping later
    SCAT = scatter_plot(datapoints,markersize=2,edgecolor='red',figsize=(10,4),axes_labels=['Sample Values','Sample Number'])
    AVGS = scatter_plot(averages,markersize=50,edgecolor='blue',marker='o',figsize=(7,4))
    
    freqslist = frequency_distribution(avg_string,1).function().items()
       
       
# compute sample statistics for the raw data as well as for the N averages
    Mean_data = (sum(sum(data))/(N*r)).n()
#    STD_data = sqrt(sum(sum( (data-Mean_data)^2 ))/(N*r)).n()
    Mean_averages = mean(avg_values).n()
#    STD_averages = sqrt(variance(avg_values).n())
#    print "Data mean =",Mean_data," vs Mean of the averages =",Mean_averages
#    print "Data STD = ",STD_data," vs Standard Dev of avgs =", STD_averages
    if Show_Mean:
        avg_line = line([(Mean_data,0),(Mean_data,N-1)],rgbcolor='green',thickness=10)
        avg_text = text('xbar',(Mean_data,N),horizontal_alignment='right',rgbcolor='green')
    else:
        avg_line = Graphics()
        avg_text = Graphics()
            
#  Plot a scatter plot exhibiting uniformly random data and the collection of averages 
    print(html("The random data plot on the left with each row representing a sample with size determined by\n"+
         "the slider above and each circle representing the average for that particular sample.\n"+
         "First, keep sample size relatively low and increase the number of samples.  Then, \n"+
         "watch what happens when you slowly increase the sample size."))

    
#  Plot the relative frequencies of the grouped sample averages
    print(html("Now, the averages (ie. the circles) from above are collected and counted\n"+
         "with the relative frequency of each average graphed below.  For a relatively large number of\n"+
         "samples, notice what seems to happen to these averages as the sample size increases."))
    if Smoothing:
        binRange = Range//2
    else:
        binRange = Range
    
    # normed=True  # if you want to have relative frequencies below
    
    his_low = 2*rangemax/7
    his_high = 5*rangemax/7
    
    T = histogram(avg_values,normed=False,bins=binRange,range=(his_low,his_high),axes_labels=['Sample Averages','Frequency']) 
    #T = TimeSeries(avg_values).plot_histogram(axes_labels=['Sample Averages','Frequency'])   
    
    pretty_print('Scatter Plot of random data.  Horizontal is number of samples.')
    (SCAT+AVGS+avg_line+avg_text).show()
    pretty_print('Histogram of Sample Averages')
    T.show(figsize=(5,2))
	</input>
        </sage>
        <p>
So, even with random data, if you are to consider the arrangement of the collected means rather than the arrangement of the actual data then the means appear to have a bell-shaped distribution as well.
</p>
      </section>
      <section>
        <title>Central Limit Theorem</title>
        <p>
Often, when one wants to solve various scientific problems, several assumptions will be made regarding the nature of the underlying setting and base their conclusions on those assumptions.  Indeed, if one is going to use a Binomial Distribution or a Negative Binomial Distribution, an assumption on the value of p is necessary.  For Poisson and Exponential Distributions, one must know the mean.  For Normal Distributions, one must assume values for both the mean and the standard deviation.   Where do these values come from?  Often, one may perform a preliminary study and obtain a sample statistic...such as a sample mean or a relative frequency and use these values for μ or p.</p>
        <p>
But what is the underlying distribution of these sample statistics?  The Central Limit Theorem gives the answer...</p>
        <p>The results from the previous section illustrate the tendency for bell-shaped distributions. This tendency can be described more mathematically through the following theorem. It is presented here without proof.
</p>
        <theorem>
          <title>Central Limit Theorem</title>
          <statement>
            <p>
	Presume X is a random variable from a distribution with known mean <m>\mu</m> and known variance <m>\sigma_x^2</m>.  
	For some natural number n, sample the distribution repeatedly creating a string of random variables denoted <m>X_1, X_2, ... , X_n</m> and set <m>\overline{X} = \frac{\sum X_k}{n}</m>. 
	</p>
            <p> 
	Then, <m>\overline{X}</m> is approximately normally distributed with mean <m>\mu</m> and variance <m>\sigma^2 = \frac{\sigma_x^2}{n}</m>.
	</p>
          </statement>
        </theorem>
        <p>
Often the Central Limit Theorem is stated more formally using a conversion to standard units. Indeed, the theorem indicates that the random variable <m>\overline{X}</m> has variance <m>\frac{\sigma^2}{n}</m> which means as n grows this variance approaches 0. So, the limiting random variable has a zero variance and therefore is no longer a random variable. To avoid this issue, the Central Limit Theorem is often stated as:
</p>
        <p>For random variables
<me>W_n = \frac{\overline{X} - \mu}{\sigma/ \sqrt{n}}</me>
with corresponding distribution function <m>F_n(W_n)</m>,
<me>\lim_{n \rightarrow \infty} F_n(c) = \int_{-\infty}^c \frac{1}{\sqrt{2 \pi}} e^{-z^2/2} dz = \Phi(c)</me>
that is, the standard normal distribution function.
</p>
        <example>
          <title>Exponential X vs Normal <m>\overline{X}</m></title>
          <p>Consider an exponential variable X with mean time till first success of <m>\mu = 4</m>.  Then, <m>\sigma = 2</m> using the exponential formulas.
</p>
          <p>You can use the exponential probability function to compute probabilities dealing with X. Indeed,
<me>P(X \lt 3.9) = F(3.9) = 1 - e^{-3.9/4} \approx 0.6228 .</me>
</p>
          <p>
If instead you plan to sample from this distribution n=32 times, the Central Limit Theorem implies that you will get a random variable <m>\overline{X}</m> which has an approximate normal distribution with the same mean but with new variance <m>\sigma_{\overline{X}}^2 = \frac{4}{32} = \frac{1}{8}</m>.  Therefore
<me>P( \overline{X} \lt 3.9 ) \approx normalcdf(0,3.9,4,sqrt(1/8)) = 0.2119 .</me>
</p>
        </example>
        <p>When converting probability problems from continuous (such as exponential or uniform) then no adjustment to the question is needed since you are approximating one area with another area. However, when converting probability problems from discrete (such as binomial or geometric) then you need to consider how the interval would need to be adjusted so that histogram areas for the discrete problem would relate to areas under the normal curve. Generally, you will need to expand the stated interval each way by 1/2.
</p>
        <p>
The Central Limit Theorem provides that regardless of the distribution of X, the distribution of an average of X's is approximately normally distributed. However, it also shows why X may also be approximated for some distributions using the normal distribution as certain parameters are allowed to increase. Below, you can see how Binomial and Poisson distributions can be approximated directly using the Normal distribution.
</p>
        <p>Toward that end, for <m>0 \lt p \lt 1</m> consider a sequence of Bernoulli trials <m>Y_1, Y_2, ..., Y_n</m> with each over the space {0,1}. Then, 
<me>X = \sum_{k=1}^n Y_k</me>
is a Binomial variable.
</p>
        <theorem>
          <title>Binomial as approximate Normal</title>
          <statement>Given a Binomial variable X with <m>\mu = np</m> and <m>\sigma^2 = np(1-p)</m>, then X is approximately also normal with the same mean and variance so long as <m>np \gt 5</m> and <m>n(1-p) \gt 5</m>.
</statement>
          <proof>
            <p>
Using the Bernoulli variables <m>Y_k</m> each with mean p and variance p(1-p), note that the Central Limit Theorem applied to <m>\overline{X} = \frac{\sum Y_k}{n}</m> gives that
<me>\frac{\overline{X}-p}{\sqrt{p(1-p)/n}}</me>
is approximately standard normal. By multiplying top and bottom by n yields
<me>\frac{\sum Y_k - np}{\sqrt{np(1-p)}}</me>
is approximately standard normal. But <m>\sum Y_k</m> actually is the sum of the number of successes in n trials and is therefore a Binomial variable.
</p>
          </proof>
        </theorem>
        <example>
          <title>Binomial as Normal</title>
          <p>Binomial becomes normal as <m> n \rightarrow \infty</m>.  Consider n = 50 and p = 0.3.  Then, <m>\mu = 15</m> and <m>\sigma^2 = 10.5</m>.   
</p>
          <p>Using the binomial formulas, for example,
<me>P( X = 16 ) = \binom{50}{16} 0.3^{16} \cdot 0.7^{34} \approx 0.11470</me>
Using the normal distribution,
<md><mrow>P( X = 16 ) &amp; = P( 15.5 \lt X \lt 16.5) </mrow><mrow> &amp; \approx normalcdf(15.5,16.5,15,sqrt(10.5)) </mrow><mrow> &amp; = 0.11697</mrow></md>
Notice that these are very close.
</p>
        </example>
        <corollary>
          <title>Poisson as approximate Normal</title>
          <statement>Given a Poisson variable X with <m>\mu</m> and <m>\sigma^2 = \mu</m> given, then X is approximately also normal with the same mean and variance so long as <m>\mu \gt 5</m>.
</statement>
          <proof>
            <p>
Note from before that the Poisson distribution function was derived by approximating with Binomial and letting n approach infinity. Therefore, by the previous theorem, the Poisson variable is also approximately Normal using the Poisson mean and variance rather than the binomial's. Indeed, in standard units
<me>\frac{Y - \mu}{\sqrt{\mu}}</me>
is approximately normal for large <m>\mu</m>.
</p>
          </proof>
        </corollary>
        <example>
          <title>Poisson as Normal</title>
          <p>Poisson becomes normal as <m> \mu \rightarrow \infty</m>.  Consider <m>\mu = 20</m>.  Then, <m>\sigma^2 = \mu = 20</m>.   
</p>
          <p>Using the Poisson formulas, for example,
<me>P( X = 19 ) = \frac{20^{19} e^{-20}}{19!} \approx 0.08883</me>
Using the normal distribution,
<md><mrow>P( X = 19 ) &amp; = P( 18.5 \lt X \lt 19.5) </mrow><mrow> &amp; \approx normalcdf(18.5,19.5,20,sqrt(20)) </mrow><mrow> &amp; = 0.08683</mrow></md>
Again, these are very close.
</p>
        </example>
        <theorem>
          <title>Gamma as approximate Normal</title>
          <statement>Given a Gamma variable X with mean <m>r \mu</m> and variance <m> r BLOB</m> given, then X is approximately also normal with the same mean and variance so long as CONDITION????.
</statement>
        </theorem>
        <example>
          <title>Gamma as Normal</title>
          <p>Gamma becomes normal as <m> r \rightarrow \infty</m>.  Assume that the average time till a first success is 12 minutes and that <m>r = 8</m>.  Then, the mean for the Gamma distribution is <m>\mu = 12 \cdot 8 = 96</m> and <m>\sigma^2 = 8 \cdot 12^2 = 1152</m> and so <m>\sigma \approx 33.9411</m>.   
</p>
          <p>Using the Gamma formulas, 
<md><mrow>P( 90 \le X \le 100 ) &amp; = \int_{90}^{100} f(x) dx </mrow><mrow> &amp; = 0.59252 - 0.47536 = 0.11716.</mrow></md>
Using the normal distribution,
<me>P( 90 \le X \le 100) \approx normalcdf(90,100,96,33.9411) = 0.11707.</me>
Amazingly, these are also very close.
</p>
        </example>
        <example>
          <title>Uniform X vs Normal <m>\overline{X}</m></title>
          <p>Consider a discrete uniform variable X over R = {1,2,...,20}.  Then, <m>\mu = 10.5</m> and <m>\sigma = \frac{20^2-1^2}{20}</m> using the uniform formulas.
</p>
          <p>You can use the uniform probability function to compute probabilities dealing with X. Indeed,
<me>P(8 \le X \lt 12) = P(X \in \{8,9,10,11 \} = \frac{4}{20} = 1/5.</me>
</p>
          <p>
If instead you plan to sample from this distribution n=49 times, the Central Limit Theorem implies that you will get a random variable <m>\overline{X}</m> which has an approximate normal distribution with the same mean but with new variance <m>\sigma_{\overline{X}}^2 = \frac{199/20}{49} = \frac{199}{580}</m>.  Therefore, expanding the interval to include the boundaries of the corresponding histogram areas,
<me>P( 8 \le \overline{X} \lt 12 ) = P(7.5 \le \overline{X} \le 11.5) \approx normalcdf(7.5,11.5,10.5,0.585750) \approx 0.9561 .</me>
</p>
        </example>
        <p>
As these examples illustrate, you will have increasing success in approximating the desired probabilities so long as the distribution's corresponding parameter is allowed to be "sufficiently large". The mathematical reasoning this is true is not provided but depends upon the "Central Limit Theorem" discussed in the next section.
</p>
        <p>
The above theorems allow you to utilize the normal distribution to compute approximate probabilities for the variable X in the stated distributions. This is not always true for all distributions since some do not have parameters which allow for approaching normality. However, regardless of the distribution the Central Limit Theorem always allows you to approximate probabilities if they involve an average of repeated attempts...that is, for variable <m>\overline{X}</m>. This usefulness is illustrated in the examples below.
</p>
      </section>
      <section>
        <title>Summary</title>
        <introduction>
          <p>
Here is a summary of the major points in this chapter:
</p>
        </introduction>
        <p>
TBA
</p>
      </section>
      <section>
        <title>Exercises</title>
        <exercise>
          <title> - Computing basic standard normal probabilities</title>
          <p>
Compute
<ul><li><me>P( Z \gt 0)</me></li><li><me>P( Z \lt 0.892)</me></li><li><me>P( Z \lt -0.892)</me></li><li><me>P( -1.45 \lt Z \lt 2.37)</me></li><li><me>P( -1 \lt Z \lt 1)</me>
which is the probability of lying within 1 standard deviation of the mean.</li><li><me>P( -2 \lt Z \lt 2)</me>
which is the probability of lying within 2 standard deviations of the mean.</li><li><me>P( -3 \lt Z \lt 3)</me>
which is the probability of lying within 3 standard deviations of the mean.</li><li>A value for a so that <me>P( Z \lt a) = 0.8</me>
which would be the location of the 80th percentile.</li></ul>
</p>
        </exercise>
        <exercise>
          <title> - Computing basic normal probabilities</title>
          <p>Given <m>\mu = 25</m> and <m>\sigma = 4</m> compute
<me>P(X \lt \mu)</me>
<me>P( X \gt 26)</me>
<me>P( X \gt 22)</me>
<me>P( 20 \le X \le 26)</me>
</p>
        </exercise>
        <exercise>
          <title> - IQ values</title>
          <p>The Intelligence Quotient (IQ) is a measure of your ability to think and reason. Presuming that IQ scores are normally distributed with mean 100 and standard deviation 15, determine the location of the 90th percentile.  That is, the IQ score below which you will find approximately 90% of other IQ scores.
</p>
        </exercise>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="IntervalEstimation">
      <title>Estimation</title>
      <section>
        <title>Introduction</title>
        <p>
You should have noticed by now that repeatedly sampling from a given distribution will yield a variety of sample statistics such as <m>\overline{x}</m> as an estimate perhaps for the population mean <m>\mu</m> or <m>\frac{Y}{n}</m> as an estimate for the population likelihood of success p. In this section, you will see how these sample "point estimators" are actually the best possible choices.
</p>
        <p>
In creating these point estimates repeatedly, you have noticed that the results will change somewhat over time. Indeed, flip a coin 20 times and you might expect 10 heads. However, in practice it is likely to 9 or 12 out of 20 and possible to get any of the other possible outcomes. This natural variation makes the point estimates noted above to almost certainly be in error. However one would expect that they should be close and the Central Limit Theorem does indicate that the distribution of sample means should be approximately normally distributed. Thus, instead of relying just on the value of the point estimate, you might want to investigate a way to determine a reasonable interval centered on the sample statistic in which you have some confidence the actual population statistic should belong. This leads to a discussion of interval estimates known as confidence intervals (using calculational tools) and statistical tolerance intervals (using order statistics).
</p>
        <p>
In this chapter we first discuss how to determine appropriate methods for estimating the needed population statistics (point estimates) and then quantify how good they are (confidence intervals).
</p>
      </section>
      <section>
        <title>Interval Estimates - Chebyshev</title>
        <p>An interval centered on the mean in which at least a certain proportion
	of the actual data must lie.
	</p>
        <theorem>
          <title>Chebyshev's Theorem</title>
          <statement>
	Given a random variable X with given mean <m>\mu</m> and standard deviation <m>\sigma</m>, for <m> a \in \mathbb{R}^+</m> , 
	
	<me>P( \big | X - \mu \big | \lt a ) \gt 1 - \frac{\sigma^2}{a^2}</me></statement>
          <proof>
            <p>
	Notice that the variance of a continuous variable X is given by
	<md><mrow>\sigma^2 &amp; = \int_{-\infty}^{\infty} (x - \mu)^2 f(x) dx</mrow><mrow> &amp; \ge \int_{-\infty}^{\mu-a} (x - \mu)^2 f(x) dx + \int_{\mu + a}^{\infty} (x - \mu)^2 f(x) dx</mrow><mrow> &amp; \ge \int_{-\infty}^{\mu-a} a^2 f(x) dx + \int_{\mu + a}^{\infty} a^2 f(x) dx</mrow><mrow> &amp; = a^2 \big ( \int_{-\infty}^{\mu-a} f(x) dx + \int_{\mu + a}^{\infty} f(x) dx \big )</mrow><mrow> &amp; = a^2 P( X \le \mu - a \text{or} X \ge \mu + a )</mrow><mrow> &amp; = a^2 P( \big | \mu - a \big | \ge a)</mrow></md>
	Dividing by <m>a^2</m> and taking the complement gives the result.
	</p>
          </proof>
        </theorem>
        <corollary>
          <title>Alternate Form for Chebyshev's Theorem</title>
          <statement>
            <p>For positive k,
	<me>P( \big | X - \mu \big | \lt k \sigma ) \gt 1 - \frac{1}{k^2}</me>
	</p>
          </statement>
        </corollary>
        <corollary>
          <title>Special Cases for Chebyshev's Theorem</title>
          <statement>For any distribution, it is not possible for f(x)=0 within one standard deviation of the mean. Aslo, at least 75% of the data for any distribution must lie within two standard deviations of the mean and at least 88% must lie within three.
	</statement>
          <proof>
            <p>
	Apply the Chebyshev Theorem with <m>a = \sigma</m> to get
	<me>P(\mu - \sigma \lt X \lt \mu + \sigma) \gt 1 - \frac{\sigma^2}{\sigma^2} = 0</me>
	</p>
            <p>
	Apply the Chebyshev Theorem with <m>a = 2 \sigma</m> to get <m>1 - \frac{1}{2^2} = 0.75</m> and with <m>k = 3 \sigma</m> to get <m>1 - \frac{1}{3^2} = \frac{8}{9} &gt; 0.8888</m>.
	</p>
          </proof>
        </corollary>
        <p>
<example><title>WebWork</title><webwork-reps xml:id="extracted-webwork-32" ww-id="webwork-32">
    <pg source="Library/NAU/setStatistics/cheby2.pg"/>

      
    <static source="Library/NAU/setStatistics/cheby2.pg" seed="32">
      <statement><p>A statistician uses Chebyshev's Theorem to estimate that at least 55 <percent/> of a population lies between 
      the values 2 and 20.  Use this information to find the values of the population mean, <m>\mu</m> , and 
      the population standard deviation <m>\sigma</m>.</p><p>a)  <m>\mu =</m> <fillin name="AnSwEr0001" characters="20"/></p><p>b)  <m>\sigma =</m> <fillin name="AnSwEr0002" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=32&amp;sourceFilePath=Library/NAU/setStatistics/cheby2.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=32&amp;sourceFilePath=Library/NAU/setStatistics/cheby2.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=32&amp;sourceFilePath=Library/NAU/setStatistics/cheby2.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=32&amp;sourceFilePath=Library/NAU/setStatistics/cheby2.pg</server-url>

  </webwork-reps></example>
</p>
        <p>
<example><title>WebWork</title><webwork-reps xml:id="extracted-webwork-33" ww-id="webwork-33">
    <pg source="Library/NAU/setStatistics/cheby1.pg"/>

      
    <static source="Library/NAU/setStatistics/cheby1.pg" seed="33">
      <statement><p>Suppose that the blood pressure of the human inhabitants of a certain Pacific island is  distributed with 
      mean, <m>\mu</m> = 101 mmHg and standard deviation , <m>\sigma</m> = 12 mmHg. According to Chebyshev's Theorem, 
      at least what percentage of the islander's have blood pressure in the range from 68.6 mmHg to 133.4 mmHg ?</p><p>answer: <fillin name="AnSwEr0001" characters="20"/><percent/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=33&amp;sourceFilePath=Library/NAU/setStatistics/cheby1.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=33&amp;sourceFilePath=Library/NAU/setStatistics/cheby1.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=33&amp;sourceFilePath=Library/NAU/setStatistics/cheby1.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=33&amp;sourceFilePath=Library/NAU/setStatistics/cheby1.pg</server-url>

  </webwork-reps></example>
</p>
        <example>
          <title> - Comparing known distribution to Chebyshev</title>
          <p>TBA
	</p>
        </example>
      </section>
      <section>
        <title>Point Estimates</title>
        <p>
For Binomial, Geometric, what is p? For exponential, what is the mean?  For normal, what are the mean and standard deviation? Each of these parameters are necessary before you can compute any probability values from their respective formulas. Since they might not be given in a particular instance, they will need to be estimated in some manner. 
</p>
        <p>This estimate will have to be determined likely by utilizing sampling in some form. Since such an estimate will come from partial information (i.e. a sample) then it is very likely going to only be an approximation to the exact (but unknown) value. In general, an estimator is a numerical value which is used in the place of an unknown population statistic. To determine precisely what is a "best" estimator requires a multivariate approach and is beyond the scope of this text. Indeed, to justify why each of the following are good estimators look up the topic "Maximum Likelihood Estimators".
</p>
        <p>From your previous experience with the Poisson, Exponential, and Gamma distributions, you should also remember that each required a known value for <m>\mu</m> before proceeding with calculations.  It is sensible to consider estimating the unknown population mean <m>\mu</m> using the sample mean
<me>\mu \approx \overline{x} = \frac{\sum x_k}{n}</me>
where the values <m>x_k</m> are the n individual sample values.
</p>
        <p>
For any continous variable and indeed for <m>\overline{X}</m>), <m>P(\overline{X} = \mu) = 0</m>. In general, you should expect a sample statistic to be close but not precisely equal to the population statistic. Indeed, if you were so lucky as to have the sample statistic to land on the population statistic, doing one more trial would mess things up anyway and the sample statistic would certainly change some.
</p>
        <p>In a similar manner with the Binomial, Geometric, and Negative Binomial distributions, you will remember that each required a known value for p before  proceeding with any calculations. From our experiments we saw that relative frequency appeared to stabilize around what you might expect for the true proportion of success and therefore estimating the unknown proportion of success p using relative frequency
<me>p \approx \tilde{p} = \frac{y}{n}</me>
where y is the number of successes in a collection of n bernoulli trials. Again, notice that the relative frequency <m>\tilde{p}</m> is technically an average as well so the probability that a given relative frequency will like exactly on the actual value of p is again zero.
</p>
        <p>Finally, the Normal distribution requires a numerical value for <m>\sigma</m>, the population's standard deviation. It can be shown that the maximum likelihood estimator for <m>\sigma^2</m> is the variance v found in chapter one. However, you may remember that at that time we always adjusted this value somewhat using the formula <m>s^2 = \frac{n}{n-1} v</m> which increased the variance slightly. To uncover why you would not use the maximum likelihood estimator v requires you to look up the idea of "bias". As it turns out, v is maximum likelihood but exhibits mathematical bias whereas <m>s^2</m> is slightly suboptimal with respect to likelihood but exhibits no bias. Therefore, for estimating the unknown population variance <m>\sigma^2</m> you can use sample variance
<me>\sigma^2 \approx s^2</me> 
and similarly sample standard deviation
<me>\sigma \approx s</me>
to approximate the theoretical standard deviation. 
</p>
      </section>
      <section>
        <title>Interval Estimates - Confidence Interval for p</title>
        <p>
Sometimes selecting a value for p for a Binomial, Geometric, or Negative Binomial distribution problem can be done by using a theoretical value. Indeed, when flipping a coin it is reasonable to assume p = 1/2 is the probability of getting a head on one flip. Similarly, it is reasonable to assume p = 1/6 when you are looking for a particular side of a 6-sided die. However, many times you will want to deal with a problem in which it is not possible to determine exactly the precise value for the likelihood of success such as your true probability of making a free throw in basketball or knowing the true percentage of the electorate that will vote for your favorite candidate. 
</p>
        <p>
In these later situations, we found in the previous section that relative frequency <m>\frac{Y}{n}</m> is generally a good way to estimate p. In this section, you will investigate how to measure the closeness--and thereby assure some confidence in that estimate--regarding how well the point estimate approximates the actual value of p.
</p>
        <definition>
          <title>Confidence Intervals for p</title>
          <statement>
            <p>Given a point estimate <m>\tilde{p}</m> for p, a confidence interval for p is a range of values which contains the actual value of p with high probability. In notation, a two-sided confidence interval for p is of the form
<me>\tilde{p} - E_1 \lt p \lt \tilde{p} + E_2</me>
with
<me>P(\tilde{p} - E_1 \lt p \lt \tilde{p} + E_2) = 1 - \alpha</me>
where <m>\alpha</m> is near 0 and <m>E_k \gt 0</m>.  One-sided confidence intervals for p can be similarly described 
<me>P( p \lt \tilde{p} + E_2) = 1 - \alpha</me>
or
<me>P(\tilde{p} - E_1 \lt p) = 1 - \alpha.</me>
</p>
          </statement>
        </definition>
        <p>
Generally, symmmetry is presumed when using a two-sided confidence interval so that <m>E_1 = E_2 = E</m> and therefore the interval looks like
<me>P(\tilde{p} - E \lt p \lt \tilde{p} + E) = 1 - \alpha.</me>
In this case, E is known as the margin of error.
</p>
        <p>
To determine E carefully, note that from the central limit theorem
<me>\frac{Y-np}{\sqrt{np(1-p}} = \frac{\tilde{p} - p}{\sqrt{p(1-p)/n}}</me>
is approximately standard normal for large n.  Presuming that <m>\tilde{p} \approx p</m> and replacing the unknown p terms on the bottom with <m>\tilde{p}</m> gives 
<me>z = \frac{\tilde{p} - p}{\sqrt{\tilde{p}(1-\tilde{p})/n}}</me>
where z is a standard normal distribution variable. So, using the central limit theorem and the standard normal distribution, you can find the value <m> z_{ \alpha/2}</m> where
<me>P( -z_{ \alpha/2} \lt z \lt z_{ \alpha/2}) = 1 - \alpha</me>
<me>P( -z_{ \alpha/2} \lt \frac{\tilde{p} - p}{\sqrt{\tilde{p}(1-\tilde{p})/n}} \lt z_{ \alpha/2}) = 1 - \alpha</me>
or by rearranging the inside inequality
<me>P( \tilde{p} - z_{ \alpha/2}\sqrt{\tilde{p}(1-\tilde{p})/n} \lt  p \lt \tilde{p} + z_{ \alpha/2}\sqrt{\tilde{p}(1-\tilde{p})/n}) = 1 - \alpha.</me>
Setting <m>E = z_{ \alpha/2}\sqrt{\tilde{p}(1-\tilde{p})/n}</m> gives a way to determine a confidence interval centered on <m>\tilde{p} = \frac{Y}{n}</m> for p with "confidence level" <m>1-\alpha</m>.  
</p>
        <p>
To complete the interval, one needs a specific value for <m>z_{ \alpha/2}</m>.
Generally, one chooses confidence levels on the order of 90%, 95%, or 99% with 95% being the usual choice.  Fortunately this value is easily computed using graphing calculators or other automatic methods although your ancient teacher might have been required to use tables. On a TI calculator, use
<me>z_{\alpha /2} = \text{InvNorm}( 1 - \frac{\alpha}{2} )</me>

</p>
        <p>
For 90% confidence level, you need to find a z-value so that
<me>P( -z_{ \alpha/2} \lt z \lt z_{ \alpha/2}) = 0.9 = 1 - 0.1 .</me>
Using the symmetry of the normal distribution, this can be rewritten
<me>F(z_{ \frac{0.1}{2}}) = P( z \lt z_{ \frac{0.1}{2}}) = 0.95 = 1 - \frac{0.1}{2} .</me>
Using the inverse of the standard normal distribution (on the TI calculator this is InvNorm(0.95)) gives <m>z_{ 0.05} \approx 1.645</m>.
</p>
        <p>
Similarly, for a 95 % confidence level, find where
<me>F(z_{ \frac{0.05}{2}}) = P( z \lt z_{ \frac{0.05}{2}}) = 0.975 = 1 - \frac{0.05}{2} .</me>
The calculators InvNorm(0.975) gives <m>z_{ 0.025} \approx 1.960</m>.
</p>
        <p>
For a 99 % confidence level, find where
<me>F(z_{ \frac{0.01}{2}}) = P( z \lt z_{ \frac{0.01}{2}}) = 0.995 = 1 - \frac{0.01}{2} .</me>
The calculators InvNorm(0.995) gives <m>z_{ 0.005} \approx 2.576</m>.
</p>
        <p>
Notice that when computing the confidence intervals above that we choose to just replace some of the p terms with <m>\tilde{p}</m> so that only one p term was left and could be isolated in the middle. There are other ways to deal with this. The easiest is to take the worst case scenario for the p terms in the denominator above. Indeed, the confidence interval is made wider (and therefore more likely to contain the actual p) if the square root term is as large as possible, using basic calculus it is easy to see that p(1-p) is maximized when p = 1/2. Therefore, a second alternative is to create your confidence interval using
<me>z = \frac{\tilde{p} - p}{\frac{1}{2\sqrt{n}}}</me>
and therefore <m>E = \frac{z_{ \alpha/2}}{2\sqrt{n}}</m>.
This method should be used only when trying to create the roughest and "safest" interval.
</p>
        <p>
The methods for determining a confidence interval for p above depend upon a good approximation with the Central Limit Theorem. This approximation will be fine if n is relatively large. To consider a confidence interval for p when n is small, note that the binomial random variable is discrete and so expanding the interval by a factor of <m>\frac{1}{2n}</m> might be in order.
</p>
        <p>
Another more elaborate mechanism when n is relatively large is given by the Wilson Score. This confidence interval is more complicated than just taking <m>\tilde{p}</m> and adding and subtracting E. This approach notes that the possible extreme values for p must satisfy (before replacing some of the p terms with <m>\tilde{p}</m>)
 </p>
        <p>

<theorem><title>Wilson Score Confidence Interval for p</title><statement><p>
<me>\frac{\tilde{p} + \frac{z_{\alpha/2}^2}{2n} - z_{\alpha/2} \sqrt{\frac{\tilde{p}(1-\tilde{p}) + \frac{z_{\alpha/2}^2}{4n}}{n}}}{1 + \frac{z_{\alpha/2}^2}{n}} \lt p \lt \frac{\tilde{p} + \frac{z_{\alpha/2}^2}{2n} + z_{\alpha/2} \sqrt{\frac{\tilde{p}(1-\tilde{p}) + \frac{z_{\alpha/2}^2}{4n}}{n}}}{1 + \frac{z_{\alpha/2}^2}{n}}
</me>
</p></statement><proof><p>Again, noting that <m>\tilde{p} = \frac{Y}{n}</m>, the expression above
<me> \big | p - \tilde{p} \big | = z_{\alpha /2} \sqrt{\frac{p(1-p)}{n}}</me>
can be simplified by squaring both sides to get

<me> \big ( p - \tilde{p} \big )^2 = z_{\alpha /2}^2 \frac{p(1-p)}{n}.</me>

Replacing <m>\tilde{p}</m> with the relative frequency gives
<me> \big ( p - \frac{Y}{n} \big )^2 = z_{\alpha /2}^2 \frac{p(1-p)}{n}</me>

or by simplifying
<me>(n+z_{\alpha /2}^2 )p^2 - (2Y+z_{/alpha /2}^2) p + \frac{Y^2}{2} = 0.</me>

Solving for p using the quadratic formula and simplifying ultimately results in the described interval.
</p></proof></theorem>

<example><title>Comparison of the three Confidence Interval methods for p</title><p>
Presume that from a sample of size n = 400 you get Y = 144 successes.  Determine 95% two-sided confidence intervals for the actual p using all three of the methods above. Note that for each you will utilize <m>z_{\alpha/2} = z_{0.025} = 1.960</m> and <m>\tilde{p} = \frac{144}{400} = 0.36</m>.
</p><p>Normal Interval:
<me>P( 0.36 - 1.960 \sqrt{0.36 \cdot 0.64) / 400} \lt  p \lt 0.36 + 1.960 \sqrt{0.36 \cdot 0.64) / 400}) = 1 - \alpha.</me>
or
<me>P( 0.36 - 1.960 \cdot 0.6 \cdot 0.8) / 20 \lt  p \lt 0.36 + 1.960 \cdot 0.6 \cdot 0.8) / 20) = 0.95 </me>
or
<me>P( 0.36 - 0.04704 \lt  p \lt 0.36 + 0.04704) = 0.95 .</me>
or
<me>P( 0.31296 \lt  p \lt 0.40704) = 0.95 .</me>
So, there is a 95% chance that the actual value for p lies inside the interval
<m>(0.31296 , 0.40704).</m>
</p><p>Maximal Interval:
<me>P( 0.36 - 1.960 \frac{1}{2\sqrt{400}} \lt  p \lt 0.36 + 1.960 \frac{1}{2\sqrt{400}} ) = 1 - \alpha.</me>
or
<me>P( 0.36 - 1.960 \frac{1}{40} \lt  p \lt 0.36 + 1.960 \frac{1}{40} ) = 1 - \alpha.</me>
or
<me>P( 0.311 \lt  p \lt 0.409 ) = 1 - \alpha.</me>
Notice the interval is only slightly wider than when using <m>\tilde{p}</m> to estimate p in the first case.
</p><p>Wilson Score Interval:  Let's do this on in parts...
<me>z_{\alpha/2} \sqrt{\frac{\tilde{p}(1-\tilde{p}) + \frac{z_{\alpha/2}^2}{4n}}{n}} = 1.96 \sqrt{ \frac{0.36 \cdot 0.64 + \frac{1.96^2}{1600}}{400}} \approx 0.04728
</me>
Therefore, 
<me>\frac{0.36 + \frac{1.96^2}{800} - 0.04728}{1 + \frac{1.96^2}{400}} \lt p \lt \frac{0.36 + \frac{1.96^2}{800} + 0.04728}{1 + \frac{1.96^2}{400}}
</me>
or
<me>0.3145 \lt p \lt 0.4082</me>
which is slightly different than the first and slightly smaller than the second.
</p></example>

</p>
        <p>
<exercise><title>WebWork</title><webwork-reps xml:id="extracted-webwork-34" ww-id="webwork-34">
    <pg source="Library/ASU-topics/setStat/kolossa49.pg"/>

      
    <static source="Library/ASU-topics/setStat/kolossa49.pg" seed="34">
      <statement><p>A poll is taken in which <m>377</m> out of <m>525</m> randomly selected voters indicated their preference for a certain
      candidate.</p><p>(a) Find a <m>99</m><percent/> confidence interval for <m>p</m>.</p><p><fillin name="AnSwEr0001" characters="20"/> <m>\leq p \leq</m> <fillin name="AnSwEr0002" characters="20"/></p><p>(b) Find the margin of error for this <m>99</m><percent/> confidence interval for <m>p</m>.</p><p><fillin name="AnSwEr0003" characters="20"/></p></statement>
      
      <statement><p>(c) Without doing any calculations, indicate whether the margin of error is larger or smaller or the same for an 80<percent/> confidence interval.
      <var form="buttons">
      <li>
      <p>larger</p>
      </li>
      <li>
      <p>smaller</p>
      </li>
      <li>
      <p>same</p>
      </li>
      </var></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=34&amp;sourceFilePath=Library/ASU-topics/setStat/kolossa49.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=34&amp;sourceFilePath=Library/ASU-topics/setStat/kolossa49.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=34&amp;sourceFilePath=Library/ASU-topics/setStat/kolossa49.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=34&amp;sourceFilePath=Library/ASU-topics/setStat/kolossa49.pg</server-url>

  </webwork-reps></exercise>
</p>
        <theorem>
          <title>Determining Sample Size for proportions</title>
          <statement>Given a margin of error E and preliminary relative frequency estimate <m>\tilde{p_0}</m> the sample size needed to create the corresponding confidence interval is given by 
<me>n \gt \left ( \frac{z_{\alpha /2}}{E} \right )^2 \tilde{p_0}(1-\tilde{p_0}).</me></statement>
          <proof>
Solve for n in the confidence interval above.
</proof>
        </theorem>
        <example>
          <title>Determining Sample Size for one proportion</title>
          <p>
Given a 99% confidence level, margin of error E=0.03, and preliminary estimate <m>\tilde{p_0} = 0.35</m>, notice that <m>z_{\alpha / 2} = 2.58</m> gives
<me>n \gt \left ( \frac{2.58}{0.03} \right )^2 0.35 \cdot 0.65 \approx 1682.59</me>
or a sample size of at least 1683.
</p>
        </example>
        <p>
<exercise><title>WebWork</title><webwork-reps xml:id="extracted-webwork-35" ww-id="webwork-35">
    <pg source="Library/UBC/STAT/STAT200/hw07/hw07-q04b.pg"/>

      
    <static source="Library/UBC/STAT/STAT200/hw07/hw07-q04b.pg" seed="35">
      <statement><p>Refer to the following scenario.</p><p>An epidemiologist is worried about the prevalence of the flu in East Vancouver and the potential shortage of vaccines for the area. She will need to provide a recommendation for how to allocate the vaccines appropriately across the city. She takes a simple random sample of 340 people living in East Vancouver and finds that 39 have recently had the flu.</p><p>Suppose that the epidemiologist wants to re-estimate the population proportion and wishes
      for her 95<percent/> confidence interval to have a margin of error no larger than 0.04.  How large 
      a sample should she take to achieve this? Please carry answers to at least six decimal places in intermediate steps.</p><p>Sample size = <fillin name="AnSwEr0001" characters="6"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=35&amp;sourceFilePath=Library/UBC/STAT/STAT200/hw07/hw07-q04b.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=35&amp;sourceFilePath=Library/UBC/STAT/STAT200/hw07/hw07-q04b.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=35&amp;sourceFilePath=Library/UBC/STAT/STAT200/hw07/hw07-q04b.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=35&amp;sourceFilePath=Library/UBC/STAT/STAT200/hw07/hw07-q04b.pg</server-url>

  </webwork-reps></exercise>
</p>
      </section>
      <section>
        <title>Interval Estimates - Confidence Interval for <m>\mu</m></title>
        <p>
As with the confidence intervals above for proportions, the Central Limit Theorem also allows you to create an interval centered on a sample mean for estimating the population mean <m>\mu</m>.
</p>
        <definition>
          <title>Confidence Interval for One Mean</title>
          <statement>
            <p>
Given a sample mean <m>\overline{x}</m>, a two-sided confidence interval for the mean with confidence level <m>1-\alpha</m> is an interval 
<me>\overline{x} - E_1 \lt \mu \lt \overline{x} + E_2</me>
such that
<me>P(\overline{x} - E_1 \lt \mu \lt \overline{x} + E_2) = 1-\alpha.</me>
Generally, the interval is symmetrical of the form <m>\overline{x} \pm E</m> with E again known as the margin of error.  One-sided confidence intervals can be determined in the same manner as in the previous section.
</p>
          </statement>
        </definition>
        <p>
Once again, utilize the Central Limit Theorem.  Notice that the symmetrical confidence interval 
<me>P(\overline{x} - E \lt \mu \lt \overline{x} + E) = 1-\alpha.</me>
is equivalent to

<me>P \left ( \frac{-E}{\sigma / \sqrt{n}} \lt \frac{\overline{x} - \mu}{\sigma / \sqrt{n}} \lt \frac{E}{\sigma / \sqrt{n}} \right ) = 1 - \alpha</me>
in which the middle term can be approximated using a standard normal variable and therefore this statement is approximately

<me>P \left ( \frac{-E}{\sigma / \sqrt{n}} \lt Z \lt \frac{E}{\sigma / \sqrt{n}} \right ) = 1 - \alpha.</me>

Using the symmetry of the standard normal distribution about Z=0 gives
<me>\Phi (z_{\alpha/2} ) = \Phi \left ( \frac{E}{\sigma / \sqrt{n}} \right ) = P \left ( Z \lt \frac{E}{\sigma / \sqrt{n}} \right ) = 1 - \frac{\alpha}{2}</me>

and so to determine E again requires the inverse of the standard normal distribution function.  Using an appropriate <m>z_{\alpha /2}</m> (as determine in a manner described in the previous section) gives a confidence interval for the mean
<me>\overline{x} - z_{\alpha / 2} \frac{\sigma}{\sqrt{n}} \lt \mu \lt \overline{x} + z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}</me>
with confidence level <m>1-\alpha</m> and margin of error 
<me>E = z_{\alpha /2} \frac{\sigma}{\sqrt{n}}.</me>
</p>
        <p>
<exercise><title>WebWork</title><webwork-reps xml:id="extracted-webwork-36" ww-id="webwork-36">
    <pg source="Library/CollegeOfIdaho/setStatistics_Ch14InferenceIntro/14Stats_05_InferenceIntro.pg"/>

      
    <static source="Library/CollegeOfIdaho/setStatistics_Ch14InferenceIntro/14Stats_05_InferenceIntro.pg" seed="36">
      <statement><p>A random sample of <m>n</m> measurements was selected from a population with 
      standard deviation <m>\sigma = 17.7</m> and unknown mean <m>\mu</m>.  
      Calculate a <m>99</m> <percent/> confidence interval for <m>\mu</m> for each of the
      following situations:</p><p>(a) <m>n = 70, \ \overline{x} = 90.8</m></p><p><fillin name="AnSwEr0001" characters="15"/> <m>\leq \mu \leq</m> <fillin name="AnSwEr0002" characters="15"/></p><p>(b)  <m>n = 85, \ \overline{x} = 90.8</m></p><p><fillin name="AnSwEr0003" characters="15"/> <m>\leq \mu \leq</m> <fillin name="AnSwEr0004" characters="15"/></p><p>(c)  <m>n = 105, \ \overline{x} = 90.8</m></p><p><fillin name="AnSwEr0005" characters="15"/> <m>\leq \mu \leq</m> <fillin name="AnSwEr0006" characters="15"/></p><p>(d)  In general, we can say that for the same confidence level, increasing the sample size <fillin name="AnSwEr0007" characters="20"/> the
      margin of error (width) of the confidence interval.  (Enter: ''DECREASES'', ''DOES NOT CHANGE'' or
      ''INCREASES'', without the quotes.)</p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=36&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch14InferenceIntro/14Stats_05_InferenceIntro.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=36&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch14InferenceIntro/14Stats_05_InferenceIntro.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=36&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch14InferenceIntro/14Stats_05_InferenceIntro.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=36&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch14InferenceIntro/14Stats_05_InferenceIntro.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
It should be noted that the use of the Central Limit Theorem makes the use of  InvNorm an approximation. It can be shown that so long as n is larger than 30 then generally this approximation is reasonable. If not, then use replace the z-score with a corresponding value from the t-distribution.
</p>
        <p>
<exercise><title>WebWork with t-scores</title><webwork-reps xml:id="extracted-webwork-37" ww-id="webwork-37">
    <pg source="Library/Rochester/setStatistics3Estimates/ur_stt_3_6.pg"/>

      
    <static source="Library/Rochester/setStatistics3Estimates/ur_stt_3_6.pg" seed="37">
      <statement><p>Use the given data to find the 95<percent/> confidence interval estimate of the population 
      mean <m>\mu</m>. Assume that the population has a normal distribution.</p><p>IQ scores of professional athletes:</p><p>Sample size <m>n = 10</m></p><p>Mean <m>\overline{x} = 103</m></p><p>Standard deviation <m>s  = 10</m></p><p><fillin name="AnSwEr0001" characters="20"/> <m>\lt  \mu \lt </m> <fillin name="AnSwEr0002" characters="20"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=37&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_6.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=37&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_6.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=37&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_6.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=37&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_6.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
Additionally, this derivation assumes that <m>\mu</m> is not known...indeed the goal is to approximate that mean using <m>\overline{x}</m>...but that <m>\sigma</m> is known. This is often not the case. It can however be shown that if n is larger than 30, replacing <m>\sigma</m> with the sample standard deviation s gives an acceptable confidence interval.
</p>
        <theorem>
          <title>Sample Size needed for <m>\mu</m> given Margin of Error</title>
          <statement>
            <p>
Given confidence level <m>1-\alpha</m> and margin of error E, the sample size needed to determine an appropriate confidence interval satisfies
<me> n \gt \left ( z_{\alpha /2} \frac{\sigma}{E} \right )^2</me>
</p>
          </statement>
          <proof>
            <p>
Solve for n in the formula for E above. Notice that n must be an integer so you will need to round up. You will also need an estimate for the sample standard deviation s by using a preliminary sample. 
</p>
          </proof>
        </theorem>
        <p>
Notice, in practice you might want to take n to be a little larger than the absolute minimum value prescribed above since you are dealing with approximations (Central Limit Theorem and the use of an estimate for s rather than the actual <m>\sigma</m>.)
</p>
        <example>
          <title>Determining Sample Size for one Mean</title>
          <p>
Given a 95% confidence level, margin of error E=0.1, and preliminary sample with standard deviation s = 2, <m>z_{\alpha / 2} = 1.96</m> gives
<me>n \gt \left ( 1.96 \cdot \frac{2}{0.1} \right )^2 \approx 1536.64</me>
or a sample size of at least 1537.
</p>
        </example>
      </section>
      <section>
        <title>Interval Estimates - Confidence Interval for <m>\sigma^2</m></title>
        <p>
Once again, you may need to approximate the population variance or standard deviation but only have the sample values available. One difference from the previous sections is that you are not dealing with an average of values (such as <m>\overline{x}</m> or <m>\tilde{p}</m>) but with the average of the squares of values. The Central Limit Theorem does not directly help you in this case but the following result (presented without proof) provides a solution.
</p>
        <theorem>
          <title>Relationship between Variance and <m>\chi ^2</m></title>
          <statement>
            <p>If <m>S^2</m> is a random variable of possible sample variance values from a sample of size n, then
<me>W = \frac{(n-1)S^2}{\sigma^2}</me>
is approximately <m>\chi ^2(n-1).</m>
</p>
          </statement>
        </theorem>
        <p>
To create a confidence interval for <m>\sigma^2</m> first consider an interval of the form
<me>E_1 \lt \sigma^2 \lt E_2</me>
and determine values for the boundaries so that the likelihood of this being true is high. For this case, since the chi-square distribution only has a positive domain and is not symmetrical, you will not expect to determine a symmetrical confidence interval.  Therefore, consider
<me>P (E_1 \lt \sigma^2 \lt E_2 ) = 1 - \alpha </me> 

and by playing around with algebra you get
<me>P \left ( \frac{E_1}{(n-1)S^2} \lt \frac{\sigma^2}{(n-1)S^2} \lt \frac{E_2}{(n-1)S^2} \right ) = 1 - \alpha </me> 

or by inverting the inequality yields
<me>P \left ( \frac{(n-1)S^2}{E_2} \lt \frac{(n-1)S^2}{\sigma^2} \lt \frac{(n-1)S^2}{E_1} \right ) = 1 - \alpha .</me> 

Using the previous theorem, note that the inside variable can be replaced with a chi-square variable. If F is the distribution function for chi-square, then you get
<me>F \left ( \frac{(n-1)S^2}{E_1} \right ) - F \left ( \frac{(n-1)S^2}{E_2} \right ) = 1 - \alpha .</me> 

For a given value of <m>\alpha</m> there are many possible choices but often one often utilized is one in which 

<me> F(\chi^2_{1-\alpha/2} ) = F \left ( \frac{(n-1)S^2}{E_1} \right ) = 1 - \alpha / 2</me>
and
<me> F(\chi^2_{\alpha/2} ) = F \left ( \frac{(n-1)S^2}{E_2} \right ) = \alpha / 2.</me> 

Using the inverse chi-square gives values for the expression on the inside and algebra can be used to solve for each of <m>E_1, E_2</m>. Indeed,

<me> E_1 = \frac{(n-1)S^2}{\chi^2_{1-\alpha/2}} </me>
and
<me> E_2 = \frac{(n-1)S^2}{\chi^2_{\alpha/2}} </me>

</p>
        <p>
To determine appropriate values for <m>\chi^2_{\alpha/2} </m> and <m>\chi^2_{1-\alpha/2} </m> with equal probabilities in each tail, consider using the interactive cell below:
</p>
        <sage>
          <input>
# Chi-Square Calculator for confidence intervals with equal alpha/2 tails
var('t')
@interact(layout=dict(top=[['c'],['n']]))
def _(c=input_box(0.95,width=10,label='Confidence Level = '),n=input_box(20,width=8,label='n =')):
    alpha = 1-c
    T = RealDistribution('chisquared', n)
    a = T.cum_distribution_function_inv(alpha/2)
    a1 = T.cum_distribution_function(a)
    b = T.cum_distribution_function_inv(1-alpha/2)
    b1 = T.cum_distribution_function(b)
    
    print 'From the Chi-Square distribution for X:'
    print 'P(',a,'&lt; X &lt; ',(b),') = ',c
    print 'with'
    print 'P( X &lt; ',a,') = ',a1
    print 'P( X &lt; ',b,') = ',b1
    
    f = x^(n/2-1)*e^(-x/2)/(gamma(n/2)*2^(n/2))
    G = plot(f,x,0,b+(b-a)/2)+plot(f,x,a,b,thickness=5,color='green')
    G += line([(a,0),(a,f(x=a))],color='green',thickness=3)
    G += line([(b,0),(b,f(x=b))],color='green',thickness=3)
    G += text(str(c.n(digits=5)),((a+b)/2,f(x=(a+b)/2)/3),color='green')
    G.show()
	</input>
        </sage>
        <p>

The example below uses the specific chi-square values given in the interactive cell below:

<sage><input>
# Chi-Square Calculator specifics
var('t')
c=0.95
n=8
alpha = 1-c
T = RealDistribution('chisquared', n)
a = T.cum_distribution_function_inv(alpha/2)
a1 = T.cum_distribution_function(a)
b = T.cum_distribution_function_inv(1-alpha/2)
b1 = T.cum_distribution_function(b)

print 'From the Chi-Square distribution for X:'
print 'P(',a,'&lt; X &lt; ',(b),') = ',c
print 'with'
print 'P( X &lt; ',a,') = ',a1
print 'P( X &lt; ',b,') = ',b1

f = x^(n/2-1)*e^(-x/2)/(gamma(n/2)*2^(n/2))
G = plot(f,x,0,b+(b-a)/2)+plot(f,x,a,b,thickness=5,color='green')
G += line([(a,0),(a,f(x=a))],color='green',thickness=3)
G += line([(b,0),(b,f(x=b))],color='green',thickness=3)
G += text(str(c.n(digits=5)),((a+b)/2,f(x=(a+b)/2)/3),color='green')
G.show()
	</input></sage>


<example><title> - Two-sided Confidence interval for <m>\sigma^2</m> and <m>\sigma</m></title><p>Given the data 570, 561, 546, 540, 609, 580, 550, 577, 585, determine a 95% confidence interval for <m>\sigma^2</m>.
</p><p>
Using the computational forumaula (or your calculator) gives <m>s^2 \approx 479.5</m>. Also, notice for n=9, the resulting interval will use a Chi-square variable with 8 degrees of freedom. Using the symmetric option, gives
<m>\chi_{0.025}^2 = 2.18</m> and <m>\chi_{0.975}^2 = 17.53</m>.  Therefore
<me> E_1 = \frac{8 \cdot 479.5}{17.53} \approx 221.095</me>
and
<me> E_2 = \frac{8 \cdot 479.5}{2.18} \approx 1759.63.</me>
Hence, you are 95% certain that 
<me>221.095 \lt \sigma^2 \lt 1759.63.</me>
By taking square roots you get
<me>14.87 \lt \sigma \lt 41.95.</me>
Notice, this interval is relatively wide which is a result both of the number of data values being relatively small (n=9) and the actual data values being relatively large and spread out.
</p></example>

The example below uses the specific chi-square values given in the interactive cell below:

<sage><input>
# Chi-Square Calculator specifics
var('t')
c=0.95
n=399
alpha = 1-c
T = RealDistribution('chisquared', n)
a = T.cum_distribution_function_inv(alpha/2)
a1 = T.cum_distribution_function(a)
b = T.cum_distribution_function_inv(1-alpha/2)
b1 = T.cum_distribution_function(b)

print 'From the Chi-Square distribution for X:'
print 'P(',a,'&lt; X &lt; ',(b),') = ',c
print 'with'
print 'P( X &lt; ',a,') = ',a1
print 'P( X &lt; ',b,') = ',b1
	</input></sage>


<example><title> - Two-sided Confidence interval for the variance and standard deviation with large n.</title><p>
<exercise><title>WebWork</title><webwork-reps xml:id="extracted-webwork-38" ww-id="webwork-38">
    <pg source="Library/Rochester/setStatistics3Estimates/ur_stt_3_20.pg"/>

      
    <static source="Library/Rochester/setStatistics3Estimates/ur_stt_3_20.pg" seed="38">
      <statement><p>Find the critical values <m>\chi_L^2 = \chi_{1-\alpha/2}^2</m> and 
      <m>\chi_R^2 = \chi_{\alpha/2}^2</m> that correspond to <m>90</m><percent/> degree of 
      confidence and the sample size <m>n = 28.</m></p><p><m>\chi_L^2 =</m> <fillin name="AnSwEr0001" characters="10"/> <m>\ \ \ \ </m>
      <m>\chi_R^2 =</m> <fillin name="AnSwEr0002" characters="10"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=38&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_20.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=38&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_20.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=38&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_20.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=38&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_20.pg</server-url>

  </webwork-reps></exercise>
</p><p>Continuing the previous example, suppose now that you have n=400 data values and suppose you have computed from those a sample variance of <m>s^2 = 479.5</m>.  Then, the only change in the calculation is the two chi-square statistic values. For 95% but now with 399 degrees of freedom
<m>\chi_{0.025}^2 = 345.55</m> and <m>\chi_{0.975}^2 = 456.24</m>.  

Therefore
<me> E_1 = \frac{8 \cdot 479.5}{456.24} \approx 419.3</me>
and
<me> E_2 = \frac{8 \cdot 479.5}{345.55} \approx 553.7.</me>
Hence, you are 95% certain that 
<me>419.24 \lt \sigma^2 \lt 553.7.</me>
By taking square roots you get
<me>20.48 \lt \sigma \lt 23.53</me>
which is a relatively tight confidence interval.  Notice, these are also completely contained in the confidence intervals from the previous small n example.
</p></example>
</p>
        <p>
Similar to above, another choice to estimate <m>\sigma ^2</m> is to use a one sided confidence interval. If you want to find one of these, continue as described above but just leave one endpoint off.  Indeed, 
<me>\sigma^2 \lt E_2</me>
can be determined using 
<me> F(\chi^2_{\alpha} ) = F \left ( \frac{(n-1)S^2}{E_2} \right ) = \alpha</me>
and 
<me>E_1 \lt \sigma^2 </me>
can be determined using
<me> F(\chi^2_{1-\alpha} ) = F \left ( \frac{(n-1)S^2}{E_1} \right ) = 1 - \alpha.</me>


<example><title> - One-sided Confidence intervals for <m>\sigma^2</m></title><p>
</p></example>
</p>
        <p>You can, of course, use the formula to work out the sample size needed in order to have a sufficiently narrow confidence interval
</p>
        <p>
<exercise><title>WebWork</title><webwork-reps xml:id="extracted-webwork-39" ww-id="webwork-39">
    <pg source="Library/Rochester/setStatistics3Estimates/ur_stt_3_22.pg"/>

      
    <static source="Library/Rochester/setStatistics3Estimates/ur_stt_3_22.pg" seed="39">
      <statement><p>Find the minimum sample size needed to be <m>95</m><percent/>  confident that the sample 
      variance is within <m>20</m><percent/> of the population variance.</p><p><fillin name="AnSwEr0001" characters="6"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=39&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_22.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=39&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_22.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=39&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_22.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=39&amp;sourceFilePath=Library/Rochester/setStatistics3Estimates/ur_stt_3_22.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
Finally, to determine a confidence interval for <m>\sigma</m>, proceed using the protocols described above and simply take the square root on the resulting interval.

<example><title> - Confidence intervals for <m>\sigma</m></title><p>
</p></example>

</p>
      </section>
      <section>
        <title>Exercises</title>
        <p>
<exercise><title> - Basic Confidence interval for p</title><p>
Given Y = 30 successes in n = 100 trials, determine a 90% confidence interval for the unknown value for p.  
<solution><p>
<m>\tilde{p} = 0.3</m> and <m>z_{0.05} = 1.645</m> gives
<me>0.3 - 1.645 \sqrt{\frac{0.3 \cdot 0.7}{100}} \lt p \lt 0.3 + 1.645 \sqrt{\frac{0.3 \cdot 0.7}{100}}</me>
or
<me>0.225 \lt p \lt 0.375.</me>
</p></solution>
</p></exercise>

<exercise><title> - Sample Size for confidence interval for p</title><p>
Given a preliminary estimate <m>\tilde{p_0} = 0.23</m>, determine the same size needed for determine a 95% confidence interval for p with margin of error 0.02.
<solution><p>
Using <m>z_{0.025} = 1.96</m>,
<me>n \gt \big ( \frac{1.96}{0.02} \big )^2 \cdot 0.23 \cdot 0.77 \approx 1700.87</me>
and so pick at least 1701 as the sample size.
</p></solution>
</p></exercise>

<exercise><title> - Voting projection</title><p>Randomly polling 3200 eligible voters for governor in a particular state resulted in finding that 1590 favored your candidate. Determine an appropriate 95% confidence interval for the true proportion p of voters who favor your candidate. Noting that <m>\tilde{p}</m> in this instance is smaller than 50%, write a short paragraph regarding what you might conclude from this confidence interval regarding your candidate's chances in winning the election.

<solution><p>
Note that although the point estimate is below 50%, the confidence interval includes the possibility that the actual value for p is greater than 50%. So, you cannot conclude that your candidate will either win or lose.
</p></solution>
</p></exercise>

<exercise><title> - Basic Confidence interval for the mean</title><p>Given a sample mean of <m>\overline{x} = 25.3</m> with n = 121 and sample variance <m>s^2 = 12.1</m>, determine a 99% confidence interval for the true mean <m>\mu</m>.
<solution><p>Using <m>z_{0.005} = 2.576</m> and <m>s = \sqrt{12.1} \approx 3.4786</m> gives a confidence interval 
<me>25.3 - 2.576 \cdot \frac{3.4786}{11} \lt \mu \lt 25.3 + 2.576 \cdot \frac{3.4786}{11}</me>
or 
<me>24.4854 \lt \mu \lt 26.1148.</me>
</p></solution>
</p></exercise>

<exercise><title> - Confidence Interval Experiment</title><p>

</p></exercise>
Roll two regular pair of dice 35 times, recording the sum of the dots for each roll.  Using the data from your sample, determine the corresponding sample mean and sample variance.  Using this data, create a 95% confidence interval for the population mean and a 95% "centered" confidence interval for the standard deviation. Once complete, compare your results with what you know should be the correct population statistics an appropriate "hat" distribution. (You might want to use the chi-square calculator provided earlier in this text.)
</p>
        <p>
Go back over your 35 rolls and count the number of 7's or 11's rolled. Determine a corresponding relative frequency for this outcome. Using this data, create a 95% confidence interval for the theoretical proportion of success p.  Compare your result with what you know should be the correct theoretical p. 
</p>
        <p>
Repeat this exercise but this time roll 105 times.  Notice how these differ from the confidence intervals created with the smaller set.  Write a paragraph describing how these compare and whether one is better or not than the other.
</p>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="HypothesisTesting">
      <title>Hypothesis Testing</title>
      <section>
        <title>Introduction</title>
        <p>
When creating confidence intervals, you started with a sample and used the sample statistic (sample mean, relative frequency, sample variance, etc.) to anchor an interval which (with high possibility) contains the corresponding population statistic <m>\mu, p, \sigma^2</m>, etc. In this section, we instead start with an educated guess for one of the population statistics <m>\mu, p, \sigma^2</m> and then statistically compare that value with the subsequently collected sample statistic.
</p>
        <p>
The educated guess noted above is often called the "null hypothesis" and should be considered as a guess that one tries to disprove if possible by using a subsequent statistical sample.
</p>
      </section>
      <section>
        <title>Hypotheses and Errors</title>
        <p>
In formulating a hypothesis, you will be making a declarative statement (a proposition) that has an actual truth value. That is, it is either true or it is not true in real life. However, since we will assess that truth using a test sample then measuring that truth value will never be 100% certain in the same manner that confidence intervals can never include 100% of the possible choices for a particular statistic. Hence, it is possible for you to make an incorrect conclusion.
</p>
        <p>
In general, there are four different outcomes that are possible when testing a hypothesis:
<ul><li>Your hypothesis is true and you determine that it is true.</li><li>Your hypothesis is false but you determine that it is true.</li><li>Your hypothesis is true but you determine that it is false.</li><li>Your hypothesis is false and you determine that it is false.</li></ul>
The first and last cases are "good" since you have accurately determined the truth of the hypothesis. The second and third are however bad since you either believe something that is not true or you don't believe something that is true. We would like to minimize the likelihood of allowing these last two possibilities.
</p>
        <p>
Toward that end, let's consider the case where the hypothesis is true but you determine (in error) that it is false. This is called a Type I error and we will designate the probability of this error by <m>\alpha</m>. To lower the risk of a Type I error, you will want to make <m>\alpha</m> smaller.  In general, <m>\alpha</m> is also called "the significance level" with <m>\alpha = 0.05</m> a common choice with 0.01 and 0.10 also sometimes used. In general, any value between 0 and 1 is ok but large values mean large likelihood for error so choosing a value closer to 0 is preferred.
</p>
        <p>
In a similar manner, consider the case where the hypothesis is false but you determine (in error) that it is true. This is called a Type II error and will be denote the probability of a Type II error by <m>\beta</m>. Again, your goal is to make the risk of a Type II error smaller and therefore want <m>\beta</m> to be as small as possible.
</p>
        <p>
In the following sections you will play around with minimizing Type I and Type II errors. Type I errors will be minimized by simply choosing a smaller value for <m>\alpha</m> when working through the formulas. Type II errors will be minimized by talking (if possible) a larger sample size when computing the needed sample statistics. 
</p>
        <p>
Toward that end, you will compose in each case a <em>Null Hypothesis</em> (denoted <m>N_0</m>). This statement is what you will test for truth. You will also compose an <em>Alternate Hypothesis</em> (denoted <m>N_a</m>) that is often the logical complement (but not always) of <m>N_0</m>. The null hypothesis is often a statement corresponding to the likelihood that observations occur purely by chance while the alternate hypothesis will often indicate that outcomes are not actually random but are influenced by some (possibly unknown) causes.  If our sample shows that the null hypothesis <m>N_0</m> is false, then we will accept the alternate <m>N_a</m>. If this is a bad decision then it will be true that the hypothesis is true but you will have determined that it is false...that is, made a Type I error. 
</p>
        <p>
To avoid ever making an Type II error, often often never "accepts" the null hypothesis <m>N_0</m> even if the sample does not conclude that it is false. In other words, if you do this then you will never allow yourself to determine that <m>N_0</m> is true.  Seems odd but this is one way to avoid ever worrying much about type II errors. The best way to avoid this blind spot is to use relatively large test samples and in doing so you will minimize the likelihood of type II.
</p>
        <p>
So, our plan of attack is to find some way to determine, from a sample, the amount of Type I error we might make. For a given problem, from the sample, you will create a specific estimate for Type I error...called a p-statistic...and compare to the chosen significance level <m>\alpha</m>. Sounds easy enough?
</p>
        <p>Finally, you will notice in each of the instances presented that the form of the solution method will be very similar to the forms we used in creating confidence intervals. The difference is that for hypothesis testing we <em>assume</em> the value in the middle and test to see whether the sample statistic is in one of the tails so that we can reject rather than with confidence intervals we assume as sample statistic is in the middle and then use that sample to create boundaries within which the theoretical population statistic <em>must</em> like with high confidence.
</p>
      </section>
      <section>
        <title>Hypothesis Test for one proportion</title>
        <p>
In this section, you will consider the following options for null hypothesis and corresponding alternate hypothesis with respect to the unknown value p:
<me> H_0 : p = p_0 \\ H_a : p \neq p_0</me>
or
<me> H_0 : p \le p_0 \\ H_a : p \gt p_0</me>
or 
<me> H_0 : p \ge p_0 \\ H_a : p \lt p_0.</me>
For any given problem, we choose only one of these three options.
The first is called a "two-tailed" test since the alternate hypothesis can not be equal if it is actually larger or smaller. The last two are called "one-tailed" tests since the alternate hypothesis only allows for being on one side.  Note that some people will write all of these null hypothesis options using equality but the alternate hypothesis determines the number of tails.
</p>
        <p>
From the Central Limit Theorem, you found that every interesting distribution eventually becomes approximately normal. This includes the binomial distribution with mean <m>\mu = n p_0</m> and variance <m>\sigma^2 = n p_0 (1-p_0)</m>. Hence, the <em>z-statistic</em>
<me> Z = \frac{X - n p_0}{\sqrt{n p_0(1-p_0)}} = \frac{p - p_0}{\sqrt{p_0(1-p_0)/n}}</me>
is approximately standard normal and so probabilities on this statistic can be computed as needed using the normal distribution.
</p>
        <p>
Let's look at an example for this by considering:
<me>H_0: p = 0.20</me>
vs
<me>H_a: p \ne 0.20.</me>
Tests like this are called <em>two-tailed</em> since there are two ways to reject the null hypothesis: we find that p should be less than 0.2 or we find that p should be greater than 0.2.
</p>
        <p>
To test our hypothesis, let's now chose a significance level of <m>\alpha = 0.05</m> and take a sample. Presuming we actually do this, let's assume that we find that out of n=100 sample values we get X = 27 successes. Hence, our actual test statistic is <m>p = \frac{27}{100} = 0.27</m>.
</p>
        <p>
So, in this case we have
<me> \sigma = \sqrt{\frac{p_0(1-p_0)}{n}} = \sqrt{\frac{0.2 \cdot 0.8}{100}} = 0.04</me>
and the z-statistic (using the normal distribution) for the sample statistic of p = 0.27 is
<me>z = \frac{0.27 - 0.2}{0.04} = 1.75.</me>
Remember, the alternate hypothesis has two tails so to determine the P value we need to determine from the normal distribution 
<me>P(Z \gt 1.75) + P(Z \lt -1.75)</me>
and find that this has probability approximately 0.0392 + 0.0392 = 0.0784.  However, this P value is greater than our significance level <m>\alpha = 0.05</m> so we cannot reject the null hypothesis at the 5 percent significance level. However, if we had chosen initially to use a 10 percent significance level then we would have rejected the null hypothesis and accepted the alternate.
</p>
        <p>
<exercise><title>WebWork - two tailed test</title><introduction><p>
		Two-tailed test for p.
		</p></introduction><webwork-reps xml:id="extracted-webwork-40" ww-id="webwork-40">
    <pg source="Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_03_InferencePropn.pg"/>

      
    <static source="Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_03_InferencePropn.pg" seed="40">
      <statement><p>An article in the Washington Post on March 16, 1993 stated that nearly 45 
      percent of  all Americans have brown eyes.  A random sample of <m>n = 
      80</m> C of I 
      students found 30 with brown eyes.</p><p>We test</p><p><m>H_0: p = .45</m></p><p><m>H_a: p \neq .45</m></p><p>(a) What is the <m>z</m>-statistic for this test? <m/>
      <fillin name="AnSwEr0001" characters="10"/></p><p>(b) What is the P-value of the test?  <m/>
      <fillin name="AnSwEr0002" characters="10"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=40&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_03_InferencePropn.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=40&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_03_InferencePropn.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=40&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_03_InferencePropn.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=40&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_03_InferencePropn.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
<exercise><title>WebWork</title><introduction><p>
		One-tailed test for p. Notice, in this case you will only compute z-score probability for one tail and not both tails.
		</p></introduction><webwork-reps xml:id="extracted-webwork-41" ww-id="webwork-41">
    <pg source="Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_10_InferencePropn.pg"/>

      
    <static source="Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_10_InferencePropn.pg" seed="41">
      <statement><p>A noted psychic was tested for ESP.  The psychic was presented with 
      220 cards face down and was asked to determine if the card was one of 
      5 symbols: a star, cross, circle, square, or three wavy lines.  The psychic 
      was correct in 52 cases.  Let <m>p</m> represent the probability that 
      the psychic correctly identifies the symbol on the card in a random trial.  
      Assume the 220 trials can be treated as an SRS from the population of 
      all guesses.</p><p>To see if there is evidence that the psychic is doing better than just 
      guessing, we test</p><p><m>H_0: p = .2</m></p><p><m>H_a: p &gt; .2</m></p><p>(a) What is the <m>z</m>-statistic for this test? <m/>
      <fillin name="AnSwEr0001" characters="10"/></p><p>(b) What is the P-value of the test?  <m/>
      <fillin name="AnSwEr0002" characters="10"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=41&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_10_InferencePropn.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=41&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_10_InferencePropn.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=41&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_10_InferencePropn.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=41&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch19InferencePropn/19Stats_10_InferencePropn.pg</server-url>

  </webwork-reps></exercise>
</p>
      </section>
      <section>
        <title>Hypothesis Test for one mean</title>
        <p>
In this section, you will consider the following options for null hypothesis and corresponding alternate hypothesis with respect to the unknown value <m>\mu</m>:
<me> H_0 : \mu = \mu_0 \\ H_a: \mu \neq \mu_0</me>
or
<me> H_0 : \mu \le \mu_0 \\ H_a: \mu \gt \mu_0</me>
or
<me> H_0 : \mu \ge \mu_0 \\ H_a:\mu \lt \mu_0</me>
Again, we choose only one of these three options and as before the first is called a "two-tailed" test and the last two are called "one-tailed" tests.  Note that some people will write all of these null hypothesis options using equality but the alternate hypothesis determines the number of tails.

</p>
        <p>
Once again, if the test sample size is sufficiently large and the standard deviation <m>\sigma</m> of the underlying distribution is known, one can use the normal distribution to compute probabilities. If the test sample size is relatively small or if <m>\sigma</m> is not known (and therefore is approximated by the sample standard deviation s), then the t-distribution can be utilized to compute probabilities. We will only consider using the t-distribution to compute p-values. 
</p>
        <p>
The Standard Error <m>\sigma_e</m> is given by
<me>\sigma_e = \frac{s}{\sqrt{n}}</me>
where s is the standard deviation of the sample. For this presentation, we will assume that the actual population is relatively large relative to the sample size. In cases where this is not true, an adjustment (not presented here) will need to be made when computing <m>\sigma_e</m>.
</p>
        <p>
To determine the p-value for a given sample with sample mean <m>\overline{x}</m>, 
<me>t = \frac{\overline{x}-\mu}{\frac{s}{\sqrt{n}}}</me>
is a t-variable with n-1 degrees of freedom. Therefore, probabilities on t can be computed using the t-distribution.
</p>
        <p>
Consider a Two-tailed Hypothesis test for <m>\mu</m> using
<me> H_0 : \mu = 200 \\ H_a: \mu \neq 200</me>
using a sample of size n = 49 and with a resulting mean of <m>\overline{x} = 206</m>, a sample standard deviation of <m>s = 15</m>, and a significance level of <m>\alpha = 0.01</m>.
</p>
        <p>
The standard error for this test is
<me>\sigma_e = \frac{15}{\sqrt{49}} = \frac{15}{7}</me>
and so using the t-distribution with degrees of freedom n-1 = 48 yields a t-statistic of 
<me>t = \frac{\overline{x} - 200}{\sigma_e} = \frac{206-200}{\frac{15}{7}} = \frac{14}{5} = 2.80.</me>
To compute the p-value, 
<me>P(t \gt 2.80) + P(t \lt 2.80) \approx 0.0037 + 0.0037 = 0.0074.</me>
Since this p-value is less than our significance level <m>\alpha = 0.01</m> then you can reject the null hypothesis and accept the alternate.
</p>
        <p>
<exercise><webwork-reps xml:id="extracted-webwork-42" ww-id="webwork-42">
    <authored>
      
        <setup><pg-code>
          
          </pg-code></setup>
        <statement><p>
      A random sample of 10 observations was drawn from a large normally distributed population. The data is below.
      </p><p>
      22 20 22 20 25 18 22 23 19 18
      </p><p>
      To determine if you can infer at the 4% significance level that the population mean is not equal to 22, complete the steps below:
      </p><p>
      The value of the standardized test statistic: <var name="-1.52379841858" width="10"/>
      </p><p>
      Using interval notation with <m>\infty</m> written as "infty" and <m>\cup</m> written as "U" (capital u), determine each of the following: 
      </p><p>
      The rejection region for the standardized test statistic: <var name="(-infty,-2.39844)U(2.39844,infty)" width="30"/>
      </p><p>
      The p-value is <var name="0.161894" width="10"/> 
      </p><p>
      Your decision for the hypothesis test therefore would be to not reject the null hypothesis <m>H_0</m>.
      </p></statement>
        <solution/>
      
    </authored>

    <pg>
      #######################################
      ###    Generated from PreTeXt source   
      ###    on 2018-11-07T13:06:50-06:00    
      ###                                    
      ###   http://mathbook.pugetsound.edu   
      ###                                    
      #######################################
      ## DBsubject()
      ## DBchapter()
      ## DBsection()
      ## Level()
      ## KEYWORDS()
      ## TitleText1(Essentials of Mathematical Probability and Statistics)
      ## EditionText1()
      ## AuthorText1(John Travis)
      ## Section1(not reported)
      ## Problem1(11.4.1)
      ## Author()
      ## Institution()
      ## Language(en-US)
      
      DOCUMENT();
      
      ############################################################
      # Load Macros
      ############################################################
      loadMacros(
        "PGstandard.pl",
        "MathObjects.pl",
        "PGML.pl",
        "AnswerFormatHelp.pl",
        "PGcourse.pl",
      );
      
      ############################################################
      # Header
      ############################################################
      COMMENT('Authored in PreTeXt');
      TEXT(beginproblem());
      
      ############################################################
      # PG Setup
      ############################################################
      Context('Numeric');
      
      ############################################################
      # Body
      ############################################################
      
      BEGIN_PGML
      A random sample of 10 observations was drawn from a large normally distributed population. The data is below.
      
      22 20 22 20 25 18 22 23 19 18
      
      To determine if you can infer at the 4% significance level that the population mean is not equal to 22, complete the steps below:
      
      The value of the standardized test statistic: [__________]{-1.52379841858}
      
      Using interval notation with [`\infty`] written as "infty" and [`\cup`] written as "U" (capital u), determine each of the following:
      
      The rejection region for the standardized test statistic: [__]{(-infty,-2.39844)U(2.39844,infty)}{width =&gt; 30}
      
      The p-value is [__________]{0.161894}
      
      Your decision for the hypothesis test therefore would be to not reject the null hypothesis [`H_0\text{.}`]
      
      END_PGML
      
      ############################################################
      # Solution
      ############################################################
      
      BEGIN_PGML_SOLUTION
      
      END_PGML_SOLUTION
      
      ############################################################
      # End Problem
      ############################################################
      
      ENDDOCUMENT();
      
    </pg>

      
    <static seed="42">
      <statement><p>A random sample of 10 observations was drawn from a large normally distributed population. The data is below.</p><p>22 20 22 20 25 18 22 23 19 18</p><p>To determine if you can infer at the 4<percent/> significance level that the population mean is not equal to 22, complete the steps below:</p><p>The value of the standardized test statistic: <fillin name="AnSwEr0001" characters="10"/></p><p>Using interval notation with <m>\infty</m> written as <lq/>infty<rq/> and <m>\cup</m> written as <lq/>U<rq/> (capital u), determine each of the following:</p><p>The rejection region for the standardized test statistic: <fillin name="AnSwEr0002" characters="30"/></p><p>The p-value is <fillin name="AnSwEr0003" characters="10"/></p><p>Your decision for the hypothesis test therefore would be to not reject the null hypothesis <m>H_0\text{.}</m></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=42&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkEgcmFuZG9tIHNhbXBsZSBvZiAxMCBvYnNlcnZhdGlvbnMgd2FzIGRyYXduIGZyb20gYSBsYXJnZSBub3JtYWxseSBkaXN0cmlidXRlZCBwb3B1bGF0aW9uLiBUaGUgZGF0YSBpcyBiZWxvdy4KCjIyIDIwIDIyIDIwIDI1IDE4IDIyIDIzIDE5IDE4CgpUbyBkZXRlcm1pbmUgaWYgeW91IGNhbiBpbmZlciBhdCB0aGUgNCUgc2lnbmlmaWNhbmNlIGxldmVsIHRoYXQgdGhlIHBvcHVsYXRpb24gbWVhbiBpcyBub3QgZXF1YWwgdG8gMjIsIGNvbXBsZXRlIHRoZSBzdGVwcyBiZWxvdzoKClRoZSB2YWx1ZSBvZiB0aGUgc3RhbmRhcmRpemVkIHRlc3Qgc3RhdGlzdGljOiBbX19fX19fX19fX117LTEuNTIzNzk4NDE4NTh9CgpVc2luZyBpbnRlcnZhbCBub3RhdGlvbiB3aXRoIFtgXGluZnR5YF0gd3JpdHRlbiBhcyAiaW5mdHkiIGFuZCBbYFxjdXBgXSB3cml0dGVuIGFzICJVIiAoY2FwaXRhbCB1KSwgZGV0ZXJtaW5lIGVhY2ggb2YgdGhlIGZvbGxvd2luZzoKClRoZSByZWplY3Rpb24gcmVnaW9uIGZvciB0aGUgc3RhbmRhcmRpemVkIHRlc3Qgc3RhdGlzdGljOiBbX117KC1pbmZ0eSwtMi4zOTg0NClVKDIuMzk4NDQsaW5mdHkpfXt3aWR0aD0%2BMzB9CgpUaGUgcC12YWx1ZSBpcyBbX19fX19fX19fX117MC4xNjE4OTR9CgpZb3VyIGRlY2lzaW9uIGZvciB0aGUgaHlwb3RoZXNpcyB0ZXN0IHRoZXJlZm9yZSB3b3VsZCBiZSB0byBub3QgcmVqZWN0IHRoZSBudWxsIGh5cG90aGVzaXMgW2BIXzBcdGV4dHsufWBdCgoKRU5EX1BHTUwKCkJFR0lOX1BHTUxfU09MVVRJT04KCkVORF9QR01MX1NPTFVUSU9OCgpFTkRET0NVTUVOVCgpOw%3D%3D</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=42&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkEgcmFuZG9tIHNhbXBsZSBvZiAxMCBvYnNlcnZhdGlvbnMgd2FzIGRyYXduIGZyb20gYSBsYXJnZSBub3JtYWxseSBkaXN0cmlidXRlZCBwb3B1bGF0aW9uLiBUaGUgZGF0YSBpcyBiZWxvdy4KCjIyIDIwIDIyIDIwIDI1IDE4IDIyIDIzIDE5IDE4CgpUbyBkZXRlcm1pbmUgaWYgeW91IGNhbiBpbmZlciBhdCB0aGUgNCUgc2lnbmlmaWNhbmNlIGxldmVsIHRoYXQgdGhlIHBvcHVsYXRpb24gbWVhbiBpcyBub3QgZXF1YWwgdG8gMjIsIGNvbXBsZXRlIHRoZSBzdGVwcyBiZWxvdzoKClRoZSB2YWx1ZSBvZiB0aGUgc3RhbmRhcmRpemVkIHRlc3Qgc3RhdGlzdGljOiBbX19fX19fX19fX117LTEuNTIzNzk4NDE4NTh9CgpVc2luZyBpbnRlcnZhbCBub3RhdGlvbiB3aXRoIFtgXGluZnR5YF0gd3JpdHRlbiBhcyAiaW5mdHkiIGFuZCBbYFxjdXBgXSB3cml0dGVuIGFzICJVIiAoY2FwaXRhbCB1KSwgZGV0ZXJtaW5lIGVhY2ggb2YgdGhlIGZvbGxvd2luZzoKClRoZSByZWplY3Rpb24gcmVnaW9uIGZvciB0aGUgc3RhbmRhcmRpemVkIHRlc3Qgc3RhdGlzdGljOiBbX117KC1pbmZ0eSwtMi4zOTg0NClVKDIuMzk4NDQsaW5mdHkpfXt3aWR0aD0%2BMzB9CgpUaGUgcC12YWx1ZSBpcyBbX19fX19fX19fX117MC4xNjE4OTR9CgpZb3VyIGRlY2lzaW9uIGZvciB0aGUgaHlwb3RoZXNpcyB0ZXN0IHRoZXJlZm9yZSB3b3VsZCBiZSB0byBub3QgcmVqZWN0IHRoZSBudWxsIGh5cG90aGVzaXMgW2BIXzBcdGV4dHsufWBdCgoKRU5EX1BHTUwKCkVORERPQ1VNRU5UKCk7</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=42&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkEgcmFuZG9tIHNhbXBsZSBvZiAxMCBvYnNlcnZhdGlvbnMgd2FzIGRyYXduIGZyb20gYSBsYXJnZSBub3JtYWxseSBkaXN0cmlidXRlZCBwb3B1bGF0aW9uLiBUaGUgZGF0YSBpcyBiZWxvdy4KCjIyIDIwIDIyIDIwIDI1IDE4IDIyIDIzIDE5IDE4CgpUbyBkZXRlcm1pbmUgaWYgeW91IGNhbiBpbmZlciBhdCB0aGUgNCUgc2lnbmlmaWNhbmNlIGxldmVsIHRoYXQgdGhlIHBvcHVsYXRpb24gbWVhbiBpcyBub3QgZXF1YWwgdG8gMjIsIGNvbXBsZXRlIHRoZSBzdGVwcyBiZWxvdzoKClRoZSB2YWx1ZSBvZiB0aGUgc3RhbmRhcmRpemVkIHRlc3Qgc3RhdGlzdGljOiBbX19fX19fX19fX117LTEuNTIzNzk4NDE4NTh9CgpVc2luZyBpbnRlcnZhbCBub3RhdGlvbiB3aXRoIFtgXGluZnR5YF0gd3JpdHRlbiBhcyAiaW5mdHkiIGFuZCBbYFxjdXBgXSB3cml0dGVuIGFzICJVIiAoY2FwaXRhbCB1KSwgZGV0ZXJtaW5lIGVhY2ggb2YgdGhlIGZvbGxvd2luZzoKClRoZSByZWplY3Rpb24gcmVnaW9uIGZvciB0aGUgc3RhbmRhcmRpemVkIHRlc3Qgc3RhdGlzdGljOiBbX117KC1pbmZ0eSwtMi4zOTg0NClVKDIuMzk4NDQsaW5mdHkpfXt3aWR0aD0%2BMzB9CgpUaGUgcC12YWx1ZSBpcyBbX19fX19fX19fX117MC4xNjE4OTR9CgpZb3VyIGRlY2lzaW9uIGZvciB0aGUgaHlwb3RoZXNpcyB0ZXN0IHRoZXJlZm9yZSB3b3VsZCBiZSB0byBub3QgcmVqZWN0IHRoZSBudWxsIGh5cG90aGVzaXMgW2BIXzBcdGV4dHsufWBdCgoKRU5EX1BHTUwKCkJFR0lOX1BHTUxfU09MVVRJT04KCkVORF9QR01MX1NPTFVUSU9OCgpFTkRET0NVTUVOVCgpOw%3D%3D</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=42&amp;problemSource=RE9DVU1FTlQoKTsKbG9hZE1hY3JvcygiUEdzdGFuZGFyZC5wbCIsIk1hdGhPYmplY3RzLnBsIiwiUEdNTC5wbCIsIkFuc3dlckZvcm1hdEhlbHAucGwiLCJQR2NvdXJzZS5wbCIsKTtURVhUKGJlZ2lucHJvYmxlbSgpKTtDb250ZXh0KCdOdW1lcmljJyk7CgpCRUdJTl9QR01MCkEgcmFuZG9tIHNhbXBsZSBvZiAxMCBvYnNlcnZhdGlvbnMgd2FzIGRyYXduIGZyb20gYSBsYXJnZSBub3JtYWxseSBkaXN0cmlidXRlZCBwb3B1bGF0aW9uLiBUaGUgZGF0YSBpcyBiZWxvdy4KCjIyIDIwIDIyIDIwIDI1IDE4IDIyIDIzIDE5IDE4CgpUbyBkZXRlcm1pbmUgaWYgeW91IGNhbiBpbmZlciBhdCB0aGUgNCUgc2lnbmlmaWNhbmNlIGxldmVsIHRoYXQgdGhlIHBvcHVsYXRpb24gbWVhbiBpcyBub3QgZXF1YWwgdG8gMjIsIGNvbXBsZXRlIHRoZSBzdGVwcyBiZWxvdzoKClRoZSB2YWx1ZSBvZiB0aGUgc3RhbmRhcmRpemVkIHRlc3Qgc3RhdGlzdGljOiBbX19fX19fX19fX117LTEuNTIzNzk4NDE4NTh9CgpVc2luZyBpbnRlcnZhbCBub3RhdGlvbiB3aXRoIFtgXGluZnR5YF0gd3JpdHRlbiBhcyAiaW5mdHkiIGFuZCBbYFxjdXBgXSB3cml0dGVuIGFzICJVIiAoY2FwaXRhbCB1KSwgZGV0ZXJtaW5lIGVhY2ggb2YgdGhlIGZvbGxvd2luZzoKClRoZSByZWplY3Rpb24gcmVnaW9uIGZvciB0aGUgc3RhbmRhcmRpemVkIHRlc3Qgc3RhdGlzdGljOiBbX117KC1pbmZ0eSwtMi4zOTg0NClVKDIuMzk4NDQsaW5mdHkpfXt3aWR0aD0%2BMzB9CgpUaGUgcC12YWx1ZSBpcyBbX19fX19fX19fX117MC4xNjE4OTR9CgpZb3VyIGRlY2lzaW9uIGZvciB0aGUgaHlwb3RoZXNpcyB0ZXN0IHRoZXJlZm9yZSB3b3VsZCBiZSB0byBub3QgcmVqZWN0IHRoZSBudWxsIGh5cG90aGVzaXMgW2BIXzBcdGV4dHsufWBdCgoKRU5EX1BHTUwKCkVORERPQ1VNRU5UKCk7</server-url>

  </webwork-reps></exercise>
</p>
        <p>This is a repeat of the previous exercise but using the OPL
<exercise><title>WebWorK - two tailed test</title><webwork-reps xml:id="extracted-webwork-43" ww-id="webwork-43">
    <pg source="Library/UVA-Stat/setStat212-Homework10/stat212-HW10-08.pg"/>

      
    <static source="Library/UVA-Stat/setStat212-Homework10/stat212-HW10-08.pg" seed="43">
      <statement><p>A random sample of 10 observations was drawn from a large normally 
      distributed population.  The data is below.</p><p><me>\begin{array}{ccccccccccc} 
      19 \amp  25 \amp  20 \amp  21 \amp  20 \amp  20 \amp  28 \amp  28 \amp  25 \amp  26 
      \end{array}</me></p><p>Test to determine if we can infer at the 4<percent/> significance level that the 
      population mean is not equal to 23, filling in the requested 
      information below.</p><p>A. The value of the standardized test statistic: <fillin name="AnSwEr0001" characters="25"/></p><p><em> Note:</em> For the next part, your answer should use interval notation.  An
      answer of the form <m>(-\infty, a)</m> is expressed (-infty, a), an answer of the 
      form <m>(b, \infty)</m> is expressed (b, infty), and an answer of the 
      form <m>(-\infty, a) \cup (b, \infty)</m> is expressed (-infty, a)U(b, infty).</p><p>B. The rejection region for the standardized test statistic: <fillin name="AnSwEr0002" characters="40"/></p><p>C. The p-value is <fillin name="AnSwEr0003" characters="25"/></p><p>D. Your decision for the hypothesis test:</p><p><var form="buttons">
      <li>
      <p>Do Not Reject <m>H_0</m>.</p>
      </li>
      <li>
      <p>Reject <m>H_0</m>.</p>
      </li>
      <li>
      <p>Do Not Reject <m>H_1</m>.</p>
      </li>
      <li>
      <p>Reject <m>H_1</m>.</p>
      </li>
      </var></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=43&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework10/stat212-HW10-08.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=43&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework10/stat212-HW10-08.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=43&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework10/stat212-HW10-08.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=43&amp;sourceFilePath=Library/UVA-Stat/setStat212-Homework10/stat212-HW10-08.pg</server-url>

  </webwork-reps></exercise>
</p>
        <p>
Consider One-tailed Hypothesis test for <m>\mu</m> using an interesting application:
</p>
        <p>
Suppose that a manufacturer bottling a delicious beverage and the label indicates that the bottle contains 16 fluid ounces. Since providing the customer too little product might cause a significant negative reaction relative to the modest additional cost of providing a little too much, consider the following hypothesis test:
<me> H_0 : \mu = 16 \\ H_a: \mu \gt 200.</me>
To test this hypothesis at significance level <m>\alpha = 0.05</m>, you randomly pull out 20 bottles from the production line and accurately measure the amount of produce in each bottle. If the resulting average of these measurements is <m>\overline{x} = 16.05</m> ounces with a standard deviation of <m>s = 0.08</m> ounces, determine if you can safely make it known that more product is actually delivered in general to each consumer.
</p>
        <p>
The standard error for this test is
<me>\sigma_e = \frac{0.08}{\sqrt{20}} \approx 0.01789</me>
and using the t-distribution with n-1 = 19 degrees of freedom yields a t-statistic of
<me>t = \frac{\overline{x} - 16}{\sigma_e} = \frac{16.05-16}{0.01789} \approx 2.795.</me>
To compute the p-value, 
<me>P(t \gt 2.795) \approx 0.0058.</me>
Since this p-value is less than our significance level <m>\alpha = 0.05</m> (by a lot) then you can reject the null hypothesis and accept the alternate. It is safe therefore to say that customers can expect at least 16 ounces! However, note that some folks will still be stiffed since the standard deviation of 0.08 certainly means that some bottles have less than 16.05-0.08 ounces of beverage.  
</p>
        <p>
<exercise><title>WebWorK - one tailed test</title><webwork-reps xml:id="extracted-webwork-44" ww-id="webwork-44">
    <pg source="Library/CollegeOfIdaho/setStatistics_Ch17InferenceMean_t/17Stats_08_InferenceMean_t.pg"/>

      
    <static source="Library/CollegeOfIdaho/setStatistics_Ch17InferenceMean_t/17Stats_08_InferenceMean_t.pg" seed="44">
      <statement><p>Katie thinks that people living in a rural environment have a healthier lifestyle
      than other people.  She believes the average lifespan in the USA is 77 years. A random 
      sample of 20 obituaries from newspapers from rural towns in Idaho give <m>\bar{x} = 77.71</m> 
      and <m>s = 2.54</m>.  Does this sample provide evidence that people living in rural Idaho communities live 
      longer than 77 years?</p><p>(a) State the null and alternative hypotheses:  (Type "mu" for the symbol <m>\mu</m> , 
       e.g.  <em> mu <m>&gt;</m>1 </em> for the mean is greater than 1,  <em> mu <m>\lt </m> 1 </em> 
      for the mean is less than 1, <em> mu not = 1 </em> for the mean is not equal to 1)</p><p><m>H_0</m> : <fillin name="AnSwEr0001" characters="15"/></p><p><m>H_a</m> : <fillin name="AnSwEr0002" characters="15"/></p><p>(b) Find the test statistic, t =  <fillin name="AnSwEr0003" characters="10"/></p><p>(c) Answer the question: Does this sample provide evidence that people living in rural Idaho communities live 
      longer than 77 years? (Use a 10% level of significance)</p><p>(Type: Yes or No) <fillin name="AnSwEr0004" characters="10"/></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=44&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch17InferenceMean_t/17Stats_08_InferenceMean_t.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=44&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch17InferenceMean_t/17Stats_08_InferenceMean_t.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=44&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch17InferenceMean_t/17Stats_08_InferenceMean_t.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=44&amp;sourceFilePath=Library/CollegeOfIdaho/setStatistics_Ch17InferenceMean_t/17Stats_08_InferenceMean_t.pg</server-url>

  </webwork-reps></exercise>
</p>
      </section>
      <section>
        <title>Hypothesis Test for one variance</title>
        <p>
Proceeding in a similar manner, we can also perform hypothesis testing on variances using the <m>\chi^2</m>-distribution to determine probabilities.
<me> H_0 : \sigma^2 = \sigma_0^2  \\ H_a: \sigma^2 \neq \sigma_0^2</me>
or
<me> H_0 : \sigma^2 \ge \sigma_0^2  \\ H_a: \sigma^2 \lt \sigma_0^2</me>
or
<me> H_0 : \sigma^2 \le \sigma_0^2  \\ H_a: \sigma^2 \gt \sigma_0^2</me>

<me>\text{test statistic} = T = (n-1) \frac{s^2}{\sigma_0^2}</me> 

For two-tailed, reject if 
<me>T \gt \chi_{1-\alpha/2,n-1}^2 \text{ or } T \lt \chi_{\alpha/2,n-1}^2</me>
and for one-tailed to the right if
<me>T \gt \chi_{1-\alpha,n-1}^2</me>
and for one-tailed to the left if
<me>T \lt \chi_{\alpha,n-1}^2.</me>
Technically, for the two-tailed test you could pick T-values so that the total probability sums to <m>\alpha</m> in any fashion but generally this probability is split evenly between the two tails as noted above.
</p>
        <p>
<exercise><title>WebWorK</title><webwork-reps xml:id="extracted-webwork-45" ww-id="webwork-45">
    <pg source="Library/Rochester/setStatistics4HypothesisTesting/ur_stt_4_22.pg"/>

      
    <static source="Library/Rochester/setStatistics4HypothesisTesting/ur_stt_4_22.pg" seed="45">
      <statement><p>Use a <m>\alpha = 0.01</m> significance level to test the claim that <m>\sigma = 20</m>
      if the sample statistics include <m>n = 17,</m> <m>\overline{x} = 100,</m> and <m>s = 28.</m></p><p>The test statistic is <fillin name="AnSwEr0001" characters="15"/></p><p>The smaller critical number is <fillin name="AnSwEr0002" characters="15"/></p><p>The bigger critical number is <fillin name="AnSwEr0003" characters="15"/></p><p>What is your conclusion?</p><p><var form="buttons">
      <li>
      <p>There is sufficient evidence to warrant the rejection of the claim that
               the population standard deviation is equal to 20</p>
      </li>
      <li>
      <p>There is not sufficient evidence to warrant the rejection of the claim that 
               the population standard deviation is equal to 20</p>
      </li>
      </var></p></statement>
      
      
    </static>
      
    <server-url hint="yes" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=45&amp;sourceFilePath=Library/Rochester/setStatistics4HypothesisTesting/ur_stt_4_22.pg</server-url>

    <server-url hint="yes" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=45&amp;sourceFilePath=Library/Rochester/setStatistics4HypothesisTesting/ur_stt_4_22.pg</server-url>

    <server-url hint="no" solution="yes">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=45&amp;sourceFilePath=Library/Rochester/setStatistics4HypothesisTesting/ur_stt_4_22.pg</server-url>

    <server-url hint="no" solution="no">https://webwork-ptx.aimath.org/webwork2/html2xml?courseID=anonymous&amp;userID=anonymous&amp;password=anonymous&amp;course_password=anonymous&amp;answersSubmitted=0&amp;displayMode=MathJax&amp;outputformat=simple&amp;problemSeed=45&amp;sourceFilePath=Library/Rochester/setStatistics4HypothesisTesting/ur_stt_4_22.pg</server-url>

  </webwork-reps></exercise>
</p>
      </section>
      <!--
<section><title>Hypothesis Test for the difference of two means</title>

	<p><m> H_0 : \mu_1 = \mu_2</m>
	vs  <m> H_a : \mu_1 \neq \mu_2</m>
	</p>	
	
</section>
-->
      <section>
        <title>Summary</title>
        <p>
TBA
</p>
      </section>
      <section>
        <title>Exercises</title>
        <p>
TBA
</p>
      </section>
    </chapter>
    <!-- This file is part of the documentation of MathBook XML   -->
    <!--                                                          -->
    <!--    MathBook XML Author's Guide                           -->
    <!--                                                          -->
    <!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
    <!-- See the file COPYING for copying conditions.             -->
    <chapter xml:id="PowerSeriesReview">
      <title>Review of Calculus</title>
      <introduction>
        <p>This chapter is a review of power series results from Calculus.</p>
      </introduction>
      <section>
        <title>Geometric Series</title>
        <introduction><p>
		  Knowledge of the use of power series is very important when dealing with both 
		  probability functions. </p><md><mrow>S = \sum_{k=0}^{\infty} {x^k} = \frac{1}{1-x}</mrow></md> provided x is small is of utmost importance  
		<p>as is its extension know as the negative binomial series <m>( n \in \mathbb{N} )</m>.</p><md><mrow>NB = \sum_{k=0}^{\infty} (-1)^k \binom{-n + k - 1}{k} {x^k b^{-n-k}} = \frac{1}{(x+b)^n}</mrow></md><p>In this section, we review this series, develop its properties, and explore some of its extensions.</p></introduction>
        <subsection>
          <title>Geometric Series</title>
          <theorem xml:id="theorem-GeomSeries">
            <statement>
              <m> S = \sum_{k=0}^{\infty} {x^k} = \frac{1}{1-x}</m>
            </statement>
            <proof>
              <p>Consider the partial sum</p>
              <md>
                <mrow> S_n = \sum_{k=0}^{n} {x^k} = 1 + x + x^2 + ... + x^n </mrow>
                <mrow> (1-x)S_n = S_n - x S_n = 1 + x + x^2 + ... + x^n - (x + x^2 + ... + x^n + x^{n+1}) = 1 - x^{n+1} </mrow>
                <mrow> \Rightarrow S_n = \frac{1-x^{n+1}}{1-x} </mrow>
              </md>
              <p>and so as <m> n \rightarrow \infty </m>,</p>
              <md>
                <mrow> S_n \rightarrow S = \frac{1}{1-x} </mrow>
              </md>
            </proof>
          </theorem>
          <p>
		The interactive activity below shows how well the partial sums approximate <m>\frac{1}{1-x}</m>
		as the number of terms increases.
		</p>
          <sage>
            <input>
var('x,n,k')
f = 1/(1-x)
@interact
def _(n = slider(2,20,1,2)):
	Sn = sum(x^k,k,0,n)
	pretty_print(html('$S_n(x) = %s$'%str(latex(Sn))))
	G = plot(f,x,-1,0.9,color='black')
	G += plot(Sn,x,-1,0.9,color='blue')
	G += plot(abs(f-Sn),x,-1,0.9,color='red')
	G.show(title="Partial Sums (blue) vs Infinite Series (black) and Error (red)",figsize=(5,4))
</input>
          </sage>
        </subsection>
        <introduction/>
        <subsection>
          <title>Alternate Forms for the Geometric Series</title>
          <theorem>
            <title>Generalized Geometric Series</title>
            <statement>For <m>k \in \mathbb{N}, \sum_{k=M}^{\infty} {x^k} = \frac{x^M}{1-x}</m></statement>
            <proof>
              <md>
                <mrow>\sum_{k=M}^{\infty} {x^k} &amp; = x^M \sum_{k=0}^{\infty} {x^k}</mrow>
                <mrow> &amp; = x^M \frac{1}{1-x}</mrow>
                <mrow> &amp; = \frac{x^M}{1-x}</mrow>
              </md>
            </proof>
          </theorem>
          <example>
            <title>Integrating and Differentiating to get new Power Series</title>
            <p>The geometric power series is a nice function which is relatively easily differentiated and integrated. In doing so, one can obtain
					new power series which might also be very useful in their own right.  Here we develop a few which are of special interest.</p>
            <p>Let <m>f(x) = \sum_{k=0}^\infty x^k = \frac{1}{1-x}</m>.  Then,</p>
            <md>
              <mrow> f'(x) = \sum_{k=1}^{\infty} {kx^{k-1}} = \frac{1}{(1-x)^2}</mrow>
              <mrow> f''(x) = \sum_{k=2}^{\infty} {k(k-1)x^{k-1}} = \frac{2}{(1-x)^3}</mrow>
              <mrow> f^{(n)}(x) = \sum_{k=n}^{\infty} {k(k-1)...(k-n+1)x^{k-n}} = \frac{n!}{(1-x)^{n+1}}</mrow>
              <mrow> \int f(x) dx = \sum_{k=0}^{\infty} {\frac{x^{k+1}}{k+1}} = -ln(1-x)</mrow>
            </md>
          </example>
          <example>
            <title>Playing with the base</title>
            <md>
              <mrow>\sum_{k=0}^{\infty} {a^k x^k} &amp; = \sum_{k=0}^{\infty} {(ax)^k}</mrow>
              <mrow> &amp; = \frac{1}{1-ax}, |x| \lt \frac{1}{a}</mrow>
            </md>
            <p>or perhaps</p>
            <md>
              <mrow>\sum_{k=0}^{\infty} {(x-b)^k} = \frac{1}{1-(x-b)}, |x-b| \lt 1</mrow>
            </md>
          </example>
          <example>
            <title>Application: Converting repeating decimals to fractional form</title>
            <p>Consider this example:</p>
            <md>
              <mrow>2.48484848... &amp; = 2 + 0.48 + 0.0048 + 0.000048 + ...</mrow>
              <mrow> &amp;  = 2 + 0.48(1 + 0.01 + 0.0001 + ... ) = 2 + 0.48 \sum_{k=0}^\infty (0.01)^k</mrow>
            </md>
            <p>Therefore, applying the Geometric Series</p>
            <md>
              <mrow> 2.48484848... &amp; = 2 + 0.48 \frac{1}{1-0.01} </mrow>
              <mrow> &amp; = 2 + 0.48 \frac{100}{99} = 2 + \frac{48}{99} </mrow>
            </md>
          </example>
          <example>
            <title>Playing around with repeating decimals</title>
            <p>Certainly most students would agree that <m> 0.333333... = \frac{1}{3} </m>. So, what about <m>0.999999...</m>?  
			Simply follow the pattern above</p>
            <md>
              <mrow>0.999999... &amp; = 0.9 + 0.09 + 0.009 + 0.0009 + ... = 0.9(1 + 0.1 + 0.1^2 + 0.1^3 + ...</mrow>
              <mrow> &amp; = 0.9 \frac{1}{1-0.1} = 0.9 \frac{1}{0.9} = 1 </mrow>
            </md>
          </example>
        </subsection>
      </section>
      <section><title>Binomial Sums</title><p>
  The binomial series is also foundational. It is technically not a series since the sum_if finite 
  but we won’t bother with that for now.  
  It is given by </p><md><mrow>B = \sum_{k=0}^{n} {\binom{n}{k} a^k b^{n-k}}</mrow></md> provided n is a natural number.  

		<theorem xml:id="theorem-Binomial"><title>Binomial Theorem</title><statement>For <m> n \in \mathbb{N} </m>,  
				<m>\displaystyle {(a+b)^n = \sum_{k=0}^{n} {\binom{n}{k} a^k b^{n-k}}}</m></statement><proof><p>By induction:</p><p>Basic Step: n = 1 is trivial</p><p>Inductive Step:  Assume the statement is true as given for some <m>n \ge 1</m>.  
					Show <m>(a+b)^{n+1} = \sum_{k=0}^{n+1} {\binom{n+1}{k} a^k b^{n+1-k}}</m></p><md><mrow>(a+b)^{n+1} &amp; = (a+b)(a+b)^n</mrow><mrow> &amp; = (a+b)\sum_{k=0}^{n} {\binom{n}{k} a^k b^{n-k}}</mrow><mrow> &amp; = \sum_{k=0}^n \binom{n}{k} a^{k+1} b^{n-k} + \sum_{k=0}^n \binom{n}{k} a^k b^{n-k+1}</mrow><mrow> &amp; = \sum_{k=0}^{n-1} \binom{n}{k} a^{k+1} b^{n-k} + a^{n+1} + b^{n+1} + \sum_{k=1}^n \binom{n}{k} a^k b^{n-k+1}</mrow><p>and by using <m>j = k+1</m> yields</p><mrow> &amp; = \sum_{j=1}^n \binom{n}{j-1} a^j b^{n-(j-1)} + a^{n+1} + b^{n+1} + \sum_{k=1}^n \binom{n}{k} a^k b^{n+1-k}</mrow><mrow> &amp; = b^{n+1} + \sum_{k=1}^n \left [ \binom{n}{k-1} + \binom{n}{k} \right ] a^k b^{n+1-k} + a^{n+1}</mrow><mrow> &amp; = b^{n+1} + \sum_{k=1}^n \binom{n+1}{k} a^k b^{n+1-k} + a^{n+1}</mrow><mrow> &amp; = \sum_{k=0}^{n+1} \binom{n+1 }{k} a^k b^{n+1-k}</mrow></md></proof></theorem><title>Binomial Series</title><p>Consider <m>B(a,b) = \sum_{k=0}^{n} {\binom{n}{k} a^k b^{n-k}}</m>.  
		This finite sum_is known as the Binomial Series.</p><p>Show that <m>B(a,b) = (a+b)^n</m></p><p>Show that <m>B(1,1) = 2^n</m></p><p>Show that <m>B(-1,1) = 0</m></p><p>Show that <m>B(p,1-p) = 1</m></p><p>Easily, <m>B(x,1) = \sum_{k=0}^{n} {\binom{n}{k} a^k}</m></p><title>Trinomial Series</title><md><mrow>(a+b+c)^n = \sum_{k_1+k_2+k_3=n}^{} {\binom{n}{k_1,k_2,k_3} a^{k_1} b^{k_2} c^{k_3}} </mrow></md><p>where <m>\binom{n}{k_1,k_2,k_3} = \frac{n!}{k_1!k_2!k_3!}</m>. This can be generalized to any number 
		of terms to give what
		is know as a multinomial series.</p></section>
      <section>
        <title>Negative Binomial Series</title>
        <p>
          <m>(a+b)^{-n} = \sum_{k=0}^{\infty} {\binom{-n}{k} a^k b^{-n-k}}</m>
        </p>
        <theorem>
          <title>Alternate Form for Negative Binomial Series</title>
          <statement>
            <p>
              <m>(a+b)^{-n} = \sum_{k=0}^{\infty} {(-1)^k \binom{n+k-1}{k} a^k b^{-n-k}}</m>
            </p>
          </statement>
        </theorem>
      </section>
    </chapter>
  </book>
</mathbook>
