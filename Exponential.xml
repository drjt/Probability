<?xml version="1.0" encoding="UTF-8"?>

<!-- This file is part of the documentation of MathBook XML   -->
<!--                                                          -->
<!--    MathBook XML Author's Guide                           -->
<!--                                                          -->
<!-- Copyright (C) 2013-2016  Robert A. Beezer                -->
<!-- See the file COPYING for copying conditions.             -->

<chapter xml:id="PoissonExponential" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Poisson, Exponential, and Gamma Distributions</title>

<section><title>Introduction</title>
<p>
In this chapter, you will investigate the relationship between number of successes over some interval.  For each, one of these quantities will be fixed and the other one variable. First, consider the following:

<definition><title>Poisson Process</title>
<statement>A Poisson process is a course of action in which:
<ol>
	<li>Successes in non-overlapping subintervals are independent of each other.</li>
	<li>The probability of exactly one success in a sufficiently small interval of length h is proportional to h.  In notation, P(one success) = <m>\lambda h</m>.</li>
	<li>The probability of two or more successes in a sufficiently small interval is essentially 0.</li>
</ol>
</statement>
</definition>

You should presume these assumptions implicitly for the distributions discussed in this chapter.
</p>

</section>

<section><title>Poisson Distribution</title>
<p>
Consider a Poisson Process where you start with an interval of fixed length T and where X measures the variable number of successes, or changes, within a that interval. The resulting distribution of X will be called a Poisson distribution.

<theorem><title>Poisson Probability Function</title>
<statement>
<p>Assume X measures the number of successes in an interval [0,T] within some Poisson process. Then, 
<me>f(x) = \frac{\mu^x e^{-\mu}}{x!}</me>
for R = {0, 1, 2, ... }.
</p>
</statement>
<proof>
<p>
For a sufficiently large natural number n, break up the given interval [0,T] into n uniform parts each of width h = T/n.  Using the properties of Poisson processes, n very large implies h will be very small and eventually small enough so that 
<me>P(\text{exactly one success on a given interval}) = p = \lambda \frac{T}{n}.</me> 

However, since there are a finite number of independent intervals each with probability p of containing a success then you can use a Binomial distribution to evaluate the corresponding probabilities so long as n is finite. Doing so yields and taking the limit as n approaches infinity gives:
<md>
	<mrow>f(x) &amp; = P(\text{X changes in [0,T]}) </mrow>
	<mrow> &amp; = \lim_{n \rightarrow \infty} \binom{n}{x} p^x (1-p)^{n-x}</mrow>
	<mrow> &amp; = \lim_{n \rightarrow \infty} \binom{n}{x} (\frac{\lambda T}{n})^x (1-\lambda \frac{T}{n})^{n-x}</mrow>
	<mrow> &amp; = \lim_{n \rightarrow \infty} \frac{n(n-1)...(n-x+1)}{x!} ( \frac{\lambda T}{n})^x (1- \frac{\lambda T}{n})^{n-x}</mrow>
	<mrow> &amp; = \frac{(\lambda T)^x}{x!} \lim_{n \rightarrow \infty} \frac{n(n-1)...(n-x+1)}{n \cdot n \cdot ... \cdot n} (1-\lambda \frac{T}{n})^{n}(1-\lambda \frac{T}{n})^{-x}</mrow>
	<mrow> &amp; = \frac{(\lambda T)^x}{x!} \lim_{n \rightarrow \infty} (1-\frac{1}{n})...(1-\frac{x-1}{n})  (1- \frac{\lambda T}{n})^{n}(1- \frac{\lambda T}{n})^{-x}</mrow>
	<mrow> &amp; = \frac{(\lambda T)^x}{x!} 
	\lim_{n \rightarrow \infty} (1- \frac{\lambda T}{n})^{n}
	\lim_{n \rightarrow \infty} (1- \frac{\lambda T}{n})^{-x}</mrow>
	<mrow> &amp; = \frac{(\lambda T)^x}{x!} 
	\lim_{n \rightarrow \infty} (1- \frac{\lambda T}{n})^{n} \cdot 1</mrow>
	<mrow> &amp; = \frac{(\lambda T)^x}{x!} 
	e^{-\lambda T}</mrow>
</md>
</p>
</proof>
</theorem>

<theorem><title>Verify Poisson Probability Function</title>
<statement>
	<me>\sum_{x=0}^{\infty} \frac{(\lambda T)^x}{x!} e^{-\lambda T} = 1</me>
</statement>
<proof>
<p>Using the Power Series expansion for the natural exponential,
<md>
	<mrow> \sum_{x=0}^{\infty} f(x) &amp; = \sum_{x=0}^{\infty} \frac{(\lambda T)^x}{x!} e^{-\lambda T} </mrow>		
	<mrow> &amp; = e^{-\lambda T} \sum_{x=0}^{\infty} \frac{(\lambda T)^x}{x!} </mrow>
	<mrow> &amp; = e^{-\lambda T} e^{\lambda T}  </mrow>
	<mrow> &amp; = 1</mrow>
</md>
</p>
</proof>
</theorem>

<theorem><title>Statistics for Poisson</title>
<statement>
<me>\mu = \lambda T</me>
<me>\sigma^2 = \mu</me>
<me>\gamma_1 = \frac{1}{\sqrt{\mu}}</me>
<me>\gamma_2 = \frac{1}{\mu}+3</me>
</statement>
<proof>
<p> Using the f(x) generated in the previous theorem
<md>
	<mrow>\mu &amp; = E[X] </mrow>
	<mrow> &amp; = \sum_{x=0}^{\infty} x \cdot \frac{(\lambda T)^x}{x!} e^{-\lambda T}</mrow>
	<mrow> &amp; = \lambda T e^{-\lambda T} \sum_{x=1}^{\infty} \frac{(\lambda T)^{x-1}}{(x-1)!} </mrow>
	<mrow> &amp; = \lambda T e^{-\lambda T} \sum_{k=0}^{\infty} \frac{(\lambda T)^k}{k!} </mrow>
	<mrow> &amp; = \lambda T e^{-\lambda T} e^{\lambda T} </mrow>
	<mrow> &amp; = \lambda T </mrow>
</md>
which confirms the use of <m>\mu</m> in the original probability formula.
</p>
<p>
Continuing with <m>\mu = \lambda T</m>, the variance is given by
<md>
	<mrow>\sigma^2 &amp; = E[X(X-1)] + \mu - \mu^2 </mrow>
	<mrow> &amp; = \sum_{x=0}^{\infty} x(x-1) \cdot \frac{\mu^x}{x!} e^{-\mu} + \mu - \mu^2</mrow>
	<mrow> &amp; = e^{-\mu} \mu^2 \sum_{x=2}^{\infty} \frac{\mu^{x-2}}{(x-2)!} + \mu - \mu^2</mrow>
	<mrow> &amp; = e^{-\mu} \mu^2 \sum_{k=0}^{\infty} \frac{\mu^k}{k!} + \mu - \mu^2</mrow>
	<mrow> &amp; = \mu^2 + \mu - \mu^2 </mrow>
	<mrow> &amp; = \mu</mrow>
</md>

To derive the skewness and kurtosis, you can depend upon Sage...see the live cell below.
</p>

</proof>
</theorem>

<p>
<sage>
	<input>
var('x,mu')
assume(x,'integer')

f(x) =e^(-mu)*mu^x/factorial(x)
mu = sum(x*f,x,0,oo).factor()
M2 = sum(x^2*f,x,0,oo).factor()
M3 = sum(x^3*f,x,0,oo).factor()
M4 = sum(x^4*f,x,0,oo).factor()

pretty_print('Mean = ',mu)

v = (M2-mu^2).factor()
pretty_print('Variance = ',v)
stand = sqrt(v)

sk = ((M3 - 3*M2*mu + 2*mu^3)).factor()/stand^3
pretty_print('Skewness = ',sk)

kurt = (M4 - 4*M3*mu + 6*M2*mu^2 -3*mu^4).factor()/stand^4
pretty_print('Kurtosis = ',(kurt-3).factor(),'+3')
	</input>
</sage>
</p>
Approximation by binomial means you can also use Poisson to approximate Binomial for n sufficiently large.
</p>	
</section>



<section><title>Exponential Distribution</title>
	<p>
Once again, consider a Poisson Process where you start with an interval of variable length X so that X measures the interval needed in order to obtain a first success. The resulting distribution of X will be called an Exponential distribution.
	</p>


<p>
To derive the probability function for this distribution, consider finding f(x) by first considering F(x). This gives

<md>
	<mrow>F(x)&amp;  = P(X \le x)</mrow> 
	<mrow> &amp; = 1 - P(X \gt x)</mrow>
	<mrow> &amp; = 1 - P(\text{first change occurs after an interval of length x})</mrow>
	<mrow> &amp; = 1 - P(\text{no changes in the interval [0,x]})</mrow>
	<mrow> &amp; = 1 - \frac{(\lambda x)^0 e^{-\lambda x}}{0!}</mrow>
	<mrow> &amp; = 1 - e^{-\lambda x}</mrow>
</md>
where the discrete Poisson Probability Function is used to answer the probability of exactly no changes in the "fixed" interval [0,x]. Using this distribution function and taking the derivative yields
<me>f(x) = F'(x) = \lambda e^{-\lambda x}.</me>
</p>

<definition><title>Exponential Distribution Probability Function</title>
	<statement>
	<p>Given a Poisson process and a constant <m>\mu</m>, suppose X measures the variable interval length needed until you get a first success.  Then X has an exponential distribution with probability function
		<me>f(x) = \frac{1}{\mu} e^{-\frac{x}{\mu}}.</me>
	</p>
	</statement>
</definition>

<theorem><title>Verification of Exponential Probability Function</title>
	<statement>
		<me>\int_0^{\infty} \frac{1}{\mu} e^{-\frac{x}{\mu}} dx = 1</me>
	</statement>
	<proof>
		<p>
		<md>
			<mrow> &amp; \int_0^{\infty} \frac{1}{\mu} e^{-\frac{x}{\mu}} dx</mrow>
			<mrow> &amp; = \int_0^{\infty} e^{-u} dx</mrow>
			<mrow> &amp; = -e^{-u} \big |_0^{\infty} = 1</mrow>
		</md>
		</p>
	</proof>
</theorem>

<theorem><title>Distribution function for Exponential Distribution</title>
	<statement>
		<me>F(x) = 1 - e^{-\frac{x}{\mu}}</me>
	</statement>
	<proof>
	<p>
	Using <m>f(x) = \frac{1}{\mu} e^{-\frac{x}{\mu}}</m>, note
	<md>
		<mrow>F(x) &amp; = \int_0^x \frac{1}{\mu} e^{-\frac{u}{\mu}} du</mrow>
		<mrow> &amp; =  - e^{-\frac{u}{\mu}} \big |_0^x</mrow>
		<mrow> &amp; = 1 - e^{-\frac{x}{\mu}}</mrow>
	</md>
	</p>
	</proof>
</theorem>

<theorem><title>Derivation of Statistics for Exponential Distribution and Plotting</title>
<statement>
	<me>\sigma^2 = \mu^2</me>
	<me>\gamma_1 = 2</me>
	<me>\gamma_2 = 9</me>
</statement>
<proof>
	<p>
	For the mean, notice that
	<md>
		<mrow>\text{Mean} &amp; = \int_0^{\infty} x \cdot \frac{1}{\mu} e^{-\frac{x}{\mu}} </mrow>
		<mrow> &amp; = [ (1-x) e^{-\frac{x}{\mu}} ] \big |_0^{\infty} = \mu</mrow>
	</md>
	and so the use of <m>\mu</m> in f(x) is warranted.
	</p>
	<p>
	The remaining statistics are derived similarly using repeated integration by parts. The interactive Sage cell below calculates those for you automatically.
	</p>
</proof>
</theorem>

<p>
<sage>
	<input>
# Exponential Distribution
var('x,mu')
assume(mu>0)

f(x) =e^(-x/mu)/mu
mu = integral(x*f,x,0,oo).factor()
M2 = integral(x^2*f,x,0,oo).factor()
M3 = integral(x^3*f,x,0,oo).factor()
M4 = integral(x^4*f,x,0,oo).factor()

pretty_print('Mean = ',mu)

v = (M2-mu^2).factor()
pretty_print('Variance = ',v)
stand = sqrt(v)

sk = (((M3 - 3*M2*mu + 2*mu^3))/stand^3).simplify()
pretty_print('Skewness = ',sk)

kurt = (M4 - 4*M3*mu + 6*M2*mu^2 -3*mu^4).factor()/stand^4
pretty_print('Kurtosis = ',(kurt-3).factor(),'+3')
@interact
def _(m = slider(1,12,1/2,2,label='mu')):
    plot(f(mu=m),x,0,30).show(ymax=1)
	</input>
</sage>
</p>

<theorem><title>The Exponential Distribution yields a continuous memoryless model.</title>
<statement>
	<p>If X has an exponential distribution and a and b are nonnegative integers, then
	<me>P( X > a + b | X > b ) = P( X > a)</me>
	</p>
</statement>
<proof>
	<p>Using the definition of conditional probability,
	<md>
		<mrow>P( X > a + b | X > b ) &amp; = P( X > a + b \cap X > b ) \ P( X > b)</mrow>
		<mrow> &amp; = P( X > a + b ) / P( X > b)</mrow>
		<mrow> &amp; = e^{-(a+b)/ \mu} / e^{-b / \mu}</mrow>
		<mrow> &amp; = e^{-a/ \mu}</mrow>
		<mrow> &amp; = P(X > a)</mrow>
	</md>
	</p>
</proof>
</theorem>

</section>



<section><title>Gamma Distribution</title>
	<p>
Extending the exponential distribution model developed above, consider a Poisson Process where you start with an interval of variable length X so that X measures the interval needed in order to obtain the rth success for some natural number r. The resulting distribution of X will be called a Gamma distribution.


<definition><title>Gamma Function</title>
<statement>
	<me>\Gamma(t) = \int_0^{\infty} u^{t-1} e^{-u} du</me>
</statement>
</definition>

<theorem><title>Gamma Function on the natural numbers</title>
<statement>
<p>For <m>n \in \mathbb{N}</m>,
<me>\Gamma(n+1) = n!</me>
</p>
</statement>
<proof>
<p>
Letting n be a natural number and applying integration by parts one time gives
<md>
	<mrow>\Gamma(n+1) &amp; = \int_0^{\infty} u^n e^{-u} du</mrow>
	<mrow> &amp; = -u^n \cdot e^{-u} \big |_0^{\infty} + n \int_0^{\infty} u^{n-1} e^{-u} du </mrow>
	<mrow> &amp; = 0 - 0 + n \Gamma(n)</mrow>
</md>
Continuing using an inductive argument to obtain the final result.
</p>
</proof>
</theorem>

<p>To find the probability function for the gamma distribution, once again focus on the development of F(x). Assuming r is a natural number greater than 1 and noting that X measures the interval length needed in order to achieve the rth success
<md>
	<mrow>F(x) &amp; = P(X \le x)</mrow>
	<mrow> &amp; = 1 - P(X \gt x)</mrow>
	<mrow> &amp; = 1 - P(\text{fewer than r successes in [0,x]})</mrow>
	<mrow> &amp; = 1 - \big [ \frac{(\lambda x)^0 e^{-\lambda x}}{0!} + \frac{(\lambda x)^1 e^{-\lambda x}}{1!} + ... + \frac{(\lambda x)^{r-1} e^{-\lambda x}}{(r-1)!} \big ]</mrow>
	<mrow> &amp; = 1 - \sum_{k=0}^{r-1} \frac{(\lambda x)^k e^{-\lambda x}}{k!} </mrow>
</md>
where the discrete Poisson probability function is used on the interval [0,x]. The derivative of this function however is "telescoping" and terms cancel. Indeed,
<md>
	<mrow>F'(x) &amp; = \lambda e^{-\lambda x}/0!</mrow>
	<mrow> &amp; - \lambda e^{-\lambda x}/1! + \lambda x \cdot \lambda e^{-\lambda x}/1!</mrow>
	<mrow> &amp; - \lambda^2 2x e^{-\lambda x}/2! + \lambda^2 x^2 \cdot \lambda e^{-\lambda x}/2!</mrow>
	<mrow> &amp; - \lambda^3 3x^2 e^{-\lambda x}/3! + \lambda^3 x^3 \cdot \lambda e^{-\lambda x}/3!</mrow>
	<mrow> &amp; . . .</mrow>
	<mrow> &amp; - \lambda^{r-1} (r-1)x^{r-2} e^{-\lambda x}/(r-1)! + \lambda^{r-1} x^{r-1} \cdot \lambda e^{-\lambda x}/(r-1)!</mrow>
	<mrow> &amp; = \lambda^r x^{r-1} e^{-\lambda x}/(r-1)!</mrow>
</md>
where you can replace <m>(r-1)! = \Gamma(r)</m>.
</p>

<theorem><title>Mean</title>
<statement>
<p>
For this random variable, <m>E[X] = \mu</m> and so the use of <m>\mu</m> means the mean is the only parameter needed.
</p>
</statement>
</theorem>

<theorem><title>Gamma Distribution Probability Function</title>
<statement>If X measures the interval until the rth success, then
<me>f(x) =  \frac{x^{r-1} \cdot e^{-x / \mu}}{\Gamma(r) \cdot \mu^r}</me>
</statement>
</theorem>

<sage>
<input>
# Gamma Distribution Graphing
var('x,mu,r')
assume(mu>0)
assume(r,'integer')
@interact
def _(r=[2,3,6,12,24],mu=slider(1,12,1,5,label='mu')):
    f(x) =x^(r-1)*e^(-x/mu)/(gamma(r)*mu^r)
    plot(f,x,0,200).show()
    
</input>
</sage>
</p>

<p>
Derivation of mean, variance, skewness, and kurtosis. Pick "alpha" for the general formulas.
<sage>
	<input>
# Gamma Distribution
var('x,mu,r,alpha')
assume(mu>0)
assume(alpha,'integer')
assume(alpha>1)
@interact
def _(r=[2,3,6,9,alpha]):
    f(x) =x^(r-1)*e^(-x/mu)/(gamma(r)*mu^r)
    mean = integral(x*f,x,0,oo).full_simplify()
    M2 = integral(x^2*f,x,0,oo).full_simplify()
    M3 = integral(x^3*f,x,0,oo).full_simplify()
    M4 = integral(x^4*f,x,0,oo).full_simplify()
    
    pretty_print('Mean = ',mean)
    
    v = (M2-mean^2).factor()
    pretty_print('Variance = ',v)
    stand = sqrt(v)
    
    sk = (((M3 - 3*M2*mean + 2*mean^3))/stand^3).full_simplify()
    pretty_print('Skewness = ',sk)
    
    kurt = (M4 - 4*M3*mean + 6*M2*mean^2 -3*mean^4).factor()/stand^4
    pretty_print('Kurtosis = ',(kurt-3).factor(),'+3')
	</input>
</sage>
</p>
</section>

<section><title>Exercises</title>

<exercise><title> - Home Sales</title>
<p>
A local realty office sells on average 10 houses a week.  Let X measure the number of houses the sell in the next week.  Determine
<ol>
	<li>the probability the realty office sells 12 houses next week.</li>
	<li>the probability the realty office sells fewer than 10 houses next week.</li>
	<li>the interval <m>\mu - 2\sigma \le X \le \mu + 2\sigma</m>.</li>
	<li><m>P(\mu - 2\sigma \le X \le \mu + 2\sigma)</m>.</li>
	
</ol>
</p>
</exercise>


<exercise><title> - Computer Network Data Traffic</title>
<p>
Consider the arrival of requests on a server. Presume that the requests are considered as coming from an anonymous and large collection of users independently of each other on an average of 50 requests per second. If X measures the number of requests per second, determine
<ol>
	<li>the probability that in any given second the server gets fewer than 50 requests</li>
	<li><m>P(\mu - 2\sigma \le X \le \mu + 2\sigma)</m></li>
	<li>the expected number of requests per hour.</li>
</ol>

<solution>
<p>
Given the average of 50 requests per second and X measuring the number of "successes" in a given second long time interval given a Poission distribution
<me>f(x) = \frac{50^x}{x!}e^{-50}.</me>
Then,
<me>P(X \lt 50) = F(49) = \sum_{x=0}^{49} \frac{50^x}{x!} e^{-50}</me>
and using the graphing calculator function poissoncdf(50,49) = 0.48119.
</p>
<p>
For a time interval of one second, the mean is given to be 50 requests. Using the formulas developed above, the standard deviation therefore is <m>\sqrt{50}</m>. Therefore
<md>
	<mrow>P(\mu - 2\sigma \le X \le \mu + 2\sigma) &amp; = P(50 - 2\sqrt{50} \le X \le 50 + 2\sqrt{50})</mrow>
	<mrow> &amp; = P(X \in \{ 36, 37, 38, ..., 62, 63, 64 \}).</mrow>
</md>
Using the distribution function,
	<me>F(64) - F(35) \approx 0.97640 - 0.01621 = 0.96019</me>
</p>
<p>
Finally, notice that the time interval has been adjusted. Since the mean formula is proportional to the interval over which X is measured, using <m>\mu = \lambda T</m> with <m>\lambda = 1</m> when the interval is 1 second, then when the interval is one hour, T = 3600 seconds. Hence, we would expect on average <m>50 \cdot 3600 = 180,000</m> requests in one hour.
</p>
</solution>
</p>
</exercise>

</section>


</chapter>