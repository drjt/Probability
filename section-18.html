<!DOCTYPE html>
<!--**************************************-->
<!--* Generated from MathBook XML source *-->
<!--*    on 2016-09-02T15:01:05-05:00    *-->
<!--*                                    *-->
<!--*   http://mathbook.pugetsound.edu   *-->
<!--*                                    *-->
<!--**************************************-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>AATA Definition of Probability</title>
<meta name="Keywords" content="Authored in MathBook XML">
<meta name="viewport" content="width=device-width,  initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<script type="text/javascript" src="https://sagecell.sagemath.org/static/jquery.min.js"></script><script type="text/x-mathjax-config">
// contrib directory for accessibility menu, moot after v2.6+?
MathJax.Ajax.config.path["Contrib"] = "https://cdn.mathjax.org/mathjax/contrib";
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['\\(','\\)']],
    },
    TeX: {
        // [Contrib]accessibility menu moot after v2.6+?
        extensions: ["AMSmath.js", "AMSsymbols.js", "extpfeil.js", "autobold.js", "https://aimath.org/mathbook/mathjaxknowl.js", "[Contrib]/a11y/accessibility-menu.js", ],
        equationNumbers: { autoNumber: "none",
                           useLabelIds: true,
                           // JS comment, XML CDATA protect XHTML quality of file
                           // if removed in XSL, use entities
                           //<![CDATA[
                           formatID: function (n) {return String(n).replace(/[:'"<>&]/g,"")},
                           //]]>
                         },
        TagSide: "right",
        TagIndent: ".8em",
    },
    "HTML-CSS": {
        scale: 88,
    },
});
    </script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML-full"></script><link href="https://aimath.org/knowlstyle.css" rel="stylesheet" type="text/css">
<script type="text/javascript" src="https://aimath.org/knowl.js"></script><script src="https://aimath.org/mathbook/js/lib/jquery.sticky.js"></script><script src="https://aimath.org/mathbook/js/lib/jquery.espy.min.js"></script><script src="https://aimath.org/mathbook/js/Mathbook.js"></script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://aimath.org/mathbook/stylesheets/mathbook-3.css" rel="stylesheet" type="text/css">
<link href="https://aimath.org/mathbook/mathbook-add-on.css" rel="stylesheet" type="text/css">
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<div style="display:none;">\(
\newcommand{\lt}{ &lt; }
\newcommand{\gt}{ &gt; }
\newcommand{\amp}{ &amp; }
\)</div>
<header id="masthead"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading">
<span class="title">Introduction to Mathematical Probability and Statistics</span><span class="subtitle">A Calculus-based Approach</span>
</h1>
<p class="byline">John Travis</p>
</div>
</div></div>
<nav id="primary-navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<a class="previous-button toolbar-item button" href="RelativeFrequency.html">Previous</a><a class="up-button button toolbar-item" href="ProbabilityGeneralities.html">Up</a><a class="next-button button toolbar-item" href="section-19.html">Next</a>
</div>
<button class="sidebar-right-toggle-button button active">Annotations</button>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="RelativeFrequency.html">Previous</a><a class="up-button button toolbar-item" href="ProbabilityGeneralities.html">Up</a><a class="next-button button toolbar-item" href="section-19.html">Next</a>
</div>
</div></nav></header><div class="page">
<aside id="sidebar-left" class="sidebar"><div class="sidebar-content">
<nav id="toc"><h2 class="link"><a href="index.html"><span class="title">Front Matter</span></a></h2>
<ul>
<li><a href="colophon-1.html">Colophon</a></li>
<li><a href="biography-1.html">Author Biography</a></li>
<li><a href="preface-1.html">Preface</a></li>
</ul>
<h2 class="link"><a href="PowerSeriesReview.html"><span class="codenumber">1</span><span class="title">Review of Calculus</span></a></h2>
<ul>
<li><a href="section-1.html">Geometric Series</a></li>
<li><a href="section-2.html">Binomial Sums</a></li>
<li><a href="section-3.html">Negative Binomial Series</a></li>
</ul>
<h2 class="link"><a href="RepresentingData.html"><span class="codenumber">2</span><span class="title">Representing Data</span></a></h2>
<ul>
<li><a href="section-4.html">Measurement Scales</a></li>
<li><a href="section-5.html">Techniques for Representing Data</a></li>
<li><a href="section-6.html">Measures of Position</a></li>
<li><a href="section-7.html">Measures of the Middle</a></li>
<li><a href="section-8.html">Measures of Spread</a></li>
<li><a href="section-9.html">Grouped Data</a></li>
<li><a href="section-10.html">Other Point Measures</a></li>
<li><a href="section-11.html">Graphical Representation of Data</a></li>
<li><a href="section-12.html">Exercises</a></li>
</ul>
<h2 class="link"><a href="Combinatorics.html"><span class="codenumber">3</span><span class="title">Counting and Combinatorics</span></a></h2>
<ul>
<li><a href="section-13.html">Introduction</a></li>
<li><a href="section-14.html">Permutations</a></li>
<li><a href="section-15.html">Combinations</a></li>
<li><a href="section-16.html">Exercises</a></li>
</ul>
<h2 class="link active"><a href="ProbabilityGeneralities.html"><span class="codenumber">4</span><span class="title">Probability and Probability Functions</span></a></h2>
<ul>
<li><a href="RelativeFrequency.html">Relative Frequency</a></li>
<li><a href="section-18.html" class="active">Definition of Probability</a></li>
<li><a href="section-19.html">Conditional Probability</a></li>
<li><a href="section-20.html">Bayes Theorem</a></li>
<li><a href="section-21.html">Independence</a></li>
<li><a href="section-22.html">Random Variables</a></li>
<li><a href="ProbabilityFunctions.html">Probability Functions</a></li>
<li><a href="section-24.html">Properties of the Distribution Function</a></li>
<li><a href="section-25.html">Standard Units</a></li>
<li><a href="section-26.html">Expected Value</a></li>
</ul>
<h2 class="link"><a href="BinomNegBinom.html"><span class="codenumber">5</span><span class="title">Binomial, Geometric, and Negative Binomial Distributions</span></a></h2>
<ul>
<li><a href="BinomialDistribution.html">Binomial Distribution</a></li>
<li><a href="GeometricDistribution.html">Geometric Distribution</a></li>
<li><a href="section-29.html">Negative Binomial</a></li>
</ul>
<h2 class="link"><a href="PoissonExponential.html"><span class="codenumber">6</span><span class="title">Poisson, Exponential, and Gamma Distributions</span></a></h2>
<ul>
<li><a href="section-30.html">Poisson Distribution</a></li>
<li><a href="section-31.html">Exponential Distribution</a></li>
<li><a href="section-32.html">Gamma Distribution</a></li>
</ul>
<h2 class="link"><a href="Normal.html"><span class="codenumber">7</span><span class="title">Normal Distributions</span></a></h2>
<ul>
<li><a href="section-33.html">Properties of the Normal Distribution</a></li>
<li><a href="section-34.html">Theorems</a></li>
<li><a href="section-35.html">Chi-Square Distribution</a></li>
<li><a href="section-36.html">Central Limit Theorem</a></li>
</ul>
<h2 class="link"><a href="IntervalEstimation.html"><span class="codenumber">8</span><span class="title">Estimating Data using Intervals</span></a></h2>
<ul>
<li><a href="section-37.html">Point Estimates</a></li>
<li><a href="section-38.html">Chebyshev</a></li>
<li><a href="section-39.html">Measures of Spread</a></li>
</ul></nav><div class="extras"><nav><a class="mathbook-link" href="https://mathbook.pugetsound.edu">Authored in MathBookÂ XML</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://cdn.mathjax.org/mathjax/badge/badge.gif" border="0" alt="Powered by MathJax"></a></nav></div>
</div></aside><main class="main"><div id="content" class="mathbook-content"><section class="section" id="section-18"><header title="Section 4.2 Definition of Probability"><h1 class="heading hide-type" alt="Section 4.2 Definition of Probability">
<span class="type">Section</span><span class="codenumber">4.2</span><span class="title">Definition of Probability</span>
</h1></header><section class="subsection" id="ProbabilityDefns"><header title="Subsection 4.2.1 Motivating the Definition"><h1 class="heading hide-type" alt="Subsection 4.2.1 Motivating the Definition">
<span class="type">Subsection</span><span class="codenumber">4.2.1</span><span class="title">Motivating the Definition</span>
</h1></header><p id="p-165">Using the ideas from our examples above, let's consider how we might formally define a way
	to measure the expectation from similar experiments.  Before doing so, we need a little notation:</p>
<article class="definition-like" id="definition-20"><h5 class="heading">
<span class="type">Definition</span><span class="codenumber">4.2.1</span>
</h5>The Cardinality of the set A is the number of elements in A. This will be denoted |A| (similar
		to the idea of frequency of an outcome noted earlier.) If a set has
		a infinite number of elements, then we will say it's cardinality is also infinite and 
		write |A| = \(\infty\)</article><article class="definition-like" id="definition-21"><h5 class="heading">
<span class="type">Definition</span><span class="codenumber">4.2.2</span><span class="title">Pairwise Disjoint Sets</span>
</h5>\( \{ A_1, A_2, ... , A_n \}\) are pairwise disjoint provided \(A_k \cap A_j = \emptyset\) so long as \(k \ne j\).
		</article><p id="p-166">
	To model the behavior above, consider how we might create a definition for our expectation
	of a given outcome by following the ideas uncovered above. To do so, first consider a desired collection
	of outcomes A. If each outcome in A is equally likely then we might follow the concept behind relative 
	frequency and consider a measure of expectation be |A|/|S|. Indeed, on a standard 
	6-sided die, the expectation of the outcome A={2} from the collection S = {1,2,3,4,5,6} should be
	|A|/|S| = 1/6.</p>
<p id="p-167">From the example where we take the sum of two die, the outcome A={4,5} from the
	collection S = {2,3,4,...,12} would be</p>\begin{gather*}
|A| = | {(1,3),(2,2),(3,1),(1,4),(2,3),(3,2),(4,1)}| = 7\\
|S| = | {(1,1),...,(1,6),(2,1),...,(2,6),...,(6,1),...,(6,6)}| = 36
\end{gather*}<p id="p-168">and so the expected relative frequency would be |A|/|S| = 7/36. Compare this theoretical value
	with the sum of the two outcomes from your experiment above.</p>
<p id="p-169">We are ready to now formally give a name to the theoretical measure of expectation for
	outcomes from an experiment. Taking our cue from the ideas related to equally likely outcomes, we 
	make our definition have the following basic properties:</p>
<ol style="list-style-type: decimal;">
<li id="li-105">Relative frequency cannot be negative, since cardinality cannot be negative</li>
<li id="li-106">Relative frequencies for disjoint events should sum to one</li>
<li id="li-107">Relative frequencies for collections of disjoint outcomes should equal the sum of the
	individual relative frequencies</li>
</ol></section><section class="subsection" id="subsection-9"><header title="Subsection 4.2.2 Probability"><h1 class="heading hide-type" alt="Subsection 4.2.2 Probability">
<span class="type">Subsection</span><span class="codenumber">4.2.2</span><span class="title">Probability</span>
</h1></header><p id="p-170">Based upon these we give the following:</p>
<article class="definition-like" id="DefnProb"><h5 class="heading">
<span class="type">Definition</span><span class="codenumber">4.2.3</span>
</h5>The probability P(A) of a given outcome A is a set function which satisfies:
		<ol style="list-style-type: decimal;">
<li id="li-108">(Nonnegativity) P(A) \(\ge 0\)</li>
<li id="li-109">(Totality) P(S) = 1</li>
<li id="li-110">(Subadditivity) If A \(\cap\) B = \(\emptyset\), then P(A \(\cup\) B) = P(A) + P(B).  
			In general, if {\(A_k\)} are pairwise disjoint then \(P( \cup_k A_k) = \sum_k P(A_k)\).</li>
</ol></article></section><section class="subsection" id="BasicProbabilityTheorems"><header title="Subsection 4.2.3 Basic Probability Theorems"><h1 class="heading hide-type" alt="Subsection 4.2.3 Basic Probability Theorems">
<span class="type">Subsection</span><span class="codenumber">4.2.3</span><span class="title">Basic Probability Theorems</span>
</h1></header><p id="p-171">Based upon this definition we can immediately establish a number of results.</p>
<article class="theorem-like" id="ProbabilityComplemnts"><h5 class="heading">
<span class="type">Theorem</span><span class="codenumber">4.2.4</span><span class="title">Probability of Complements</span>
</h5> For any event A, \(P(A) + P(A^c) = 1\)</article><div class="posterior">
<span class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-proof-11" id="proof-11"><article class="hiddenproof"><h5 class="heading"><span class="type">Proof</span></h5></article></a></span><span id="hk-proof-11" style="display: none;" class="tex2jax_ignore"><article class="hiddenproof"><p id="p-172">Let A be any event and note that \(A \cap A^c = \emptyset\).  But \(A \cup A^c = S\).
			So, by subadditivity \(1 = P(S) = P(A \cup A^c) = P(A) + P(A^c)\) as desired.</p></article></span>
</div>
<article class="theorem-like" id="ProbabilityEmptySet"><h5 class="heading">
<span class="type">Theorem</span><span class="codenumber">4.2.5</span>
</h5>\(P(\emptyset) = 0\)</article><div class="posterior">
<span class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-proof-12" id="proof-12"><article class="hiddenproof"><h5 class="heading"><span class="type">Proof</span></h5></article></a></span><span id="hk-proof-12" style="display: none;" class="tex2jax_ignore"><article class="hiddenproof"><p id="p-173">Note that \(\emptyset^c = S\). So, by the theorem above, 
			\(1 = P(S) + P(\emptyset) \Rightarrow 1 = 1 + P(\emptyset)\).
			Cancelling the 1 on both sides gives \(P(\emptyset) = 0\). </p></article></span>
</div>
<article class="theorem-like" id="ProbabilityContainment"><h5 class="heading">
<span class="type">Theorem</span><span class="codenumber">4.2.6</span>
</h5>For events A and B with \( A \subset B, P(A) \le P(B)\).
		</article><div class="posterior">
<span class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-proof-13" id="proof-13"><article class="hiddenproof"><h5 class="heading"><span class="type">Proof</span></h5></article></a></span><span id="hk-proof-13" style="display: none;" class="tex2jax_ignore"><article class="hiddenproof"><p id="p-174">Assume sets A and B satisfy \( A \subset B\). Then, notice that
			\(A \cap (B-A) = \emptyset\) and  \(B = A \cup (B-A)\). Therefore, by 
			subadditivity and nonnegativity</p>\begin{gather*}
0 \le P(B-A)\\
P(A) \le P(A) + P(B-A) \\
P(A) \le P(B)
\end{gather*}</article></span>
</div>
<article class="theorem-like" id="ProbabilityLessThanOne"><h5 class="heading">
<span class="type">Theorem</span><span class="codenumber">4.2.7</span>
</h5>For any event A, \(P(A) \le 1\)</article><div class="posterior">
<span class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-proof-14" id="proof-14"><article class="hiddenproof"><h5 class="heading"><span class="type">Proof</span></h5></article></a></span><span id="hk-proof-14" style="display: none;" class="tex2jax_ignore"><article class="hiddenproof"><p id="p-175">Notice \(A \subset S\). By the theorem above \( P(A) \le P(S) = 1\)</p></article></span>
</div>
<article class="theorem-like" id="ProbabilityTwoUnions"><h5 class="heading">
<span class="type">Theorem</span><span class="codenumber">4.2.8</span>
</h5>For any sets A and B, \(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</article><div class="posterior">
<span class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-proof-15" id="proof-15"><article class="hiddenproof"><h5 class="heading"><span class="type">Proof</span></h5></article></a></span><span id="hk-proof-15" style="display: none;" class="tex2jax_ignore"><article class="hiddenproof"><p id="p-176">Notice that we can write \(A \cup B\) as the disjoint union</p>\begin{gather*}
A \cup B = (A-B) \cup (A \cap B) \cup (B-A).
\end{gather*}<p id="p-177">We can also write disjointly</p>\begin{gather*}
A = (A-B) \cup (A \cap B)\\
B = (A \cap B) \cup (B-A)
\end{gather*}<p id="p-178">Hence, </p>\begin{align*}
P(A) &amp; + P(B) - P(A \cap B) \\
&amp; = [P(A-B) + P(A \cap B)] + [P(A \cap B) + P(B-A)] - P(A \cap B)\\
&amp; = P(A-B) + P(A \cap B) + P(B-A)\\
&amp; = P(A \cup B)
\end{align*}</article></span>
</div>
<p id="p-179">This result can be extended to more that two sets using a property known as inclusion-exclusion. The
	following two theorems illustrate this property and are presented without proof.
	</p>
<article class="theorem-like" id="ProbabilityThreeUnions"><h5 class="heading">
<span class="type">Corollary</span><span class="codenumber">4.2.9</span>
</h5>
			For any sets A, B and C, 
			\begin{align*}
P(A \cup B \cup C) &amp; = P(A) + P(B) + P(C)\\
&amp; - P(A \cap B) - P(A \cap C) - P(B \cap C) \\
&amp; + P(A \cap B \cap C)
\end{align*}</article><article class="theorem-like" id="ProbabilityFourUnions"><h5 class="heading">
<span class="type">Corollary</span><span class="codenumber">4.2.10</span>
</h5>
			For any sets A, B, C and D, 
			\begin{align*}
P(A \cup B \cup C \cup D) &amp; = P(A) + P(B) + P(C) + P(D)\\
&amp; - P(A \cap B) - P(A \cap C) - P(A \cap D)  - P(B \cap C) - P(B \cap D) - P(C \cap D)\\
&amp; + P(A \cap B \cap C) + P(A \cap B \cap D) + P(A \cap C \cap D) + P(B \cap C \cap D)\\
&amp; - P(A \cap B \cap C \cap D)
\end{align*}</article></section><section class="subsection" id="subsection-11"><header title="Subsection 4.2.4 Equally Likely Outcomes"><h1 class="heading hide-type" alt="Subsection 4.2.4 Equally Likely Outcomes">
<span class="type">Subsection</span><span class="codenumber">4.2.4</span><span class="title">Equally Likely Outcomes</span>
</h1></header><p id="p-180">
Many times, you will be dealing with making selections from a sample space where each item in the space has an equal chance of being selected. This may happen (for example) when items in the sample space are of equal size or when selecting a card from a completely shuffled deck or when coins are flipped or when a normal fair die is rolled. 
</p>
<p id="p-181">It is important to notice that not all outcomes are equally likely--even in times when there are only two of them. Indeed, it is generally not an equally likely situation when picking the winner of a football game which pits, say, the New Orleans Saints professional football team with the New Orleans Home School Saints. Even though there are only two options the probability of the professional team winning is much greater than the chances that the high school will prevail. 
</p>
<p id="p-182">
When items are equally likely (sometimes also called "randomly selected") then each individual event has the same chance of being selected as any other. In this instance, determining the probability of a collection of outcomes is relatively simple.
</p>
<article class="theorem-like" id="theorem-21"><h5 class="heading">
<span class="type">Theorem</span><span class="codenumber">4.2.11</span><span class="title">Probability of Equally Likely Events</span>
</h5>If outcomes in S are equally likely, then for \(A \subset S, P(A) = \frac{|A|}{|S|}\)</article><div class="posterior">
<span class="hidden-knowl-wrapper"><a knowl="" class="id-ref" refid="hk-proof-16" id="proof-16"><article class="hiddenproof"><h5 class="heading"><span class="type">Proof</span></h5></article></a></span><span id="hk-proof-16" style="display: none;" class="tex2jax_ignore"><article class="hiddenproof"><p id="p-183">
Enumerate S = {\(x_1, x_2, ..., x_{|S|}\)} and note \(P( \{ x_k \} ) = c\) for some constant c since each item is equally likely. However, using each outcome as a disjoint event and the definition of probability, 
\begin{align*}
1 = P(S) &amp; = P( \{ x_1 \} \cup \{x_2 \} \cup ... \cup \{x_{|S|} \} )\\
 &amp; = P(\{ x_1 \}) + P(\{ x_2 \} ) + ... + P(\{ x_{|S|} \} )\\
 &amp; = c + c + ... + c = {|S|} \times c
\end{align*}
and so \(c = \frac{1}{{|S|}}\). Therefore, \(P( \{ x_k \} ) = \frac{1}{|S|}\) .
</p>
<p id="p-184">
Hence, with A = {\(a_1, a_2, ..., a_{|A|}\)}, breaking up the disjoint probabilities as above gives
\begin{align*}
P(A) &amp; = P( \{ a_1 \} \cup \{ a_2 \} \cup ... \cup \{ a_{|A|} \} )\\
 &amp; = P(\{ a_1 \}) + P(\{ a_2 \} ) + ... + P(\{ a_{|A|} \} )\\
 &amp; = \frac{1}{{|S|}} + \frac{1}{{|S|}} + ... + \frac{1}{{|S|}}\\
 &amp; = \frac{|A|}{{|S|}}
\end{align*}
as desired.
</p></article></span>
</div></section><section class="subsection" id="subsection-12"><header title="Subsection 4.2.5 Exercises"><h1 class="heading hide-type" alt="Subsection 4.2.5 Exercises">
<span class="type">Subsection</span><span class="codenumber">4.2.5</span><span class="title">Exercises</span>
</h1></header>
<p id="p-185">
HOMEWORK: Determine the probabilities associated with the various 5-card hands.
</p>

<p id="p-186">
HOMEWORK: Determine the 36 possible outcomes related to the rolling a pair of fair dice. Justify why each of these outcomes is equally likely. Determine the probabilities associated with each possible sum.
</p>

<p id="p-187">
HOMEWORK: Suppose you have one die which only has three possible sides labeled 1, 2, or 3. Suppose a second die has twelve equally likely sides with labels 1,2,3,4,4,5,5,6,6,7,8,9.  Justify that the probabilities associate with each possible sum is the same as the probabilities when using two normal 6-sided dice.
</p>


<p id="p-188">
HOMEWORK: Analyze the game of
<a class="external-url" href="http://mathworld.wolfram.com/Craps.html" target="_blank">"craps"</a>.
</p>
</section></section></div></main>
</div>
</body>
</html>
